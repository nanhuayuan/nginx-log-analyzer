#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Nginxç›‘æ§æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ
æ”¯æŒæ—¥æŠ¥ã€å‘¨æŠ¥ã€æœˆæŠ¥ä»¥åŠè‡ªå®šä¹‰æ—¶é—´æ®µçš„ç›‘æ§æŠ¥å‘Šç”Ÿæˆ
åŒ…å«GUIç•Œé¢å’ŒExcelå¯¼å‡ºåŠŸèƒ½
"""

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
from tkinter.ttk import *
import datetime
import json
import logging
import os
import sys
from dataclasses import dataclass
from enum import Enum
from typing import Dict, List, Tuple, Optional, Any
import pandas as pd
import requests
from requests.auth import HTTPBasicAuth
import threading
import queue

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('monitoring_report.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


# æšä¸¾å’Œæ•°æ®ç±»å®šä¹‰
class ReportType(Enum):
    DAILY = "æ—¥æŠ¥"
    WEEKLY = "å‘¨æŠ¥"
    MONTHLY = "æœˆæŠ¥"
    CUSTOM = "è‡ªå®šä¹‰"


@dataclass
class MetricResult:
    value: float
    unit: str = ""
    timestamp: str = ""
    status: str = "normal"


@dataclass
class ConnectionConfig:
    url: str
    username: str
    password: str
    datasource_ids: List[str]


# æŒ‡æ ‡é…ç½®é›†ä¸­ç®¡ç†
class MetricsConfig:
    """æŒ‡æ ‡é…ç½®é›†ä¸­ç®¡ç†ç±»"""

    @staticmethod
    def get_core_metrics_queries() -> Dict[str, Dict[str, Any]]:
        """æ ¸å¿ƒä¸šåŠ¡æŒ‡æ ‡æŸ¥è¯¢é…ç½®"""
        return {
            "availability": {
                "query": 'count(nginx_active{{cluster="{cluster}"}} > 0) / count(nginx_active{{cluster="{cluster}"}}) * 100',
                "type": "instant",
                "unit": "%",
                "thresholds": {"critical": 99.0, "warning": 99.9}
            },
            "total_requests": {
                "query": 'sum(increase(nginx_requests{{cluster="{cluster}"}}[{duration}]))',
                "type": "instant",
                "unit": "æ¬¡"
            },
            "qps": {
                "query": 'sum(rate(nginx_requests{{cluster="{cluster}"}}[2m]))',
                "type": "range",
                "unit": "req/s"
            },
            "bandwidth_in": {
                "query": 'sum(rate(net_bytes_recv{{cluster="{cluster}"}}[2m]) * 8) / 1000000000',
                "type": "range",
                "unit": "Gbps"
            },
            "bandwidth_out": {
                "query": 'sum(rate(net_bytes_sent{{cluster="{cluster}"}}[2m]) * 8) / 1000000000',
                "type": "range",
                "unit": "Gbps"
            },
            "traffic_in": {
                "query": 'sum(increase(net_bytes_recv{{cluster="{cluster}"}}[{duration}])) / 1024 / 1024 / 1024 / 1024',
                "type": "instant",
                "unit": "TB"
            },
            "traffic_out": {
                "query": 'sum(increase(net_bytes_sent{{cluster="{cluster}"}}[{duration}])) / 1024 / 1024 / 1024 / 1024',
                "type": "instant",
                "unit": "TB"
            }
        }

    @staticmethod
    def get_system_metrics_queries() -> Dict[str, Dict[str, Any]]:
        """ç³»ç»Ÿèµ„æºæŒ‡æ ‡æŸ¥è¯¢é…ç½®"""
        return {
            "cpu_usage": {
                "query": 'avg(cpu_usage_active{{cluster="{cluster}"}})',
                "type": "range",
                "unit": "%",
                "thresholds": {"critical": 85, "warning": 70}
            },
            "memory_usage": {
                "query": 'avg(mem_used_percent{{cluster="{cluster}"}})',
                "type": "range",
                "unit": "%",
                "thresholds": {"critical": 90, "warning": 75}
            },
            "system_load": {
                "query": 'avg(system_load5{{cluster="{cluster}"}})',
                "type": "range",
                "unit": ""
            },
            "cpu_cores": {
                "query": 'system_n_cpus{{cluster="{cluster}"}}',
                "type": "instant",
                "unit": "æ ¸"
            },
            "node_count": {
                "query": 'count(up{{cluster="{cluster}", job=~".*node.*"}} == 1 or system_uptime{{cluster="{cluster}"}} > 0)',
                "type": "instant",
                "unit": "ä¸ª"
            }
        }

    @staticmethod
    def get_connection_metrics_queries() -> Dict[str, Dict[str, Any]]:
        """è¿æ¥çŠ¶æ€æŒ‡æ ‡æŸ¥è¯¢é…ç½®"""
        return {
            "conn_active": {
                "query": 'sum(nginx_active{{cluster="{cluster}"}})',
                "type": "range",
                "unit": "ä¸ª"
            },
            "conn_waiting": {
                "query": 'sum(nginx_waiting{{cluster="{cluster}"}})',
                "type": "range",
                "unit": "ä¸ª"
            },
            "conn_reading": {
                "query": 'sum(nginx_reading{{cluster="{cluster}"}})',
                "type": "range",
                "unit": "ä¸ª"
            },
            "conn_writing": {
                "query": 'sum(nginx_writing{{cluster="{cluster}"}})',
                "type": "range",
                "unit": "ä¸ª"
            }
        }

    @staticmethod
    def get_anomaly_metrics_queries() -> Dict[str, Dict[str, Any]]:
        """å¼‚å¸¸äº‹ä»¶æŒ‡æ ‡æŸ¥è¯¢é…ç½®"""
        return {
            "oom_events": {
                "query": 'sum(increase(kernel_vmstat_oom_kill{{cluster="{cluster}"}}[{duration}]))',
                "type": "instant",
                "unit": "æ¬¡",
                "thresholds": {"critical": 1}
            },
            "high_cpu_nodes": {
                "query": 'count(cpu_usage_active{{cluster="{cluster}"}} > {cpu_threshold})',
                "type": "instant",
                "unit": "ä¸ª",
                "thresholds": {"warning": 1}
            },
            "high_memory_nodes": {
                "query": 'count(mem_used_percent{{cluster="{cluster}"}} > {memory_threshold})',
                "type": "instant",
                "unit": "ä¸ª",
                "thresholds": {"warning": 1}
            },
            "network_errors": {
                "query": 'sum(increase(net_err_in{{cluster="{cluster}"}}[{duration}]) + increase(net_err_out{{cluster="{cluster}"}}[{duration}]))',
                "type": "instant",
                "unit": "ä¸ª",
                "thresholds": {"critical": 1000, "warning": 100}
            }
        }


class NightingaleClient:
    """å¤œèºç›‘æ§å®¢æˆ·ç«¯"""

    def __init__(self, base_url: str, username: str, password: str):
        self.base_url = base_url.rstrip('/')
        self.auth = HTTPBasicAuth(username, password)
        self.session = requests.Session()
        self.session.auth = self.auth
        self.session.headers.update({
            'Content-Type': 'application/json',
            'Accept': 'application/json'
        })

    def query_instant(self, query: str, timestamp: int) -> Dict:
        """æ‰§è¡Œå³æ—¶æŸ¥è¯¢"""
        # url = f"{self.base_url}/api/v1/query"
        url = f"{self.base_url}/api/n9e/proxy/1/api/v1/query"
        params = {
            'query': query,
            'time': timestamp
        }

        try:
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"å³æ—¶æŸ¥è¯¢å¤±è´¥: {query}, é”™è¯¯: {e}")
            return {}

    def query_range(self, query: str, start_time: int, end_time: int, step: str = "1m") -> Dict:
        """æ‰§è¡ŒèŒƒå›´æŸ¥è¯¢"""
        # url = f"{self.base_url}/api/v1/query_range"
        url = f"{self.base_url}/api/n9e/proxy/1/api/v1/query_range"
        params = {
            'query': query,
            'start': start_time,
            'end': end_time,
            'step': step
        }

        try:
            response = self.session.get(url, params=params, timeout=60)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"èŒƒå›´æŸ¥è¯¢å¤±è´¥: {query}, é”™è¯¯: {e}")
            return {}


class MetricsExtractor:
    """æŒ‡æ ‡æ•°æ®æå–å™¨"""

    @staticmethod
    def extract_max_with_time(result: Dict) -> Tuple[float, str]:
        """æå–æœ€å¤§å€¼å’Œå¯¹åº”çš„æ—¶é—´æˆ³"""
        max_value = 0.0
        max_time = "N/A"

        for series in result.get("data", {}).get("result", []):
            for timestamp, value in series.get("values", []):
                try:
                    val = float(value)
                    if val > max_value:
                        max_value = val
                        max_time = datetime.datetime.fromtimestamp(timestamp).strftime("%m-%d %H:%M")
                except (ValueError, TypeError):
                    continue

        return max_value, max_time

    @staticmethod
    def extract_min_with_time(result: Dict) -> Tuple[float, str]:
        """æå–æœ€å°å€¼å’Œå¯¹åº”çš„æ—¶é—´æˆ³"""
        min_value = float('inf')
        min_time = "N/A"

        for series in result.get("data", {}).get("result", []):
            for timestamp, value in series.get("values", []):
                try:
                    val = float(value)
                    if val < min_value:
                        min_value = val
                        min_time = datetime.datetime.fromtimestamp(timestamp).strftime("%m-%d %H:%M")
                except (ValueError, TypeError):
                    continue

        return min_value if min_value != float('inf') else 0.0, min_time

    @staticmethod
    def extract_avg(result: Dict) -> float:
        """æå–å¹³å‡å€¼"""
        total_sum = 0.0
        count = 0

        for series in result.get("data", {}).get("result", []):
            for timestamp, value in series.get("values", []):
                try:
                    total_sum += float(value)
                    count += 1
                except (ValueError, TypeError):
                    continue

        return total_sum / count if count > 0 else 0.0

    @staticmethod
    def extract_instant_value(result: Dict) -> float:
        """æå–å³æ—¶å€¼"""
        for series in result.get("data", {}).get("result", []):
            try:
                return float(series["value"][1])
            except (KeyError, ValueError, TypeError, IndexError):
                continue
        return 0.0


class NginxReportGenerator:
    """Nginxç›‘æ§æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, client: NightingaleClient, cpu_threshold: float = 85, memory_threshold: float = 90):
        self.client = client
        self.extractor = MetricsExtractor()
        self.cpu_threshold = cpu_threshold
        self.memory_threshold = memory_threshold
        self.metrics_config = MetricsConfig()

    def get_time_ranges(self, target_date: str, report_type: ReportType = ReportType.DAILY,
                        end_date: str = None) -> Dict[str, Tuple[int, int]]:
        """è·å–æ—¶é—´èŒƒå›´"""
        try:
            base_date = datetime.datetime.strptime(target_date, "%Y-%m-%d")
        except ValueError:
            logger.error(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {target_date}")
            raise ValueError(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {target_date}")

        ranges = {}

        if report_type == ReportType.CUSTOM and end_date:
            try:
                end_dt = datetime.datetime.strptime(end_date, "%Y-%m-%d")
                current_start = base_date.replace(hour=0, minute=0, second=0, microsecond=0)
                current_end = end_dt.replace(hour=23, minute=59, second=59, microsecond=0)
                ranges["current"] = (int(current_start.timestamp()), int(current_end.timestamp()))
            except ValueError:
                logger.error(f"ç»“æŸæ—¥æœŸæ ¼å¼é”™è¯¯: {end_date}")
                raise ValueError(f"ç»“æŸæ—¥æœŸæ ¼å¼é”™è¯¯: {end_date}")

        elif report_type == ReportType.DAILY:
            current_start = base_date.replace(hour=0, minute=0, second=0, microsecond=0)
            current_end = base_date.replace(hour=23, minute=59, second=59, microsecond=0)
            ranges["current"] = (int(current_start.timestamp()), int(current_end.timestamp()))

            prev_date = base_date - datetime.timedelta(days=1)
            prev_start = prev_date.replace(hour=0, minute=0, second=0, microsecond=0)
            prev_end = prev_date.replace(hour=23, minute=59, second=59, microsecond=0)
            ranges["previous"] = (int(prev_start.timestamp()), int(prev_end.timestamp()))

        elif report_type == ReportType.WEEKLY:
            monday = base_date - datetime.timedelta(days=base_date.weekday())
            current_start = monday.replace(hour=0, minute=0, second=0, microsecond=0)
            current_end = (monday + datetime.timedelta(days=6)).replace(hour=23, minute=59, second=59, microsecond=0)
            ranges["current"] = (int(current_start.timestamp()), int(current_end.timestamp()))

            prev_monday = monday - datetime.timedelta(days=7)
            prev_start = prev_monday.replace(hour=0, minute=0, second=0, microsecond=0)
            prev_end = (prev_monday + datetime.timedelta(days=6)).replace(hour=23, minute=59, second=59, microsecond=0)
            ranges["previous"] = (int(prev_start.timestamp()), int(prev_end.timestamp()))

        elif report_type == ReportType.MONTHLY:
            first_day = base_date.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
            if base_date.month == 12:
                next_month = first_day.replace(year=base_date.year + 1, month=1)
            else:
                next_month = first_day.replace(month=base_date.month + 1)
            last_day = next_month - datetime.timedelta(days=1)
            current_end = last_day.replace(hour=23, minute=59, second=59, microsecond=0)
            ranges["current"] = (int(first_day.timestamp()), int(current_end.timestamp()))

            if first_day.month == 1:
                prev_first = first_day.replace(year=first_day.year - 1, month=12, day=1)
            else:
                prev_first = first_day.replace(month=first_day.month - 1, day=1)
            prev_last = first_day - datetime.timedelta(days=1)
            prev_end = prev_last.replace(hour=23, minute=59, second=59, microsecond=0)
            ranges["previous"] = (int(prev_first.timestamp()), int(prev_end.timestamp()))

        return ranges

    def _execute_query(self, query_config: Dict[str, Any], cluster: str, start_time: int,
                       end_time: int, **kwargs) -> Dict:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        duration = f"{end_time - start_time}s"
        query = query_config["query"].format(
            cluster=cluster,
            duration=duration,
            cpu_threshold=kwargs.get('cpu_threshold', self.cpu_threshold),
            memory_threshold=kwargs.get('memory_threshold', self.memory_threshold)
        )

        if query_config["type"] == "instant":
            return self.client.query_instant(query, end_time)
        else:
            return self.client.query_range(query, start_time, end_time)

    def collect_metrics_by_config(self, metrics_config: Dict[str, Dict[str, Any]],
                                  cluster: str, start_time: int, end_time: int) -> Dict[str, MetricResult]:
        """æ ¹æ®é…ç½®æ”¶é›†æŒ‡æ ‡"""
        metrics = {}

        for metric_name, config in metrics_config.items():
            try:
                result = self._execute_query(config, cluster, start_time, end_time)

                if config["type"] == "instant":
                    value = self.extractor.extract_instant_value(result)
                    metrics[metric_name] = MetricResult(
                        value=max(0, value),
                        unit=config["unit"],
                        status=self._get_status(value, config.get("thresholds", {}))
                    )
                else:
                    # èŒƒå›´æŸ¥è¯¢ï¼Œæå–å¹³å‡å€¼ã€å³°å€¼ç­‰
                    avg_value = self.extractor.extract_avg(result)
                    peak_value, peak_time = self.extractor.extract_max_with_time(result)
                    min_value, min_time = self.extractor.extract_min_with_time(result)

                    metrics[f"{metric_name}_avg"] = MetricResult(
                        value=max(0, avg_value),
                        unit=config["unit"],
                        status=self._get_status(avg_value, config.get("thresholds", {}))
                    )
                    metrics[f"{metric_name}_peak"] = MetricResult(
                        value=max(0, peak_value),
                        unit=config["unit"],
                        timestamp=peak_time
                    )
                    metrics[f"{metric_name}_min"] = MetricResult(
                        value=max(0, min_value),
                        unit=config["unit"],
                        timestamp=min_time
                    )

            except Exception as e:
                logger.error(f"æ”¶é›†æŒ‡æ ‡ {metric_name} å¤±è´¥: {e}")
                metrics[metric_name] = MetricResult(value=0.0, unit=config["unit"])

        return metrics

    def _get_status(self, value: float, thresholds: Dict[str, float]) -> str:
        """æ ¹æ®é˜ˆå€¼åˆ¤æ–­çŠ¶æ€"""
        if not thresholds:
            return "normal"

        if "critical" in thresholds and value >= thresholds["critical"]:
            return "critical"
        elif "warning" in thresholds and value >= thresholds["warning"]:
            return "warning"
        else:
            return "normal"

    def generate_report(self, target_date: str, clusters: List[str],
                        report_type: ReportType = ReportType.DAILY,
                        end_date: str = None, include_comparison: bool = True) -> List[str]:
        """ç”Ÿæˆç›‘æ§æŠ¥å‘Š"""
        logger.info(f"ğŸš€ å¼€å§‹ç”Ÿæˆ {target_date} çš„{report_type.value}ç›‘æ§æŠ¥å‘Š...")

        time_ranges = self.get_time_ranges(target_date, report_type, end_date)
        current_start, current_end = time_ranges["current"]

        cluster_reports = []

        for cluster in clusters:
            logger.info(f"ğŸ“Š å¤„ç†é›†ç¾¤: {cluster}")

            # æ”¶é›†å„ç±»æŒ‡æ ‡
            core_metrics = self.collect_metrics_by_config(
                self.metrics_config.get_core_metrics_queries(),
                cluster, current_start, current_end
            )

            system_metrics = self.collect_metrics_by_config(
                self.metrics_config.get_system_metrics_queries(),
                cluster, current_start, current_end
            )

            connection_metrics = self.collect_metrics_by_config(
                self.metrics_config.get_connection_metrics_queries(),
                cluster, current_start, current_end
            )

            anomaly_metrics = self.collect_metrics_by_config(
                self.metrics_config.get_anomaly_metrics_queries(),
                cluster, current_start, current_end
            )

            # å¯¹æ¯”æ•°æ®
            comparison_data = {}
            if include_comparison and "previous" in time_ranges:
                prev_start, prev_end = time_ranges["previous"]
                prev_core = self.collect_metrics_by_config(
                    self.metrics_config.get_core_metrics_queries(),
                    cluster, prev_start, prev_end
                )
                prev_system = self.collect_metrics_by_config(
                    self.metrics_config.get_system_metrics_queries(),
                    cluster, prev_start, prev_end
                )

                comparison_data = self._calculate_comparisons(core_metrics, system_metrics,
                                                              prev_core, prev_system)

            # æ ¼å¼åŒ–æŠ¥å‘Š
            cluster_report = self._format_cluster_report(
                target_date, report_type, cluster,
                core_metrics, system_metrics, connection_metrics, anomaly_metrics,
                comparison_data
            )

            cluster_reports.append(cluster_report)

        logger.info(f"âœ… {target_date} {report_type.value}ç›‘æ§æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ{len(cluster_reports)}ä¸ªé›†ç¾¤æŠ¥å‘Š")
        return cluster_reports

    def _calculate_comparisons(self, current_core: Dict, current_system: Dict,
                               prev_core: Dict, prev_system: Dict) -> Dict:
        """è®¡ç®—å¯¹æ¯”æ•°æ®"""
        comparisons = {}

        compare_pairs = [
            ("total_requests", "total_requests"),
            ("traffic_in", "traffic_in"),
            ("qps_peak", "qps_peak"),
            ("cpu_usage_avg", "cpu_usage_avg"),
            ("memory_usage_avg", "memory_usage_avg")
        ]

        for current_key, prev_key in compare_pairs:
            current_val = 0
            prev_val = 0

            # ä»å½“å‰æ•°æ®ä¸­è·å–å€¼
            if current_key in current_core:
                current_val = current_core[current_key].value
            elif current_key in current_system:
                current_val = current_system[current_key].value

            # ä»å†å²æ•°æ®ä¸­è·å–å€¼
            if prev_key in prev_core:
                prev_val = prev_core[prev_key].value
            elif prev_key in prev_system:
                prev_val = prev_system[prev_key].value

            comparisons[current_key] = self.calculate_comparison(current_val, prev_val)

        return comparisons

    def calculate_comparison(self, current: float, previous: float) -> Tuple[float, str]:
        """è®¡ç®—å¯¹æ¯”å˜åŒ–"""
        if previous == 0:
            if current == 0:
                return 0.0, "æŒå¹³"
            else:
                return 100.0, "æ–°å¢"

        change_ratio = ((current - previous) / previous) * 100

        if abs(change_ratio) < 0.1:
            trend = "æŒå¹³"
        elif change_ratio > 0:
            trend = f"ä¸Šå‡{abs(change_ratio):.1f}%"
        else:
            trend = f"ä¸‹é™{abs(change_ratio):.1f}%"

        return change_ratio, trend

    def _format_cluster_report(self, target_date: str, report_type: ReportType, cluster: str,
                               core_metrics: Dict, system_metrics: Dict, connection_metrics: Dict,
                               anomaly_metrics: Dict, comparison_data: Dict) -> str:
        """æ ¼å¼åŒ–é›†ç¾¤æŠ¥å‘Š"""
        report_lines = []

        # æŠ¥å‘Šå¤´éƒ¨
        report_lines.append(f"# {cluster} é›†ç¾¤ {target_date} {report_type.value}ç›‘æ§æŠ¥å‘Š")
        report_lines.append("=" * 60)
        report_lines.append("")

        # æ ¸å¿ƒä¸šåŠ¡æŒ‡æ ‡
        report_lines.append("## ğŸ“Š æ ¸å¿ƒä¸šåŠ¡æŒ‡æ ‡")
        report_lines.append("")

        if "availability" in core_metrics:
            availability = core_metrics["availability"]
            status_icon = "ğŸŸ¢" if availability.status == "normal" else "ğŸŸ¡" if availability.status == "warning" else "ğŸ”´"
            report_lines.append(f"**æœåŠ¡å¯ç”¨æ€§**: {status_icon} {availability.value:.2f}%")

        if "total_requests" in core_metrics:
            requests = core_metrics["total_requests"]
            comparison = comparison_data.get("total_requests", (0, ""))
            report_lines.append(f"**æ€»è¯·æ±‚æ•°**: {self.format_requests(requests.value)} ({comparison[1]})")

        if "qps_peak" in core_metrics:
            qps = core_metrics["qps_peak"]
            comparison = comparison_data.get("qps_peak", (0, ""))
            report_lines.append(f"**å³°å€¼QPS**: {qps.value:.2f} {qps.unit} (æ—¶é—´: {qps.timestamp}) ({comparison[1]})")

        # ç³»ç»Ÿèµ„æºæŒ‡æ ‡
        report_lines.append("")
        report_lines.append("## ğŸ–¥ï¸ ç³»ç»Ÿèµ„æºæŒ‡æ ‡")
        report_lines.append("")

        if "cpu_usage_avg" in system_metrics:
            cpu = system_metrics["cpu_usage_avg"]
            cpu_peak = system_metrics.get("cpu_usage_peak", MetricResult(0, ""))
            status_icon = "ğŸŸ¢" if cpu.status == "normal" else "ğŸŸ¡" if cpu.status == "warning" else "ğŸ”´"
            comparison = comparison_data.get("cpu_usage_avg", (0, ""))
            report_lines.append(
                f"**CPUä½¿ç”¨ç‡**: {status_icon} å¹³å‡{cpu.value:.1f}%, å³°å€¼{cpu_peak.value:.1f}% (æ—¶é—´: {cpu_peak.timestamp}) ({comparison[1]})")

        if "memory_usage_avg" in system_metrics:
            memory = system_metrics["memory_usage_avg"]
            memory_peak = system_metrics.get("memory_usage_peak", MetricResult(0, ""))
            comparison = comparison_data.get("memory_usage_avg", (0, ""))
            status_icon = "ğŸŸ¢" if memory.status == "normal" else "ğŸŸ¡" if memory.status == "warning" else "ğŸ”´"
            report_lines.append(
                f"**å†…å­˜ä½¿ç”¨ç‡**: {status_icon} å¹³å‡{memory.value:.1f}%, å³°å€¼{memory_peak.value:.1f}% (æ—¶é—´: {memory_peak.timestamp}) ({comparison[1]})")

        # è¿æ¥çŠ¶æ€æŒ‡æ ‡
        if any(key.startswith("conn_") for key in connection_metrics.keys()):
            report_lines.append("")
            report_lines.append("## ğŸ”— è¿æ¥çŠ¶æ€æŒ‡æ ‡")
            report_lines.append("")

            for conn_type in ["active", "waiting", "reading", "writing"]:
                avg_key = f"conn_{conn_type}_avg"
                peak_key = f"conn_{conn_type}_peak"
                if avg_key in connection_metrics:
                    avg_conn = connection_metrics[avg_key]
                    peak_conn = connection_metrics.get(peak_key, MetricResult(0, ""))
                    report_lines.append(
                        f"**{conn_type.title()}è¿æ¥**: å¹³å‡{avg_conn.value:.0f}ä¸ª, å³°å€¼{peak_conn.value:.0f}ä¸ª (æ—¶é—´: {peak_conn.timestamp})")

        # å¼‚å¸¸äº‹ä»¶
        if any(metric.value > 0 for metric in anomaly_metrics.values()):
            report_lines.append("")
            report_lines.append("## âš ï¸ å¼‚å¸¸äº‹ä»¶")
            report_lines.append("")

            for metric_name, metric in anomaly_metrics.items():
                if metric.value > 0:
                    status_icon = "ğŸ”´" if metric.status == "critical" else "ğŸŸ¡"
                    report_lines.append(f"**{metric_name}**: {status_icon} {metric.value:.0f}{metric.unit}")

        report_lines.append("")
        report_lines.append("---")
        report_lines.append(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("")

        return "\n".join(report_lines)

    def export_to_excel(self, target_date: str, clusters: List[str],
                        report_type: ReportType, end_date: str = None,
                        output_path: str = "monitoring_report.xlsx") -> bool:
        """å¯¼å‡ºExcelæŠ¥å‘Š"""
        try:
            time_ranges = self.get_time_ranges(target_date, report_type, end_date)
            current_start, current_end = time_ranges["current"]

            all_data = []

            for cluster in clusters:
                logger.info(f"ğŸ“Š å¯¼å‡ºé›†ç¾¤ {cluster} çš„Excelæ•°æ®...")

                # æ”¶é›†å„ç±»æŒ‡æ ‡
                all_metrics = {}
                all_metrics.update(self.collect_metrics_by_config(
                    self.metrics_config.get_core_metrics_queries(),
                    cluster, current_start, current_end
                ))
                all_metrics.update(self.collect_metrics_by_config(
                    self.metrics_config.get_system_metrics_queries(),
                    cluster, current_start, current_end
                ))
                all_metrics.update(self.collect_metrics_by_config(
                    self.metrics_config.get_connection_metrics_queries(),
                    cluster, current_start, current_end
                ))
                all_metrics.update(self.collect_metrics_by_config(
                    self.metrics_config.get_anomaly_metrics_queries(),
                    cluster, current_start, current_end
                ))

                # æ ¼å¼åŒ–æ•°æ®ä¸ºExcelæ ¼å¼
                for metric_name, metric in all_metrics.items():
                    row_data = {
                        'æ—¥æœŸ': target_date,
                        'é›†ç¾¤': cluster,
                        'æŒ‡æ ‡åç§°': metric_name,
                        'æ•°å€¼': metric.value,
                        'å•ä½': metric.unit,
                        'çŠ¶æ€': metric.status,
                        'æ—¶é—´æˆ³': metric.timestamp if metric.timestamp else '',
                        'æŠ¥å‘Šç±»å‹': report_type.value
                    }
                    all_data.append(row_data)

            # åˆ›å»ºDataFrameå¹¶å¯¼å‡ºExcel
            df = pd.DataFrame(all_data)

            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                # åŸå§‹æ•°æ®è¡¨
                df.to_excel(writer, sheet_name='ç›‘æ§æ•°æ®', index=False)

                # ç»Ÿè®¡æ±‡æ€»è¡¨
                summary_data = []
                for cluster in clusters:
                    cluster_data = df[df['é›†ç¾¤'] == cluster]
                    for metric_name in cluster_data['æŒ‡æ ‡åç§°'].unique():
                        metric_data = cluster_data[cluster_data['æŒ‡æ ‡åç§°'] == metric_name]
                        if not metric_data.empty:
                            values = metric_data['æ•°å€¼'].dropna()
                            if not values.empty:
                                summary_row = {
                                    'é›†ç¾¤': cluster,
                                    'æŒ‡æ ‡åç§°': metric_name,
                                    'æœ€å¤§å€¼': values.max(),
                                    'æœ€å°å€¼': values.min(),
                                    'å¹³å‡å€¼': values.mean(),
                                    'æ€»å’Œ': values.sum(),
                                    'å•ä½': metric_data['å•ä½'].iloc[0] if not metric_data['å•ä½'].empty else ''
                                }
                                summary_data.append(summary_row)

                summary_df = pd.DataFrame(summary_data)
                summary_df.to_excel(writer, sheet_name='ç»Ÿè®¡æ±‡æ€»', index=False)

            logger.info(f"âœ… ExcelæŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {output_path}")
            return True

        except Exception as e:
            logger.error(f"âŒ Excelå¯¼å‡ºå¤±è´¥: {e}")
            return False

    @staticmethod
    def format_requests(value: float) -> str:
        """æ ¼å¼åŒ–è¯·æ±‚æ•°"""
        if value >= 1000000000:
            return f"{value / 1000000000:.2f}G"
        elif value >= 1000000:
            return f"{value / 1000000:.2f}M"
        elif value >= 1000:
            return f"{value / 1000:.2f}K"
        else:
            return f"{value:.0f}"


class NginxMonitoringGUI:
    """Nginxç›‘æ§ç³»ç»ŸGUIç•Œé¢"""

    def __init__(self, root):
        self.root = root
        self.root.title("Nginxç›‘æ§æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ")
        self.root.geometry("800x700")
        self.root.resizable(True, True)

        # é…ç½®æ ·å¼
        self.setup_styles()

        # åˆå§‹åŒ–å˜é‡
        self.init_variables()

        # åˆ›å»ºç•Œé¢
        self.create_widgets()

        # çŠ¶æ€
        self.client = None
        self.generator = None
        self.report_queue = queue.Queue()

    def setup_styles(self):
        """é…ç½®ç•Œé¢æ ·å¼"""
        style = ttk.Style()
        style.theme_use('clam')

        # é…ç½®é¢œè‰²
        style.configure('Title.TLabel', font=('Arial', 12, 'bold'))
        style.configure('Section.TLabel', font=('Arial', 10, 'bold'))
        style.configure('Success.TLabel', foreground='green')
        style.configure('Error.TLabel', foreground='red')

    def init_variables(self):
        """åˆå§‹åŒ–ç•Œé¢å˜é‡"""
        # è¿æ¥é…ç½®
        self.url_var = tk.StringVar(value="http://localhost:8080")
        self.username_var = tk.StringVar(value="admin")
        self.password_var = tk.StringVar(value="")
        self.datasource_var = tk.StringVar(value="prometheus")

        # æŠ¥å‘Šé…ç½®
        self.report_type_var = tk.StringVar(value="æ—¥æŠ¥")
        self.start_date_var = tk.StringVar(value=datetime.datetime.now().strftime("%Y-%m-%d"))
        self.end_date_var = tk.StringVar(value=datetime.datetime.now().strftime("%Y-%m-%d"))
        self.clusters_var = tk.StringVar(value="default")

        # é˜ˆå€¼é…ç½®
        self.cpu_threshold_var = tk.DoubleVar(value=85.0)
        self.memory_threshold_var = tk.DoubleVar(value=90.0)

        # è¾“å‡ºé…ç½®
        self.output_text_var = tk.BooleanVar(value=True)
        self.output_excel_var = tk.BooleanVar(value=True)
        self.output_path_var = tk.StringVar(value="./reports/")

        # çŠ¶æ€
        self.status_var = tk.StringVar(value="å°±ç»ª")

    def create_widgets(self):
        """åˆ›å»ºç•Œé¢ç»„ä»¶"""
        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # é…ç½®æƒé‡
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(1, weight=1)

        current_row = 0

        # æ ‡é¢˜
        title_label = ttk.Label(main_frame, text="Nginxç›‘æ§æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ", style='Title.TLabel')
        title_label.grid(row=current_row, column=0, columnspan=3, pady=(0, 20))
        current_row += 1

        # è¿æ¥é…ç½®åŒºåŸŸ
        self.create_connection_section(main_frame, current_row)
        current_row += 6

        # æŠ¥å‘Šé…ç½®åŒºåŸŸ
        self.create_report_section(main_frame, current_row)
        current_row += 8

        # é˜ˆå€¼é…ç½®åŒºåŸŸ
        self.create_threshold_section(main_frame, current_row)
        current_row += 3

        # è¾“å‡ºé…ç½®åŒºåŸŸ
        self.create_output_section(main_frame, current_row)
        current_row += 4

        # æ“ä½œæŒ‰é’®åŒºåŸŸ
        self.create_action_section(main_frame, current_row)
        current_row += 2

        # çŠ¶æ€æ 
        self.create_status_section(main_frame, current_row)

    def create_connection_section(self, parent, start_row):
        """åˆ›å»ºè¿æ¥é…ç½®åŒºåŸŸ"""
        # æ ‡é¢˜
        conn_label = ttk.Label(parent, text="ğŸ”— è¿æ¥é…ç½®", style='Section.TLabel')
        conn_label.grid(row=start_row, column=0, columnspan=3, sticky=tk.W, pady=(10, 5))

        # æœåŠ¡å™¨åœ°å€
        ttk.Label(parent, text="æœåŠ¡å™¨åœ°å€:").grid(row=start_row + 1, column=0, sticky=tk.W, pady=2)
        url_entry = ttk.Entry(parent, textvariable=self.url_var, width=40)
        url_entry.grid(row=start_row + 1, column=1, sticky=(tk.W, tk.E), pady=2, padx=(5, 0))

        # ç”¨æˆ·å
        ttk.Label(parent, text="ç”¨æˆ·å:").grid(row=start_row + 2, column=0, sticky=tk.W, pady=2)
        username_entry = ttk.Entry(parent, textvariable=self.username_var, width=40)
        username_entry.grid(row=start_row + 2, column=1, sticky=(tk.W, tk.E), pady=2, padx=(5, 0))

        # å¯†ç 
        ttk.Label(parent, text="å¯†ç :").grid(row=start_row + 3, column=0, sticky=tk.W, pady=2)
        password_entry = ttk.Entry(parent, textvariable=self.password_var, show="*", width=40)
        password_entry.grid(row=start_row + 3, column=1, sticky=(tk.W, tk.E), pady=2, padx=(5, 0))

        # æ•°æ®æºID
        ttk.Label(parent, text="æ•°æ®æºID:").grid(row=start_row + 4, column=0, sticky=tk.W, pady=2)
        datasource_entry = ttk.Entry(parent, textvariable=self.datasource_var, width=40)
        datasource_entry.grid(row=start_row + 4, column=1, sticky=(tk.W, tk.E), pady=2, padx=(5, 0))

        # è¿æ¥æµ‹è¯•æŒ‰é’®
        test_btn = ttk.Button(parent, text="æµ‹è¯•è¿æ¥", command=self.test_connection)
        test_btn.grid(row=start_row + 1, column=2, rowspan=2, padx=(10, 0), pady=2)

    def create_report_section(self, parent, start_row):
        """åˆ›å»ºæŠ¥å‘Šé…ç½®åŒºåŸŸ"""
        # æ ‡é¢˜
        report_label = ttk.Label(parent, text="ğŸ“Š æŠ¥å‘Šé…ç½®", style='Section.TLabel')
        report_label.grid(row=start_row, column=0, columnspan=3, sticky=tk.W, pady=(10, 5))

        # æŠ¥å‘Šç±»å‹
        ttk.Label(parent, text="æŠ¥å‘Šç±»å‹:").grid(row=start_row + 1, column=0, sticky=tk.W, pady=2)
        report_type_combo = ttk.Combobox(parent, textvariable=self.report_type_var,
                                         values=["æ—¥æŠ¥", "å‘¨æŠ¥", "æœˆæŠ¥", "è‡ªå®šä¹‰"], state="readonly")
        report_type_combo.grid(row=start_row + 1, column=1, sticky=(tk.W, tk.E), pady=2, padx=(5, 0))
        report_type_combo.bind('<<ComboboxSelected>>', self.on_report_type_changed)

        # å¼€å§‹æ—¥æœŸ
        ttk.Label(parent, text="å¼€å§‹æ—¥æœŸ:").grid(row=start_row + 2, column=0, sticky=tk.W, pady=2)
        start_date_entry = ttk.Entry(parent, textvariable=self.start_date_var, width=40)
        start_date_entry.grid(row=start_row + 2, column=1, sticky=(tk.W, tk.E), pady=2, padx=(5, 0))

        # ç»“æŸæ—¥æœŸï¼ˆè‡ªå®šä¹‰æ—¶é—´æ®µæ—¶æ˜¾ç¤ºï¼‰
        self.end_date_label = ttk.Label(parent, text="ç»“æŸæ—¥æœŸ:")
        self.end_date_entry = ttk.Entry(parent, textvariable=self.end_date_var, width=40)

        # é›†ç¾¤é€‰æ‹©
        ttk.Label(parent, text="é›†ç¾¤åˆ—è¡¨:").grid(row=start_row + 4, column=0, sticky=tk.W, pady=2)
        clusters_entry = ttk.Entry(parent, textvariable=self.clusters_var, width=40)
        clusters_entry.grid(row=start_row + 4, column=1, sticky=(tk.W, tk.E), pady=2, padx=(5, 0))

        # è¯´æ˜æ ‡ç­¾
        help_label = ttk.Label(parent, text="æç¤º: é›†ç¾¤åç§°ç”¨é€—å·åˆ†éš”ï¼Œæ—¥æœŸæ ¼å¼: YYYY-MM-DD",
                               font=('Arial', 8), foreground='gray')
        help_label.grid(row=start_row + 5, column=1, sticky=tk.W, pady=2, padx=(5, 0))

    def create_threshold_section(self, parent, start_row):
        """åˆ›å»ºé˜ˆå€¼é…ç½®åŒºåŸŸ"""
        # æ ‡é¢˜
        threshold_label = ttk.Label(parent, text="âš ï¸ é˜ˆå€¼é…ç½®", style='Section.TLabel')
        threshold_label.grid(row=start_row, column=0, columnspan=3, sticky=tk.W, pady=(10, 5))

        # CPUé˜ˆå€¼
        ttk.Label(parent, text="CPUå‘Šè­¦é˜ˆå€¼(%):").grid(row=start_row + 1, column=0, sticky=tk.W, pady=2)
        cpu_spinbox = ttk.Spinbox(parent, from_=0, to=100, textvariable=self.cpu_threshold_var,
                                  increment=5, width=10)
        cpu_spinbox.grid(row=start_row + 1, column=1, sticky=tk.W, pady=2, padx=(5, 0))

        # å†…å­˜é˜ˆå€¼
        ttk.Label(parent, text="å†…å­˜å‘Šè­¦é˜ˆå€¼(%):").grid(row=start_row + 2, column=0, sticky=tk.W, pady=2)
        memory_spinbox = ttk.Spinbox(parent, from_=0, to=100, textvariable=self.memory_threshold_var,
                                     increment=5, width=10)
        memory_spinbox.grid(row=start_row + 2, column=1, sticky=tk.W, pady=2, padx=(5, 0))

    def create_output_section(self, parent, start_row):
        """åˆ›å»ºè¾“å‡ºé…ç½®åŒºåŸŸ"""
        # æ ‡é¢˜
        output_label = ttk.Label(parent, text="ğŸ“ è¾“å‡ºé…ç½®", style='Section.TLabel')
        output_label.grid(row=start_row, column=0, columnspan=3, sticky=tk.W, pady=(10, 5))

        # è¾“å‡ºæ ¼å¼
        format_frame = ttk.Frame(parent)
        format_frame.grid(row=start_row + 1, column=1, sticky=(tk.W, tk.E), pady=2, padx=(5, 0))

        ttk.Label(parent, text="è¾“å‡ºæ ¼å¼:").grid(row=start_row + 1, column=0, sticky=tk.W, pady=2)
        ttk.Checkbutton(format_frame, text="æ–‡æœ¬æŠ¥å‘Š", variable=self.output_text_var).grid(row=0, column=0, sticky=tk.W)
        ttk.Checkbutton(format_frame, text="ExcelæŠ¥è¡¨", variable=self.output_excel_var).grid(row=0, column=1,
                                                                                             sticky=tk.W, padx=(20, 0))

        # è¾“å‡ºè·¯å¾„
        ttk.Label(parent, text="è¾“å‡ºè·¯å¾„:").grid(row=start_row + 2, column=0, sticky=tk.W, pady=2)
        path_frame = ttk.Frame(parent)
        path_frame.grid(row=start_row + 2, column=1, sticky=(tk.W, tk.E), pady=2, padx=(5, 0))
        path_frame.columnconfigure(0, weight=1)

        path_entry = ttk.Entry(path_frame, textvariable=self.output_path_var)
        path_entry.grid(row=0, column=0, sticky=(tk.W, tk.E))

        browse_btn = ttk.Button(path_frame, text="æµè§ˆ", command=self.browse_output_path)
        browse_btn.grid(row=0, column=1, padx=(5, 0))

    def create_action_section(self, parent, start_row):
        """åˆ›å»ºæ“ä½œæŒ‰é’®åŒºåŸŸ"""
        action_frame = ttk.Frame(parent)
        action_frame.grid(row=start_row, column=0, columnspan=3, pady=(20, 10))

        # ç”ŸæˆæŠ¥å‘ŠæŒ‰é’®
        generate_btn = ttk.Button(action_frame, text="ğŸš€ ç”ŸæˆæŠ¥å‘Š",
                                  command=self.generate_report, style='Accent.TButton')
        generate_btn.pack(side=tk.LEFT, padx=(0, 10))

        # åœæ­¢æŒ‰é’®
        self.stop_btn = ttk.Button(action_frame, text="â¹ï¸ åœæ­¢",
                                   command=self.stop_generation, state=tk.DISABLED)
        self.stop_btn.pack(side=tk.LEFT, padx=(0, 10))

        # æ¸…ç©ºæ—¥å¿—æŒ‰é’®
        clear_btn = ttk.Button(action_frame, text="ğŸ—‘ï¸ æ¸…ç©ºæ—¥å¿—", command=self.clear_log)
        clear_btn.pack(side=tk.LEFT)

    def create_status_section(self, parent, start_row):
        """åˆ›å»ºçŠ¶æ€æ åŒºåŸŸ"""
        status_frame = ttk.LabelFrame(parent, text="è¿è¡ŒçŠ¶æ€", padding="5")
        status_frame.grid(row=start_row, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(10, 0))
        status_frame.columnconfigure(0, weight=1)
        status_frame.rowconfigure(1, weight=1)

        # çŠ¶æ€æ ‡ç­¾
        status_label = ttk.Label(status_frame, textvariable=self.status_var)
        status_label.grid(row=0, column=0, sticky=tk.W, pady=(0, 5))

        # è¿›åº¦æ¡
        self.progress = ttk.Progressbar(status_frame, mode='indeterminate')
        self.progress.grid(row=0, column=1, sticky=(tk.W, tk.E), padx=(10, 0))

        # æ—¥å¿—æ–‡æœ¬æ¡†
        log_frame = ttk.Frame(status_frame)
        log_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(5, 0))
        log_frame.columnconfigure(0, weight=1)
        log_frame.rowconfigure(0, weight=1)

        self.log_text = tk.Text(log_frame, height=8, wrap=tk.WORD)
        log_scrollbar = ttk.Scrollbar(log_frame, orient=tk.VERTICAL, command=self.log_text.yview)
        self.log_text.configure(yscrollcommand=log_scrollbar.set)

        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        log_scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))

    def on_report_type_changed(self, event=None):
        """æŠ¥å‘Šç±»å‹æ”¹å˜æ—¶çš„å¤„ç†"""
        if self.report_type_var.get() == "è‡ªå®šä¹‰":
            # æ˜¾ç¤ºç»“æŸæ—¥æœŸè¾“å…¥
            self.end_date_label.grid(row=3, column=0, sticky=tk.W, pady=2)
            self.end_date_entry.grid(row=3, column=1, sticky=(tk.W, tk.E), pady=2, padx=(5, 0))
        else:
            # éšè—ç»“æŸæ—¥æœŸè¾“å…¥
            self.end_date_label.grid_remove()
            self.end_date_entry.grid_remove()

    def browse_output_path(self):
        """æµè§ˆè¾“å‡ºè·¯å¾„"""
        path = filedialog.askdirectory(initialdir=self.output_path_var.get())
        if path:
            self.output_path_var.set(path)

    def test_connection(self):
        """æµ‹è¯•è¿æ¥"""
        try:
            self.log_message("ğŸ”„ æ­£åœ¨æµ‹è¯•è¿æ¥...")
            self.status_var.set("æµ‹è¯•è¿æ¥ä¸­...")
            self.progress.start()

            # åœ¨åå°çº¿ç¨‹ä¸­æµ‹è¯•è¿æ¥
            def test_worker():
                try:
                    client = NightingaleClient(
                        self.url_var.get().strip(),
                        self.username_var.get().strip(),
                        self.password_var.get().strip()
                    )

                    # æ‰§è¡Œç®€å•æŸ¥è¯¢æµ‹è¯•
                    result = client.query_instant("up", int(datetime.datetime.now().timestamp()))

                    if result and "data" in result:
                        self.root.after(0, lambda: self.on_connection_success())
                    else:
                        self.root.after(0, lambda: self.on_connection_error("è¿æ¥æˆåŠŸä½†æŸ¥è¯¢è¿”å›ç©ºç»“æœ"))

                except Exception as e:
                    self.root.after(0, lambda: self.on_connection_error(str(e)))

            threading.Thread(target=test_worker, daemon=True).start()

        except Exception as e:
            self.on_connection_error(f"è¿æ¥æµ‹è¯•å¤±è´¥: {e}")

    def on_connection_success(self):
        """è¿æ¥æˆåŠŸå›è°ƒ"""
        self.progress.stop()
        self.status_var.set("è¿æ¥æµ‹è¯•æˆåŠŸ")
        self.log_message("âœ… è¿æ¥æµ‹è¯•æˆåŠŸ")
        messagebox.showinfo("è¿æ¥æµ‹è¯•", "è¿æ¥æµ‹è¯•æˆåŠŸ!")

    def on_connection_error(self, error_msg):
        """è¿æ¥é”™è¯¯å›è°ƒ"""
        self.progress.stop()
        self.status_var.set("è¿æ¥æµ‹è¯•å¤±è´¥")
        self.log_message(f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {error_msg}")
        messagebox.showerror("è¿æ¥æµ‹è¯•", f"è¿æ¥æµ‹è¯•å¤±è´¥:\n{error_msg}")

    def generate_report(self):
        """ç”ŸæˆæŠ¥å‘Š"""
        try:
            # éªŒè¯è¾“å…¥
            if not self.validate_inputs():
                return

            self.log_message("ğŸš€ å¼€å§‹ç”Ÿæˆç›‘æ§æŠ¥å‘Š...")
            self.status_var.set("æ­£åœ¨ç”ŸæˆæŠ¥å‘Š...")
            self.progress.start()
            self.stop_btn.config(state=tk.NORMAL)

            # åœ¨åå°çº¿ç¨‹ä¸­ç”ŸæˆæŠ¥å‘Š
            def generate_worker():
                try:
                    # åˆ›å»ºå®¢æˆ·ç«¯å’Œç”Ÿæˆå™¨
                    client = NightingaleClient(
                        self.url_var.get().strip(),
                        self.username_var.get().strip(),
                        self.password_var.get().strip()
                    )

                    generator = NginxReportGenerator(
                        client,
                        self.cpu_threshold_var.get(),
                        self.memory_threshold_var.get()
                    )

                    # è§£æå‚æ•°
                    clusters = [c.strip() for c in self.clusters_var.get().split(',') if c.strip()]
                    report_type = ReportType(self.report_type_var.get())
                    start_date = self.start_date_var.get()
                    end_date = self.end_date_var.get() if report_type == ReportType.CUSTOM else None

                    # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
                    if self.output_text_var.get():
                        self.root.after(0, lambda: self.log_message("ğŸ“ ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š..."))
                        reports = generator.generate_report(
                            start_date, clusters, report_type, end_date
                        )

                        # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š
                        output_dir = self.output_path_var.get().strip()
                        if not os.path.exists(output_dir):
                            os.makedirs(output_dir)

                        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                        text_file = os.path.join(output_dir, f"monitoring_report_{timestamp}.txt")

                        with open(text_file, 'w', encoding='utf-8') as f:
                            f.write("\n\n".join(reports))

                        self.root.after(0, lambda: self.log_message(f"âœ… æ–‡æœ¬æŠ¥å‘Šå·²ä¿å­˜: {text_file}"))

                    # ç”ŸæˆExcelæŠ¥å‘Š
                    if self.output_excel_var.get():
                        self.root.after(0, lambda: self.log_message("ğŸ“Š ç”ŸæˆExcelæŠ¥å‘Š..."))
                        output_dir = self.output_path_var.get().strip()
                        if not os.path.exists(output_dir):
                            os.makedirs(output_dir)

                        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                        excel_file = os.path.join(output_dir, f"monitoring_report_{timestamp}.xlsx")

                        success = generator.export_to_excel(
                            start_date, clusters, report_type, end_date, excel_file
                        )

                        if success:
                            self.root.after(0, lambda: self.log_message(f"âœ… ExcelæŠ¥å‘Šå·²ä¿å­˜: {excel_file}"))
                        else:
                            self.root.after(0, lambda: self.log_message("âŒ ExcelæŠ¥å‘Šç”Ÿæˆå¤±è´¥"))

                    self.root.after(0, lambda: self.on_generation_complete())

                except Exception as e:
                    self.root.after(0, lambda: self.on_generation_error(str(e)))

            threading.Thread(target=generate_worker, daemon=True).start()

        except Exception as e:
            self.on_generation_error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")

    def validate_inputs(self):
        """éªŒè¯è¾“å…¥å‚æ•°"""
        if not self.url_var.get().strip():
            messagebox.showerror("è¾“å…¥é”™è¯¯", "è¯·è¾“å…¥æœåŠ¡å™¨åœ°å€")
            return False

        if not self.username_var.get().strip():
            messagebox.showerror("è¾“å…¥é”™è¯¯", "è¯·è¾“å…¥ç”¨æˆ·å")
            return False

        if not self.clusters_var.get().strip():
            messagebox.showerror("è¾“å…¥é”™è¯¯", "è¯·è¾“å…¥é›†ç¾¤åˆ—è¡¨")
            return False

        # éªŒè¯æ—¥æœŸæ ¼å¼
        try:
            datetime.datetime.strptime(self.start_date_var.get(), "%Y-%m-%d")
            if self.report_type_var.get() == "è‡ªå®šä¹‰":
                datetime.datetime.strptime(self.end_date_var.get(), "%Y-%m-%d")
        except ValueError:
            messagebox.showerror("è¾“å…¥é”™è¯¯", "æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
            return False

        if not self.output_text_var.get() and not self.output_excel_var.get():
            messagebox.showerror("è¾“å…¥é”™è¯¯", "è¯·è‡³å°‘é€‰æ‹©ä¸€ç§è¾“å‡ºæ ¼å¼")
            return False

        return True

    def on_generation_complete(self):
        """æŠ¥å‘Šç”Ÿæˆå®Œæˆå›è°ƒ"""
        self.progress.stop()
        self.status_var.set("æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        self.stop_btn.config(state=tk.DISABLED)
        self.log_message("ğŸ‰ æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
        messagebox.showinfo("ç”Ÿæˆå®Œæˆ", "ç›‘æ§æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")

    def on_generation_error(self, error_msg):
        """æŠ¥å‘Šç”Ÿæˆé”™è¯¯å›è°ƒ"""
        self.progress.stop()
        self.status_var.set("æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
        self.stop_btn.config(state=tk.DISABLED)
        self.log_message(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {error_msg}")
        messagebox.showerror("ç”Ÿæˆå¤±è´¥", f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥:\n{error_msg}")

    def stop_generation(self):
        """åœæ­¢æŠ¥å‘Šç”Ÿæˆ"""
        self.progress.stop()
        self.status_var.set("æ“ä½œå·²åœæ­¢")
        self.stop_btn.config(state=tk.DISABLED)
        self.log_message("â¹ï¸ æ“ä½œå·²åœæ­¢")

    def clear_log(self):
        """æ¸…ç©ºæ—¥å¿—"""
        self.log_text.delete(1.0, tk.END)
        self.log_message("æ—¥å¿—å·²æ¸…ç©º")

    def log_message(self, message):
        """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
        timestamp = datetime.datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {message}\n"

        self.log_text.insert(tk.END, log_entry)
        self.log_text.see(tk.END)

        # é™åˆ¶æ—¥å¿—è¡Œæ•°
        lines = self.log_text.get(1.0, tk.END).split('\n')
        if len(lines) > 100:
            self.log_text.delete(1.0, f"{len(lines) - 100}.0")


def main():
    """ä¸»å‡½æ•° - å¯åŠ¨GUIåº”ç”¨ç¨‹åº"""
    try:
        # åˆ›å»ºä¸»çª—å£
        root = tk.Tk()

        # å°è¯•è®¾ç½®å›¾æ ‡ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
        try:
            root.iconbitmap('icon.ico')
        except:
            # å¦‚æœå›¾æ ‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
            pass

        # åˆ›å»ºåº”ç”¨ç¨‹åºå®ä¾‹
        app = NginxMonitoringGUI(root)

        # è®¾ç½®çª—å£å…³é—­æ—¶çš„å¤„ç†å‡½æ•°
        def on_closing():
            """çª—å£å…³é—­æ—¶çš„æ¸…ç†å·¥ä½œ"""
            try:
                # åœæ­¢è¿›åº¦æ¡ï¼ˆå¦‚æœæ­£åœ¨è¿è¡Œï¼‰
                app.progress.stop()

                # è®°å½•å…³é—­æ—¥å¿—
                app.log_message("ğŸ”„ æ­£åœ¨å…³é—­åº”ç”¨ç¨‹åº...")

                # ç¡®ä¿æ‰€æœ‰çº¿ç¨‹ç»“æŸ
                root.quit()  # é€€å‡ºä¸»å¾ªç¯
                root.destroy()  # é”€æ¯çª—å£

            except Exception as e:
                print(f"å…³é—­åº”ç”¨ç¨‹åºæ—¶å‡ºé”™: {e}")
                root.destroy()

        # ç»‘å®šçª—å£å…³é—­äº‹ä»¶
        root.protocol("WM_DELETE_WINDOW", on_closing)

        # è®¾ç½®çª—å£æœ€å°å°ºå¯¸
        root.minsize(600, 500)

        # å±…ä¸­æ˜¾ç¤ºçª—å£
        center_window(root)

        # å¯åŠ¨åº”ç”¨ç¨‹åºæ—¥å¿—
        app.log_message("ğŸš€ Nginxç›‘æ§æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿå·²å¯åŠ¨")
        app.log_message("ğŸ“ è¯·å…ˆé…ç½®è¿æ¥å‚æ•°å¹¶æµ‹è¯•è¿æ¥")

        # å¯åŠ¨ä¸»äº‹ä»¶å¾ªç¯
        root.mainloop()

    except Exception as e:
        # å¦‚æœå¯åŠ¨å¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        import traceback
        error_msg = f"å¯åŠ¨åº”ç”¨ç¨‹åºå¤±è´¥: {e}\n\nè¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}"
        print(error_msg)

        # å°è¯•æ˜¾ç¤ºé”™è¯¯å¯¹è¯æ¡†
        try:
            import tkinter.messagebox as messagebox
            messagebox.showerror("å¯åŠ¨é”™è¯¯", error_msg)
        except:
            pass


def center_window(window):
    """å°†çª—å£å±…ä¸­æ˜¾ç¤º"""
    try:
        # æ›´æ–°çª—å£ä»¥è·å–å®é™…å°ºå¯¸
        window.update_idletasks()

        # è·å–çª—å£å°ºå¯¸
        width = window.winfo_width()
        height = window.winfo_height()

        # è·å–å±å¹•å°ºå¯¸
        screen_width = window.winfo_screenwidth()
        screen_height = window.winfo_screenheight()

        # è®¡ç®—å±…ä¸­ä½ç½®
        x = (screen_width - width) // 2
        y = (screen_height - height) // 2

        # è®¾ç½®çª—å£ä½ç½®
        window.geometry(f"{width}x{height}+{x}+{y}")

    except Exception as e:
        print(f"çª—å£å±…ä¸­å¤±è´¥: {e}")


def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    import logging

    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = "./logs"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)

    # é…ç½®æ—¥å¿—æ ¼å¼
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    date_format = '%Y-%m-%d %H:%M:%S'

    # è®¾ç½®æ—¥å¿—æ–‡ä»¶åï¼ˆåŒ…å«æ—¥æœŸï¼‰
    log_filename = os.path.join(log_dir, f"nginx_monitoring_{datetime.datetime.now().strftime('%Y%m%d')}.log")

    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        datefmt=date_format,
        handlers=[
            logging.FileHandler(log_filename, encoding='utf-8'),
            logging.StreamHandler()  # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
        ]
    )

    return logging.getLogger(__name__)


if __name__ == "__main__":
    """ç¨‹åºå…¥å£ç‚¹"""


    # è®¾ç½®å…¨å±€å¼‚å¸¸å¤„ç†
    def handle_exception(exc_type, exc_value, exc_traceback):
        """å…¨å±€å¼‚å¸¸å¤„ç†å‡½æ•°"""
        if issubclass(exc_type, KeyboardInterrupt):
            # å¤„ç† Ctrl+C ä¸­æ–­
            print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
            sys.exit(0)

        # è®°å½•å…¶ä»–å¼‚å¸¸
        import traceback
        error_msg = ''.join(traceback.format_exception(exc_type, exc_value, exc_traceback))
        print(f"æœªå¤„ç†çš„å¼‚å¸¸: {error_msg}")

        # å°è¯•å†™å…¥æ—¥å¿—æ–‡ä»¶
        try:
            with open("error.log", "a", encoding="utf-8") as f:
                f.write(f"\n[{datetime.datetime.now()}] æœªå¤„ç†çš„å¼‚å¸¸:\n{error_msg}\n")
        except:
            pass


    # å¯¼å…¥å¿…è¦çš„æ¨¡å—
    import sys
    import os

    # è®¾ç½®å¼‚å¸¸å¤„ç†
    sys.excepthook = handle_exception

    try:
        # è®¾ç½®æ—¥å¿—
        logger.info("=" * 50)
        logger.info("Nginxç›‘æ§æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿå¯åŠ¨")
        logger.info("=" * 50)

        # æ£€æŸ¥Pythonç‰ˆæœ¬
        if sys.version_info < (3, 6):
            error_msg = "æ­¤ç¨‹åºéœ€è¦Python 3.6æˆ–æ›´é«˜ç‰ˆæœ¬"
            print(error_msg)
            logger.error(error_msg)
            sys.exit(1)

        # æ£€æŸ¥å¿…è¦çš„æ¨¡å—
        required_modules = [
            'tkinter', 'requests', 'pandas', 'openpyxl',
            'datetime', 'json', 'threading', 'queue'
        ]

        missing_modules = []
        for module in required_modules:
            try:
                __import__(module)
            except ImportError:
                missing_modules.append(module)

        if missing_modules:
            error_msg = f"ç¼ºå°‘å¿…è¦çš„Pythonæ¨¡å—: {', '.join(missing_modules)}"
            print(error_msg)
            print("è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…:")
            print(f"pip install {' '.join(missing_modules)}")
            logger.error(error_msg)
            sys.exit(1)

        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        directories = ["./reports", "./logs", "./temp"]
        for directory in directories:
            if not os.path.exists(directory):
                os.makedirs(directory)
                logger.info(f"åˆ›å»ºç›®å½•: {directory}")

        # å¯åŠ¨ä¸»ç¨‹åº
        logger.info("å¯åŠ¨GUIç•Œé¢...")
        main()

    except KeyboardInterrupt:
        print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        logger.info("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)

    except Exception as e:
        error_msg = f"ç¨‹åºå¯åŠ¨å¤±è´¥: {e}"
        print(error_msg)
        try:
            logger.error(error_msg, exc_info=True)
        except:
            pass
        sys.exit(1)

    finally:
        try:
            logger.info("ç¨‹åºæ­£å¸¸é€€å‡º")
            logger.info("=" * 50)
        except:
            pass