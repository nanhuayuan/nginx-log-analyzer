#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Nginxé›†ç¾¤ç›‘æ§æ—¥æŠ¥è‡ªåŠ¨åŒ–ç”Ÿæˆå™¨ - ç»¼åˆç‰ˆ
åŸºäºå¤œèº(Nightingale) v8.0.0ç›‘æ§æ•°æ®ç”Ÿæˆå…¨é¢çš„ç³»ç»Ÿè¿è¡Œæ±‡æŠ¥

åŠŸèƒ½ç‰¹æ€§:
- æ”¯æŒå¤šé›†ç¾¤ç›‘æ§ç»Ÿè®¡
- è‡ªåŠ¨ç”Ÿæˆæ—¥æŠ¥/å‘¨æŠ¥/æœˆæŠ¥
- åŒæ¯”ç¯æ¯”æ•°æ®å¯¹æ¯”
- é¢å‘æŠ€æœ¯å’ŒéæŠ€æœ¯é¢†å¯¼çš„åŒé‡æ±‡æŠ¥æ ¼å¼
- å¼‚å¸¸äº‹ä»¶å’Œå‘Šè­¦ä¿¡æ¯ç»Ÿè®¡
- çµæ´»çš„æ—¥æœŸé€‰æ‹©å’Œè¾“å‡ºæ ¼å¼
"""

import requests
import json
import datetime
import argparse
from typing import Dict, List, Optional, Tuple, Any
import sys
import logging
from dataclasses import dataclass
from enum import Enum

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('../nginx_report.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class ReportType(Enum):
    DAILY = "daily"
    WEEKLY = "weekly"
    MONTHLY = "monthly"


@dataclass
class MetricResult:
    """ç›‘æ§æŒ‡æ ‡ç»“æœæ•°æ®ç±»"""
    value: float
    timestamp: Optional[int] = None
    unit: str = ""
    status: str = "normal"  # normal, warning, critical


class NightingaleClient:
    """å¤œèºAPIå®¢æˆ·ç«¯"""

    def __init__(self, base_url: str, datasource_id: int, username: str = None, password: str = None):
        """
        åˆå§‹åŒ–å¤œèºå®¢æˆ·ç«¯

        Args:
            base_url: å¤œèºæœåŠ¡åœ°å€
            datasource_id: Prometheusæ•°æ®æºID
            username: ç”¨æˆ·åï¼ˆå¯é€‰ï¼‰
            password: å¯†ç ï¼ˆå¯é€‰ï¼‰
        """
        self.base_url = base_url.rstrip('/')
        self.datasource_id = datasource_id
        self.session = requests.Session()

        # è®¾ç½®é»˜è®¤è¶…æ—¶å’Œé‡è¯•
        self.session.timeout = 30

        # å¦‚æœæä¾›è®¤è¯ä¿¡æ¯åˆ™ç™»å½•
        if username and password:
            self._authenticate(username, password)

    def _authenticate(self, username: str, password: str) -> bool:
        """ç”¨æˆ·è®¤è¯ç™»å½•"""
        login_url = f"{self.base_url}/api/n9e/auth/login"
        login_data = {"username": username, "password": password}

        try:
            response = self.session.post(login_url, json=login_data, timeout=10)
            if response.status_code == 200:
                return True
            else:
                return False
        except Exception as e:
            return False

    def query_range(self, query: str, start_time: int, end_time: int, step: str = "60s") -> Dict:
        """åŒºé—´æŸ¥è¯¢"""
        url = f"{self.base_url}/api/n9e/proxy/1/api/v1/query_range"
        params = {
            "query": query,
            "start": start_time,
            "end": end_time,
            "step": step,
            "datasource_ids": [self.datasource_id]
        }

        try:
            response = self.session.get(url, params=params)
            if response.status_code == 200:
                return response.json()
            else:
                logger.warning(f"æŸ¥è¯¢å¤±è´¥: {query[:50]}... - {response.status_code}")
                return {"data": {"result": []}}
        except Exception as e:
            logger.error(f"æŸ¥è¯¢å¼‚å¸¸: {query[:50]}... - {e}")
            return {"data": {"result": []}}

    def query_instant(self, query: str, timestamp: int = None) -> Dict:
        """å³æ—¶æŸ¥è¯¢"""
        url = f"{self.base_url}/api/n9e/proxy/1/api/v1/query"
        params = {
            "query": query,
            "datasource_ids": [self.datasource_id]
        }

        if timestamp:
            params["time"] = timestamp

        try:
            response = self.session.get(url, params=params)
            if response.status_code == 200:
                return response.json()
            else:
                logger.warning(f"å³æ—¶æŸ¥è¯¢å¤±è´¥: {query[:50]}...")
                return {"data": {"result": []}}
        except Exception as e:
            logger.error(f"å³æ—¶æŸ¥è¯¢å¼‚å¸¸: {query[:50]}... - {e}")
            return {"data": {"result": []}}


class MetricsExtractor:
    @staticmethod
    def extract_max_with_time(result: Dict) -> Tuple[float, str]:
        """æå–æœ€å¤§å€¼å’Œå¯¹åº”çš„æ—¶é—´æˆ³"""
        max_value = 0.0
        max_time = "N/A"

        for series in result.get("data", {}).get("result", []):
            for timestamp, value in series.get("values", []):
                try:
                    val = float(value)
                    if val > max_value:
                        max_value = val
                        # æ ¼å¼åŒ–æ—¶é—´ä¸ºæ›´è¯¦ç»†çš„æ ¼å¼
                        max_time = datetime.datetime.fromtimestamp(timestamp).strftime("%m-%d %H:%M")
                except (ValueError, TypeError):
                    continue

        return max_value, max_time

    @staticmethod
    def extract_min_with_time(result: Dict) -> Tuple[float, str]:
        """æå–æœ€å°å€¼å’Œå¯¹åº”çš„æ—¶é—´æˆ³"""
        min_value = float('inf')
        min_time = "N/A"

        for series in result.get("data", {}).get("result", []):
            for timestamp, value in series.get("values", []):
                try:
                    val = float(value)
                    if val < min_value:
                        min_value = val
                        min_time = datetime.datetime.fromtimestamp(timestamp).strftime("%m-%d %H:%M")
                except (ValueError, TypeError):
                    continue

        return min_value if min_value != float('inf') else 0.0, min_time

    @staticmethod
    def extract_sum(result: Dict) -> float:
        """æå–æ€»å’Œå€¼"""
        total = 0.0
        for series in result.get("data", {}).get("result", []):
            values = series.get("values", [])
            if values:
                try:
                    total += float(values[-1][1])
                except (ValueError, TypeError, IndexError):
                    continue
        return total

    @staticmethod
    def extract_avg(result: Dict) -> float:
        """æå–å¹³å‡å€¼"""
        total_sum = 0.0
        count = 0

        for series in result.get("data", {}).get("result", []):
            for timestamp, value in series.get("values", []):
                try:
                    total_sum += float(value)
                    count += 1
                except (ValueError, TypeError):
                    continue

        return total_sum / count if count > 0 else 0.0

    @staticmethod
    def extract_instant_value(result: Dict) -> float:
        """æå–å³æ—¶å€¼"""
        for series in result.get("data", {}).get("result", []):
            try:
                return float(series["value"][1])
            except (KeyError, ValueError, TypeError, IndexError):
                continue
        return 0.0


class NginxReportGenerator:
    """Nginxç›‘æ§æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, client: NightingaleClient):
        self.client = client
        self.extractor = MetricsExtractor()

        # é»˜è®¤é›†ç¾¤é…ç½®ï¼ˆå¯é€šè¿‡å‚æ•°è¦†ç›–ï¼‰
        self.default_clusters = ["self-prod-nginx", "zgtapp-prod-nginx"]

    def get_time_ranges(self, target_date: str, report_type: ReportType = ReportType.DAILY) -> Dict[
        str, Tuple[int, int]]:
        """
        è·å–æŠ¥å‘Šæ—¶é—´èŒƒå›´

        Returns:
            {
                "current": (start, end),     # å½“å‰å‘¨æœŸ
                "previous": (start, end),    # ä¸Šä¸€å‘¨æœŸï¼ˆç”¨äºç¯æ¯”ï¼‰
                "same_period_last": (start, end)  # åŒæœŸï¼ˆç”¨äºåŒæ¯”ï¼‰
            }
        """
        try:
            base_date = datetime.datetime.strptime(target_date, "%Y-%m-%d")
        except ValueError:
            logger.error(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {target_date}")
            sys.exit(1)

        ranges = {}

        if report_type == ReportType.DAILY:
            # å½“å‰æ—¥æœŸ
            current_start = base_date.replace(hour=0, minute=0, second=0, microsecond=0)
            current_end = base_date.replace(hour=23, minute=59, second=59, microsecond=0)
            ranges["current"] = (int(current_start.timestamp()), int(current_end.timestamp()))

            # å‰ä¸€å¤©ï¼ˆç¯æ¯”ï¼‰
            prev_date = base_date - datetime.timedelta(days=1)
            prev_start = prev_date.replace(hour=0, minute=0, second=0, microsecond=0)
            prev_end = prev_date.replace(hour=23, minute=59, second=59, microsecond=0)
            ranges["previous"] = (int(prev_start.timestamp()), int(prev_end.timestamp()))

            # ä¸Šå‘¨åŒä¸€å¤©ï¼ˆåŒæ¯”ï¼‰
            same_date = base_date - datetime.timedelta(days=7)
            same_start = same_date.replace(hour=0, minute=0, second=0, microsecond=0)
            same_end = same_date.replace(hour=23, minute=59, second=59, microsecond=0)
            ranges["same_period_last"] = (int(same_start.timestamp()), int(same_end.timestamp()))

        elif report_type == ReportType.WEEKLY:
            # å½“å‰å‘¨ï¼ˆå‘¨ä¸€åˆ°å‘¨æ—¥ï¼‰
            monday = base_date - datetime.timedelta(days=base_date.weekday())
            current_start = monday.replace(hour=0, minute=0, second=0, microsecond=0)
            current_end = (monday + datetime.timedelta(days=6)).replace(hour=23, minute=59, second=59, microsecond=0)
            ranges["current"] = (int(current_start.timestamp()), int(current_end.timestamp()))

            # å‰ä¸€å‘¨
            prev_monday = monday - datetime.timedelta(days=7)
            prev_start = prev_monday.replace(hour=0, minute=0, second=0, microsecond=0)
            prev_end = (prev_monday + datetime.timedelta(days=6)).replace(hour=23, minute=59, second=59, microsecond=0)
            ranges["previous"] = (int(prev_start.timestamp()), int(prev_end.timestamp()))

            # å»å¹´åŒæœŸ
            same_monday = monday - datetime.timedelta(days=365)
            same_start = same_monday.replace(hour=0, minute=0, second=0, microsecond=0)
            same_end = (same_monday + datetime.timedelta(days=6)).replace(hour=23, minute=59, second=59, microsecond=0)
            ranges["same_period_last"] = (int(same_start.timestamp()), int(same_end.timestamp()))

        return ranges

    def collect_core_metrics(self, cluster: str, start_time: int, end_time: int) -> Dict[str, MetricResult]:
        duration = end_time - start_time
        metrics = {}

        logger.info(f"ğŸ“Š æ”¶é›†é›†ç¾¤ {cluster} çš„æ ¸å¿ƒä¸šåŠ¡æŒ‡æ ‡...")

        # å¯ç”¨æ€§è®¡ç®—ä¿æŒä¸å˜
        uptime_query = f'count(nginx_active{{cluster="{cluster}"}} > 0) / count(nginx_active{{cluster="{cluster}"}}) '
        uptime_result = self.client.query_instant(uptime_query, end_time)
        min_uptime = self.extractor.extract_instant_value(uptime_result)
        availability = min(99.99, 100.0 - (1.0 / max(min_uptime, 1)) * 100)
        metrics["availability"] = MetricResult(
            value=availability,
            unit="%",
            status="normal" if availability >= 99.9 else "warning" if availability >= 99.0 else "critical"
        )

        # ä½¿ç”¨deriv()æ›¿ä»£increase()æ¥é¿å…å¹½çµè®¡æ•°å™¨é‡ç½®
        total_requests_query = f'sum(deriv(nginx_requests{{cluster="{cluster}"}}[{duration}s])) * {duration}'
        requests_result = self.client.query_instant(total_requests_query, end_time)
        total_requests = max(0, self.extractor.extract_instant_value(requests_result))  # ç¡®ä¿éè´Ÿå€¼
        metrics["total_requests"] = MetricResult(value=total_requests, unit="æ¬¡")

        # ä½¿ç”¨deriv()æ›¿ä»£irate()
        qps_query = f'sum(deriv(nginx_requests{{cluster="{cluster}"}}[2m]))'
        qps_result = self.client.query_range(qps_query, start_time, end_time)
        qps_peak, qps_time = self.extractor.extract_max_with_time(qps_result)
        metrics["qps_peak"] = MetricResult(value=max(0, qps_peak), unit="req/s", timestamp=qps_time)

        qps_min, qps_min_time = self.extractor.extract_min_with_time(qps_result)
        metrics["qps_min"] = MetricResult(value=max(0, qps_min), unit="req/s", timestamp=qps_min_time)

        qps_avg = self.extractor.extract_avg(qps_result)
        metrics["qps_avg"] = MetricResult(value=max(0, qps_avg), unit="req/s")

        # ç½‘ç»œå¸¦å®½ä½¿ç”¨deriv()
        bandwidth_in_query = f'sum(deriv(net_bytes_recv{{cluster="{cluster}"}}[2m]) * 8) / 1000 / 1000 / 1000'
        bandwidth_out_query = f'sum(deriv(net_bytes_sent{{cluster="{cluster}"}}[2m]) * 8) / 1000 / 1000 / 1000'

        bandwidth_in_result = self.client.query_range(bandwidth_in_query, start_time, end_time)
        bandwidth_out_result = self.client.query_range(bandwidth_out_query, start_time, end_time)

        bandwidth_in_peak, bandwidth_in_time = self.extractor.extract_max_with_time(bandwidth_in_result)
        bandwidth_out_peak, bandwidth_out_time = self.extractor.extract_max_with_time(bandwidth_out_result)
        bandwidth_in_avg = self.extractor.extract_avg(bandwidth_in_result)
        bandwidth_out_avg = self.extractor.extract_avg(bandwidth_out_result)

        bandwidth_total_query = f'''sum(
            deriv(net_bytes_recv{{cluster="{cluster}"}}[2m]) * 8 + 
            deriv(net_bytes_sent{{cluster="{cluster}"}}[2m]) * 8
        ) / 1000 / 1000 / 1000'''
        bandwidth_total_result = self.client.query_range(bandwidth_total_query, start_time, end_time)
        bandwidth_peak, bandwidth_time = self.extractor.extract_max_with_time(bandwidth_total_result)
        bandwidth_avg = self.extractor.extract_avg(bandwidth_total_result)

        metrics["bandwidth_peak"] = MetricResult(value=max(0, bandwidth_peak), unit="Gbps", timestamp=bandwidth_time)
        metrics["bandwidth_avg"] = MetricResult(value=max(0, bandwidth_avg), unit="Gbps")
        metrics["bandwidth_in_peak"] = MetricResult(value=max(0, bandwidth_in_peak), unit="Gbps",
                                                    timestamp=bandwidth_in_time)
        metrics["bandwidth_out_peak"] = MetricResult(value=max(0, bandwidth_out_peak), unit="Gbps",
                                                     timestamp=bandwidth_out_time)
        metrics["bandwidth_in_avg"] = MetricResult(value=max(0, bandwidth_in_avg), unit="Gbps")
        metrics["bandwidth_out_avg"] = MetricResult(value=max(0, bandwidth_out_avg), unit="Gbps")

        # æµé‡ç»Ÿè®¡ä½¿ç”¨deriv()
        traffic_in_query = f'sum(deriv(net_bytes_recv{{cluster="{cluster}"}}[{duration}s])) * {duration} / 1024 / 1024 / 1024 / 1024'
        traffic_out_query = f'sum(deriv(net_bytes_sent{{cluster="{cluster}"}}[{duration}s])) * {duration} / 1024 / 1024 / 1024 / 1024'

        traffic_in_result = self.client.query_instant(traffic_in_query, end_time)
        traffic_out_result = self.client.query_instant(traffic_out_query, end_time)

        traffic_in = max(0, self.extractor.extract_instant_value(traffic_in_result))
        traffic_out = max(0, self.extractor.extract_instant_value(traffic_out_result))
        total_traffic = traffic_in + traffic_out

        metrics["total_traffic"] = MetricResult(value=total_traffic, unit="TB")
        metrics["traffic_in"] = MetricResult(value=traffic_in, unit="TB")
        metrics["traffic_out"] = MetricResult(value=traffic_out, unit="TB")

        return metrics

    def collect_anomaly_metrics(self, cluster: str, start_time: int, end_time: int) -> Dict[str, MetricResult]:
        duration = end_time - start_time
        metrics = {}

        logger.info(f"âš ï¸ æ”¶é›†é›†ç¾¤ {cluster} çš„å¼‚å¸¸äº‹ä»¶æŒ‡æ ‡...")

        # OOMäº‹ä»¶ç»Ÿè®¡ä½¿ç”¨deriv()æ›¿ä»£increase()
        oom_query = f'sum(deriv(kernel_vmstat_oom_kill{{cluster="{cluster}"}}[{duration}s])) * {duration}'
        oom_result = self.client.query_instant(oom_query, end_time)
        oom_count = max(0, self.extractor.extract_instant_value(oom_result))
        metrics["oom_events"] = MetricResult(
            value=oom_count,
            unit="æ¬¡",
            status="normal" if oom_count == 0 else "critical"
        )

        # é«˜CPUèŠ‚ç‚¹ç»Ÿè®¡
        high_cpu_query = f'count(cpu_usage_active{{cluster="{cluster}"}} > 85)'
        high_cpu_result = self.client.query_instant(high_cpu_query, end_time)
        high_cpu_nodes = self.extractor.extract_instant_value(high_cpu_result)
        metrics["high_cpu_nodes"] = MetricResult(
            value=high_cpu_nodes,
            unit="ä¸ª",
            status="normal" if high_cpu_nodes == 0 else "warning"
        )

        # é«˜å†…å­˜èŠ‚ç‚¹ç»Ÿè®¡
        high_mem_query = f'count(mem_used_percent{{cluster="{cluster}"}} > 90)'
        high_mem_result = self.client.query_instant(high_mem_query, end_time)
        high_mem_nodes = self.extractor.extract_instant_value(high_mem_result)
        metrics["high_memory_nodes"] = MetricResult(
            value=high_mem_nodes,
            unit="ä¸ª",
            status="normal" if high_mem_nodes == 0 else "warning"
        )

        # ç½‘ç»œé”™è¯¯ç»Ÿè®¡ä½¿ç”¨deriv()
        net_errors_query = f'sum(deriv(net_err_in{{cluster="{cluster}"}}[{duration}s]) + deriv(net_err_out{{cluster="{cluster}"}}[{duration}s])) * {duration}'
        net_errors_result = self.client.query_instant(net_errors_query, end_time)
        net_errors = max(0, self.extractor.extract_instant_value(net_errors_result))
        metrics["network_errors"] = MetricResult(
            value=net_errors,
            unit="ä¸ª",
            status="normal" if net_errors < 100 else "warning" if net_errors < 1000 else "critical"
        )

        return metrics

    def collect_system_metrics(self, cluster: str, start_time: int, end_time: int) -> Dict[str, MetricResult]:
        duration = end_time - start_time
        metrics = {}

        logger.info(f"ğŸ–¥ï¸ æ”¶é›†é›†ç¾¤ {cluster} çš„ç³»ç»Ÿèµ„æºæŒ‡æ ‡...")

        # CPUä½¿ç”¨ç‡
        cpu_query = f'avg(cpu_usage_active{{cluster="{cluster}"}})'
        cpu_result = self.client.query_range(cpu_query, start_time, end_time)
        avg_cpu = self.extractor.extract_avg(cpu_result)
        cpu_peak, cpu_peak_time = self.extractor.extract_max_with_time(cpu_result)
        cpu_min, cpu_min_time = self.extractor.extract_min_with_time(cpu_result)

        metrics["cpu_usage"] = MetricResult(
            value=avg_cpu,
            unit="%",
            status="normal" if avg_cpu < 70 else "warning" if avg_cpu < 85 else "critical"
        )
        metrics["cpu_peak"] = MetricResult(value=cpu_peak, unit="%", timestamp=cpu_peak_time)
        metrics["cpu_min"] = MetricResult(value=cpu_min, unit="%", timestamp=cpu_min_time)

        # å†…å­˜ä½¿ç”¨ç‡
        memory_query = f'avg(mem_used_percent{{cluster="{cluster}"}})'
        memory_result = self.client.query_range(memory_query, start_time, end_time)
        avg_memory = self.extractor.extract_avg(memory_result)
        memory_peak, memory_peak_time = self.extractor.extract_max_with_time(memory_result)
        memory_min, memory_min_time = self.extractor.extract_min_with_time(memory_result)

        metrics["memory_usage"] = MetricResult(
            value=avg_memory,
            unit="%",
            status="normal" if avg_memory < 75 else "warning" if avg_memory < 90 else "critical"
        )
        metrics["memory_peak"] = MetricResult(value=memory_peak, unit="%", timestamp=memory_peak_time)
        metrics["memory_min"] = MetricResult(value=memory_min, unit="%", timestamp=memory_min_time)

        # ç³»ç»Ÿè´Ÿè½½
        load_query = f'avg(system_load5{{cluster="{cluster}"}})'
        load_result = self.client.query_range(load_query, start_time, end_time)
        avg_load = self.extractor.extract_avg(load_result)
        load_peak, load_peak_time = self.extractor.extract_max_with_time(load_result)

        # è·å–CPUæ ¸å¿ƒæ•°ç»Ÿè®¡ä¿¡æ¯
        cpu_cores_query = f'system_n_cpus{{cluster="{cluster}"}}'
        cores_result = self.client.query_instant(cpu_cores_query, end_time)

        # è®¡ç®—CPUæ ¸å¿ƒæ•°çš„ç»Ÿè®¡ä¿¡æ¯
        cores_values = []
        if cores_result and 'data' in cores_result and 'result' in cores_result['data']:
            for item in cores_result['data']['result']:
                if 'value' in item and len(item['value']) > 1:
                    cores_values.append(float(item['value'][1]))

        if cores_values:
            total_cores = sum(cores_values)
            avg_cores = sum(cores_values) / len(cores_values)
            min_cores = min(cores_values)
            max_cores = max(cores_values)
            node_count = len(cores_values)
        else:
            total_cores = avg_cores = min_cores = max_cores = node_count = 0

        load_ratio = (avg_load / max(avg_cores, 1)) * 100

        metrics["system_load"] = MetricResult(
            value=avg_load,
            unit="",
            status="normal" if load_ratio < 70 else "warning" if load_ratio < 100 else "critical"
        )
        metrics["load_peak"] = MetricResult(value=load_peak, unit="", timestamp=load_peak_time)
        metrics["total_cpu_cores"] = MetricResult(value=total_cores, unit="æ ¸")
        metrics["avg_cpu_cores"] = MetricResult(value=avg_cores, unit="æ ¸")
        metrics["min_cpu_cores"] = MetricResult(value=min_cores, unit="æ ¸")
        metrics["max_cpu_cores"] = MetricResult(value=max_cores, unit="æ ¸")

        # èŠ‚ç‚¹çŠ¶æ€ç»Ÿè®¡
        # ä¿®æ”¹èŠ‚ç‚¹æŸ¥è¯¢é€»è¾‘ï¼Œä½¿ç”¨æ›´å‡†ç¡®çš„æŒ‡æ ‡
        online_nodes_query = f'count(up{{cluster="{cluster}", job=~".*node.*"}} == 1 or system_uptime{{cluster="{cluster}"}} > 0)'
        total_nodes_query = f'count(up{{cluster="{cluster}", job=~".*node.*"}} or system_uptime{{cluster="{cluster}"}})'

        online_nodes_result = self.client.query_instant(online_nodes_query, end_time)
        total_nodes_result = self.client.query_instant(total_nodes_query, end_time)

        online_nodes = self.extractor.extract_instant_value(online_nodes_result)
        total_nodes = self.extractor.extract_instant_value(total_nodes_result)

        # å¦‚æœæŸ¥è¯¢ç»“æœä¸º0ï¼Œä½¿ç”¨å¤‡ç”¨æŸ¥è¯¢
        if total_nodes == 0:
            backup_query = f'count(group by (instance) ({{cluster="{cluster}"}}))'
            backup_result = self.client.query_instant(backup_query, end_time)
            total_nodes = max(1, self.extractor.extract_instant_value(backup_result))
            online_nodes = total_nodes  # å‡è®¾éƒ½åœ¨çº¿ï¼Œå¦‚æœæœ‰æ›´ç²¾ç¡®çš„æŒ‡æ ‡å¯ä»¥æ›¿æ¢

        availability_ratio = (online_nodes / max(total_nodes, 1)) * 100
        metrics["node_availability"] = MetricResult(
            value=availability_ratio,
            unit="%",
            status="normal" if availability_ratio >= 100 else "warning" if availability_ratio >= 90 else "critical"
        )
        metrics["online_nodes"] = MetricResult(value=online_nodes, unit="ä¸ª")
        metrics["total_nodes"] = MetricResult(value=total_nodes, unit="ä¸ª")
        metrics["node_count"] = MetricResult(value=node_count, unit="å°")

        return metrics

    def format_number(self, value: float, precision: int = 2) -> str:
        """æ”¹è¿›çš„æ•°å­—æ ¼å¼åŒ–å‡½æ•°ï¼Œç‰¹åˆ«å¤„ç†å¤§æ•°å€¼"""
        if value >= 1e12:
            return f"{value / 1e12:.{precision}f}ä¸‡äº¿"
        elif value >= 1e8:  # 1äº¿
            return f"{value / 1e8:.{precision}f}äº¿"
        elif value >= 1e4:  # 1ä¸‡
            return f"{value / 1e4:.{precision}f}ä¸‡"
        elif value >= 1e3:
            return f"{value / 1e3:.{precision}f}åƒ"
        else:
            return f"{value:.{precision}f}"

    def format_requests(self, value: float, precision: int = 2) -> str:
        """ä¸“é—¨ç”¨äºæ ¼å¼åŒ–è¯·æ±‚æ•°çš„å‡½æ•°"""
        if value >= 1e8:  # 1äº¿æ¬¡
            return f"{value / 1e8:.{precision}f}äº¿æ¬¡"
        elif value >= 1e4:  # 1ä¸‡æ¬¡
            return f"{value / 1e4:.{precision}f}ä¸‡æ¬¡"
        elif value >= 1e3:  # 1åƒæ¬¡
            return f"{value / 1e3:.{precision}f}åƒæ¬¡"
        else:
            return f"{value:.{precision}f}æ¬¡"

    def calculate_comparison(self, current: float, previous: float) -> Tuple[float, str]:
        """è®¡ç®—ç¯æ¯”/åŒæ¯”å˜åŒ–"""
        if previous == 0:
            if current == 0:
                return 0.0, "æŒå¹³"
            else:
                return 100.0, "æ–°å¢"

        change_ratio = ((current - previous) / previous) * 100

        if abs(change_ratio) < 0.1:
            trend = "æŒå¹³"
        elif change_ratio > 0:
            trend = f"ä¸Šå‡{abs(change_ratio):.1f}%"
        else:
            trend = f"ä¸‹é™{abs(change_ratio):.1f}%"

        return change_ratio, trend

    def collect_connection_metrics(self, cluster: str, start_time: int, end_time: int) -> Dict[str, MetricResult]:
        """æ”¶é›†å•ä¸ªé›†ç¾¤çš„è¿æ¥çŠ¶æ€æŒ‡æ ‡"""
        duration = end_time - start_time
        metrics = {}

        logger.info(f"ğŸ”— æ”¶é›†é›†ç¾¤ {cluster} çš„è¿æ¥çŠ¶æ€æŒ‡æ ‡...")

        connection_types = ["active", "waiting", "reading", "writing"]
        for conn_type in connection_types:
            query = f'sum(nginx_{conn_type}{{cluster="{cluster}"}})'
            result = self.client.query_range(query, start_time, end_time)

            avg_conn = self.extractor.extract_avg(result)
            peak_conn, peak_time = self.extractor.extract_max_with_time(result)

            metrics[f"conn_{conn_type}"] = MetricResult(value=avg_conn, unit="ä¸ª")
            metrics[f"conn_{conn_type}_peak"] = MetricResult(value=peak_conn, unit="ä¸ª", timestamp=peak_time)

        # è®¡ç®—æ€»è¿æ¥å³°å€¼
        total_conn_query = f'sum(nginx_active{{cluster="{cluster}"}} + nginx_waiting{{cluster="{cluster}"}})'
        total_conn_result = self.client.query_range(total_conn_query, start_time, end_time)
        total_conn_peak, total_conn_time = self.extractor.extract_max_with_time(total_conn_result)
        metrics["conn_total_peak"] = MetricResult(value=total_conn_peak, unit="ä¸ª", timestamp=total_conn_time)

        return metrics

    def collect_anomaly_metrics(self, cluster: str, start_time: int, end_time: int) -> Dict[str, MetricResult]:
        """æ”¶é›†å•ä¸ªé›†ç¾¤çš„å¼‚å¸¸äº‹ä»¶æŒ‡æ ‡"""
        duration = end_time - start_time
        metrics = {}

        logger.info(f"âš ï¸ æ”¶é›†é›†ç¾¤ {cluster} çš„å¼‚å¸¸äº‹ä»¶æŒ‡æ ‡...")

        # OOMäº‹ä»¶ç»Ÿè®¡
        oom_query = f'sum(increase(kernel_vmstat_oom_kill{{cluster="{cluster}"}}[{duration}s]))'
        oom_result = self.client.query_instant(oom_query, end_time)
        oom_count = self.extractor.extract_instant_value(oom_result)
        metrics["oom_events"] = MetricResult(
            value=oom_count,
            unit="æ¬¡",
            status="normal" if oom_count == 0 else "critical"
        )

        # é«˜CPUä½¿ç”¨ç‡èŠ‚ç‚¹ç»Ÿè®¡
        high_cpu_query = f'count(cpu_usage_active{{cluster="{cluster}"}} > 85)'
        high_cpu_result = self.client.query_instant(high_cpu_query, end_time)
        high_cpu_nodes = self.extractor.extract_instant_value(high_cpu_result)
        metrics["high_cpu_nodes"] = MetricResult(
            value=high_cpu_nodes,
            unit="ä¸ª",
            status="normal" if high_cpu_nodes == 0 else "warning"
        )

        # é«˜å†…å­˜ä½¿ç”¨ç‡èŠ‚ç‚¹ç»Ÿè®¡
        high_mem_query = f'count(mem_used_percent{{cluster="{cluster}"}} > 90)'
        high_mem_result = self.client.query_instant(high_mem_query, end_time)
        high_mem_nodes = self.extractor.extract_instant_value(high_mem_result)
        metrics["high_memory_nodes"] = MetricResult(
            value=high_mem_nodes,
            unit="ä¸ª",
            status="normal" if high_mem_nodes == 0 else "warning"
        )

        # ç½‘ç»œé”™è¯¯ç»Ÿè®¡
        net_errors_query = f'sum(increase(net_err_in{{cluster="{cluster}"}}[{duration}s]) + increase(net_err_out{{cluster="{cluster}"}}[{duration}s]))'
        net_errors_result = self.client.query_instant(net_errors_query, end_time)
        net_errors = self.extractor.extract_instant_value(net_errors_result)
        metrics["network_errors"] = MetricResult(
            value=net_errors,
            unit="ä¸ª",
            status="normal" if net_errors < 100 else "warning" if net_errors < 1000 else "critical"
        )

        return metrics

    def generate_report(self, target_date: str, clusters: List[str] = None,
                        report_type: ReportType = ReportType.DAILY,
                        include_comparison: bool = True) -> List[str]:  # æ³¨æ„ï¼šè¿”å›ç±»å‹æ”¹ä¸ºList[str]
        """ç”Ÿæˆåˆ†é›†ç¾¤æŠ¥å‘Šï¼Œæ¯ä¸ªé›†ç¾¤å•ç‹¬ç”Ÿæˆä¸€ä¸ªæŠ¥å‘Š"""
        if not clusters:
            clusters = self.default_clusters

        logger.info(f"ğŸš€ å¼€å§‹ç”Ÿæˆ {target_date} çš„{report_type.value}ç›‘æ§æŠ¥å‘Š...")
        time_ranges = self.get_time_ranges(target_date, report_type)
        current_start, current_end = time_ranges["current"]
        cluster_reports = []

        for cluster in clusters:
            logger.info(f"ğŸ“Š å¤„ç†é›†ç¾¤: {cluster}")

            # æ”¶é›†å½“å‰æ—¶æ®µçš„æŒ‡æ ‡
            core_metrics = self.collect_core_metrics(cluster, current_start, current_end)
            system_metrics = self.collect_system_metrics(cluster, current_start, current_end)
            connection_metrics = self.collect_connection_metrics(cluster, current_start, current_end)
            anomaly_metrics = self.collect_anomaly_metrics(cluster, current_start, current_end)

            # æ”¶é›†å¯¹æ¯”æ•°æ®
            comparison_data = {}
            if include_comparison:
                logger.info(f"ğŸ“ˆ æ”¶é›†é›†ç¾¤ {cluster} çš„å¯¹æ¯”æ•°æ®...")
                prev_start, prev_end = time_ranges["previous"]
                prev_core = self.collect_core_metrics(cluster, prev_start, prev_end)
                prev_system = self.collect_system_metrics(cluster, prev_start, prev_end)

                comparison_data = {
                    "requests": self.calculate_comparison(
                        core_metrics["total_requests"].value,
                        prev_core["total_requests"].value
                    ),
                    "traffic": self.calculate_comparison(
                        core_metrics["total_traffic"].value,
                        prev_core["total_traffic"].value
                    ),
                    "qps_peak": self.calculate_comparison(
                        core_metrics["qps_peak"].value,
                        prev_core["qps_peak"].value
                    ),
                    "cpu_avg": self.calculate_comparison(
                        system_metrics["cpu_usage"].value,
                        prev_system["cpu_usage"].value
                    ),
                    "memory_avg": self.calculate_comparison(
                        system_metrics["memory_usage"].value,
                        prev_system["memory_usage"].value
                    )
                }

            # ç”Ÿæˆå•ä¸ªé›†ç¾¤çš„æŠ¥å‘Š
            cluster_report = self._format_cluster_report(
                target_date, report_type, cluster,
                core_metrics, system_metrics, connection_metrics, anomaly_metrics,
                comparison_data
            )

            cluster_reports.append(cluster_report)

        logger.info(f"âœ… {target_date} {report_type.value}ç›‘æ§æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ{len(cluster_reports)}ä¸ªé›†ç¾¤æŠ¥å‘Š")
        return cluster_reports  # è¿”å›æŠ¥å‘Šåˆ—è¡¨ï¼Œæ¯ä¸ªé›†ç¾¤ä¸€ä¸ªæŠ¥å‘Š

    def _generate_cluster_recommendations(self, cluster: str, core_metrics: Dict, system_metrics: Dict,
                                          connection_metrics: Dict, anomaly_metrics: Dict) -> Dict[str, List[str]]:
        """ä¸ºå•ä¸ªé›†ç¾¤ç”Ÿæˆè¿ç»´å»ºè®®"""
        recommendations = {
            "æ€§èƒ½ä¼˜åŒ–": [],
            "èµ„æºç®¡ç†": [],
            "å®‰å…¨åŠ å›º": [],
            "å®¹ç¾å¤‡ä»½": []
        }

        # æ€§èƒ½ä¼˜åŒ–å»ºè®®
        if system_metrics["cpu_usage"].value > 70:
            recommendations["æ€§èƒ½ä¼˜åŒ–"].append(
                f"é›†ç¾¤{cluster}: CPUä½¿ç”¨ç‡è¾¾åˆ°{system_metrics['cpu_usage'].value:.1f}%ï¼Œå»ºè®®ä¼˜åŒ–åº”ç”¨æ€§èƒ½æˆ–æ‰©å®¹")

        if system_metrics["memory_usage"].value > 75:
            recommendations["æ€§èƒ½ä¼˜åŒ–"].append(
                f"é›†ç¾¤{cluster}: å†…å­˜ä½¿ç”¨ç‡è¾¾åˆ°{system_metrics['memory_usage'].value:.1f}%ï¼Œå»ºè®®ä¼˜åŒ–å†…å­˜ä½¿ç”¨æˆ–å¢åŠ å†…å­˜")

        # æ£€æŸ¥è¿æ¥æ•°å³°å€¼
        if connection_metrics["conn_active_peak"].value > 10000:
            recommendations["æ€§èƒ½ä¼˜åŒ–"].append(
                f"é›†ç¾¤{cluster}: æ´»è·ƒè¿æ¥æ•°å³°å€¼è¾¾åˆ°{int(connection_metrics['conn_active_peak'].value)}ï¼Œå»ºè®®ä¼˜åŒ–è¿æ¥æ± é…ç½®")

        # èµ„æºç®¡ç†å»ºè®®
        if system_metrics["node_availability"].value < 100:
            offline_nodes = int(system_metrics["total_nodes"].value - system_metrics["online_nodes"].value)
            recommendations["èµ„æºç®¡ç†"].append(f"é›†ç¾¤{cluster}: æœ‰{offline_nodes}ä¸ªèŠ‚ç‚¹ç¦»çº¿ï¼Œè¯·æ£€æŸ¥èŠ‚ç‚¹çŠ¶æ€")

        if anomaly_metrics["oom_events"].value > 0:
            recommendations["èµ„æºç®¡ç†"].append(
                f"é›†ç¾¤{cluster}: å‘ç”Ÿ{int(anomaly_metrics['oom_events'].value)}æ¬¡OOMäº‹ä»¶ï¼Œè¯·æ£€æŸ¥å†…å­˜é…ç½®")

        # å®‰å…¨åŠ å›ºå»ºè®®
        if anomaly_metrics["network_errors"].value > 1000:
            recommendations["å®‰å…¨åŠ å›º"].append(
                f"é›†ç¾¤{cluster}: ç½‘ç»œé”™è¯¯æ•°é‡è¾ƒé«˜({int(anomaly_metrics['network_errors'].value)}ä¸ª)ï¼Œè¯·æ£€æŸ¥ç½‘ç»œå®‰å…¨")

        # å®¹ç¾å¤‡ä»½å»ºè®®
        if core_metrics["availability"].value < 99.9:
            recommendations["å®¹ç¾å¤‡ä»½"].append(
                f"é›†ç¾¤{cluster}: æœåŠ¡å¯ç”¨æ€§ä¸º{core_metrics['availability'].value:.3f}%ï¼Œå»ºè®®å®Œå–„å®¹ç¾æœºåˆ¶")

        # å¦‚æœæ²¡æœ‰ç‰¹åˆ«çš„å»ºè®®ï¼Œç»™å‡ºé€šç”¨å»ºè®®
        if not any(recommendations.values()):
            recommendations["æ€§èƒ½ä¼˜åŒ–"].append(f"é›†ç¾¤{cluster}: ç³»ç»Ÿè¿è¡ŒçŠ¶æ€è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ä¿æŒå½“å‰è¿ç»´æ°´å¹³")
            recommendations["èµ„æºç®¡ç†"].append(f"é›†ç¾¤{cluster}: èµ„æºä½¿ç”¨åˆç†ï¼Œå¯è€ƒè™‘åˆ¶å®šå®¹é‡è§„åˆ’")
            recommendations["å®‰å…¨åŠ å›º"].append(f"é›†ç¾¤{cluster}: å»ºè®®å®šæœŸè¿›è¡Œå®‰å…¨æ£€æŸ¥å’Œæ¼æ´æ‰«æ")
            recommendations["å®¹ç¾å¤‡ä»½"].append(f"é›†ç¾¤{cluster}: å»ºè®®å®šæœŸæ¼”ç»ƒå®¹ç¾æ¢å¤æµç¨‹")

        return recommendations

    def _format_cluster_report(self, date: str, report_type: ReportType, cluster: str,
                               core_metrics: Dict, system_metrics: Dict,
                               connection_metrics: Dict, anomaly_metrics: Dict,
                               comparison_data: Dict) -> str:
        type_names = {
            ReportType.DAILY: "æ—¥æŠ¥",
            ReportType.WEEKLY: "å‘¨æŠ¥",
            ReportType.MONTHLY: "æœˆæŠ¥"
        }

        # è®¡ç®—å‘Šè­¦ç»Ÿè®¡
        warning_count = sum(1 for m in {**core_metrics, **system_metrics, **anomaly_metrics}.values()
                            if hasattr(m, 'status') and m.status == "warning")
        critical_count = sum(1 for m in {**core_metrics, **system_metrics, **anomaly_metrics}.values()
                             if hasattr(m, 'status') and m.status == "critical")

        if critical_count > 0:
            overall_status = "ğŸš¨ éœ€è¦ç´§æ€¥å…³æ³¨"
        elif warning_count > 0:
            overall_status = "âš ï¸ éœ€è¦å…³æ³¨"
        else:
            overall_status = "âœ… è¿è¡Œæ­£å¸¸"

        lines = []
        lines.extend([
            "=" * 100,
            f"ğŸ¢ ã€{cluster}ã€‘é›†ç¾¤ Nginx ç³»ç»Ÿè¿è¡Œ{type_names[report_type]} - {date}",
            "=" * 100,
            f"ğŸ¯ é›†ç¾¤çŠ¶æ€: {overall_status}",
            f"ğŸ“… ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            ""
        ])

        # æ‰§è¡Œæ‘˜è¦
        lines.extend([
            "ã€ğŸ“‹ ä¸€ã€æ‰§è¡Œæ‘˜è¦ã€‘",
            ""
        ])

        availability = core_metrics["availability"].value
        total_requests = core_metrics["total_requests"].value
        qps_peak = core_metrics["qps_peak"].value
        qps_avg = core_metrics["qps_avg"].value
        bandwidth_peak = core_metrics["bandwidth_peak"].value
        bandwidth_avg = core_metrics["bandwidth_avg"].value

        lines.extend([
            f"ğŸ¯ æœåŠ¡å¯ç”¨æ€§: {availability:.3f}% {'(ä¼˜ç§€)' if availability >= 99.95 else '(è‰¯å¥½)' if availability >= 99.9 else '(éœ€æ”¹è¿›)'}",
            f"ğŸ“Š ä¸šåŠ¡å¤„ç†: æ€»è®¡ {self.format_requests(total_requests)}",  # ä½¿ç”¨æ–°çš„æ ¼å¼åŒ–å‡½æ•°
            f"âš¡ QPSè¡¨ç°: å³°å€¼ {self.format_number(qps_peak)} ({core_metrics['qps_peak'].timestamp})",
            f"ğŸŒ ç½‘ç»œå¸¦å®½: å³°å€¼ {bandwidth_peak:.2f} Gbps ({core_metrics['bandwidth_peak'].timestamp}), å¹³å‡ {bandwidth_avg:.2f} Gbps",
            f"ğŸ“¦ æ•°æ®æµé‡: æ€»è®¡ {core_metrics['total_traffic'].value:.2f} TB (ä¸Šè¡Œ {core_metrics['traffic_out'].value:.2f} TB, ä¸‹è¡Œ {core_metrics['traffic_in'].value:.2f} TB)",
            f"ğŸ’» èµ„æºä½¿ç”¨: CPUå¹³å‡ {system_metrics['cpu_usage'].value:.1f}%, å†…å­˜å¹³å‡ {system_metrics['memory_usage'].value:.1f}%",
            f"ğŸ–¥ï¸ ç¡¬ä»¶é…ç½®: {int(system_metrics['node_count'].value)} å°æœåŠ¡å™¨, æ€»è®¡ {int(system_metrics['total_cpu_cores'].value)} æ ¸ CPU",
            ""
        ])

        # ç¯æ¯”å˜åŒ–
        if comparison_data:
            lines.extend([
                "ğŸ“ˆ ç¯æ¯”å˜åŒ–:",
                f"  â€¢ è¯·æ±‚é‡: {comparison_data['requests'][1]}",
                f"  â€¢ æµé‡: {comparison_data['traffic'][1]}",
                f"  â€¢ å³°å€¼QPS: {comparison_data['qps_peak'][1]}",
                f"  â€¢ CPUå¹³å‡: {comparison_data.get('cpu_avg', ('', 'æš‚æ— æ•°æ®'))[1]}",
                f"  â€¢ å†…å­˜å¹³å‡: {comparison_data.get('memory_avg', ('', 'æš‚æ— æ•°æ®'))[1]}",
                ""
            ])

        # å¼‚å¸¸äº‹ä»¶æ‘˜è¦
        total_anomalies = int(anomaly_metrics["oom_events"].value +
                              anomaly_metrics["high_cpu_nodes"].value +
                              anomaly_metrics["high_memory_nodes"].value)

        if total_anomalies > 0:
            lines.extend([
                f"âš ï¸ å¼‚å¸¸äº‹ä»¶: å‘ç° {total_anomalies} é¡¹å¼‚å¸¸éœ€è¦å…³æ³¨",
                f"  â€¢ OOMäº‹ä»¶: {int(anomaly_metrics['oom_events'].value)} æ¬¡",
                f"  â€¢ é«˜CPUèŠ‚ç‚¹: {int(anomaly_metrics['high_cpu_nodes'].value)} ä¸ª",
                f"  â€¢ é«˜å†…å­˜èŠ‚ç‚¹: {int(anomaly_metrics['high_memory_nodes'].value)} ä¸ª",
                f"  â€¢ ç½‘ç»œé”™è¯¯: {int(anomaly_metrics['network_errors'].value)} ä¸ª",
                ""
            ])
        else:
            lines.extend([
                "âœ… å¼‚å¸¸äº‹ä»¶: æ— å¼‚å¸¸äº‹ä»¶å‘ç”Ÿ",
                ""
            ])

        # è¯¦ç»†æŠ€æœ¯æŒ‡æ ‡
        lines.extend([
            "ã€ğŸ”§ äºŒã€è¯¦ç»†æŠ€æœ¯æŒ‡æ ‡ã€‘",
            ""
        ])

        # ä¸šåŠ¡æŒ‡æ ‡
        lines.extend([
            "ğŸ“Š ä¸šåŠ¡æŒ‡æ ‡:",
            f"  â€¢ æ€»è¯·æ±‚æ•°: {self.format_number(total_requests)} æ¬¡",
            f"  â€¢ QPSå³°å€¼: {self.format_number(qps_peak)} (æ—¶é—´: {core_metrics['qps_peak'].timestamp})",
            f"  â€¢ QPSæœ€ä½: {self.format_number(core_metrics['qps_min'].value)} (æ—¶é—´: {core_metrics['qps_min'].timestamp})",
            f"  â€¢ QPSå¹³å‡: {self.format_number(qps_avg)}",
            f"  â€¢ å¸¦å®½å³°å€¼: {bandwidth_peak:.2f} Gbps (æ—¶é—´: {core_metrics['bandwidth_peak'].timestamp})",
            f"    - ä¸Šè¡Œå³°å€¼: {core_metrics['bandwidth_out_peak'].value:.2f} Gbps (æ—¶é—´: {core_metrics['bandwidth_out_peak'].timestamp})",
            f"    - ä¸‹è¡Œå³°å€¼: {core_metrics['bandwidth_in_peak'].value:.2f} Gbps (æ—¶é—´: {core_metrics['bandwidth_in_peak'].timestamp})",
            f"  â€¢ å¸¦å®½å¹³å‡: {bandwidth_avg:.2f} Gbps",
            f"    - ä¸Šè¡Œå¹³å‡: {core_metrics['bandwidth_out_avg'].value:.2f} Gbps",
            f"    - ä¸‹è¡Œå¹³å‡: {core_metrics['bandwidth_in_avg'].value:.2f} Gbps",
            f"  â€¢ æ€»æµé‡: {core_metrics['total_traffic'].value:.2f} TB",
            f"    - ä¸Šè¡Œæµé‡: {core_metrics['traffic_out'].value:.2f} TB",
            f"    - ä¸‹è¡Œæµé‡: {core_metrics['traffic_in'].value:.2f} TB",
            f"  â€¢ æœåŠ¡å¯ç”¨æ€§: {availability:.3f}%",
            ""
        ])

        # ç³»ç»Ÿèµ„æº
        lines.extend([
            "ğŸ’» ç³»ç»Ÿèµ„æº:",
            f"  â€¢ CPUä½¿ç”¨ç‡: å¹³å‡ {system_metrics['cpu_usage'].value:.1f}% {self._get_status_icon(system_metrics['cpu_usage'].status)}",
            f"    - å³°å€¼: {system_metrics['cpu_peak'].value:.1f}% (æ—¶é—´: {system_metrics['cpu_peak'].timestamp})",
            f"    - æœ€ä½: {system_metrics['cpu_min'].value:.1f}% (æ—¶é—´: {system_metrics['cpu_min'].timestamp})",
            f"  â€¢ å†…å­˜ä½¿ç”¨ç‡: å¹³å‡ {system_metrics['memory_usage'].value:.1f}% {self._get_status_icon(system_metrics['memory_usage'].status)}",
            f"    - å³°å€¼: {system_metrics['memory_peak'].value:.1f}% (æ—¶é—´: {system_metrics['memory_peak'].timestamp})",
            f"    - æœ€ä½: {system_metrics['memory_min'].value:.1f}% (æ—¶é—´: {system_metrics['memory_min'].timestamp})",
            f"  â€¢ ç³»ç»Ÿè´Ÿè½½: å¹³å‡ {system_metrics['system_load'].value:.2f}",
            f"    - å³°å€¼: {system_metrics['load_peak'].value:.2f} (æ—¶é—´: {system_metrics['load_peak'].timestamp})",
            f"  â€¢ ç¡¬ä»¶é…ç½®:",
            f"    - æœåŠ¡å™¨æ•°é‡: {int(system_metrics['node_count'].value)} å°",
            f"    - CPUæ ¸å¿ƒæ€»æ•°: {int(system_metrics['total_cpu_cores'].value)} æ ¸",
            f"    - å•æœºCPUæ ¸å¿ƒæ•°: {int(system_metrics['min_cpu_cores'].value)}-{int(system_metrics['max_cpu_cores'].value)} æ ¸ (å¹³å‡ {system_metrics['avg_cpu_cores'].value:.1f} æ ¸)",
            f"  â€¢ åœ¨çº¿èŠ‚ç‚¹: {int(system_metrics['online_nodes'].value)}/{int(system_metrics['total_nodes'].value)} ä¸ª",
            f"  â€¢ èŠ‚ç‚¹å¯ç”¨ç‡: {system_metrics['node_availability'].value:.1f}% {self._get_status_icon(system_metrics['node_availability'].status)}",
            ""
        ])

        # è¿æ¥çŠ¶æ€
        lines.extend([
            "ğŸ”— è¿æ¥çŠ¶æ€:",
            f"  â€¢ æ´»è·ƒè¿æ¥: å¹³å‡ {int(connection_metrics['conn_active'].value)} ä¸ª",
            f"    - å³°å€¼: {int(connection_metrics['conn_active_peak'].value)} ä¸ª (æ—¶é—´: {connection_metrics['conn_active_peak'].timestamp})",
            f"  â€¢ ç­‰å¾…è¿æ¥: å¹³å‡ {int(connection_metrics['conn_waiting'].value)} ä¸ª",
            f"    - å³°å€¼: {int(connection_metrics['conn_waiting_peak'].value)} ä¸ª (æ—¶é—´: {connection_metrics['conn_waiting_peak'].timestamp})",
            f"  â€¢ è¯»å–è¿æ¥: å¹³å‡ {int(connection_metrics['conn_reading'].value)} ä¸ª",
            f"    - å³°å€¼: {int(connection_metrics['conn_reading_peak'].value)} ä¸ª (æ—¶é—´: {connection_metrics['conn_reading_peak'].timestamp})",
            f"  â€¢ å†™å…¥è¿æ¥: å¹³å‡ {int(connection_metrics['conn_writing'].value)} ä¸ª",
            f"    - å³°å€¼: {int(connection_metrics['conn_writing_peak'].value)} ä¸ª (æ—¶é—´: {connection_metrics['conn_writing_peak'].timestamp})",
            f"  â€¢ æ€»è¿æ¥å³°å€¼: {int(connection_metrics['conn_total_peak'].value)} ä¸ª (æ—¶é—´: {connection_metrics['conn_total_peak'].timestamp})",
            ""
        ])

        # è¿æ¥çŠ¶æ€è¯´æ˜
        if connection_metrics['conn_reading'].value == 0 and connection_metrics['conn_reading_peak'].value <= 1:
            lines.append("  ğŸ“ è¯´æ˜: è¯»å–è¿æ¥æ•°è¾ƒä½å±äºæ­£å¸¸ç°è±¡ï¼Œè¡¨ç¤ºè¯·æ±‚å¤„ç†é€Ÿåº¦è¾ƒå¿«")
            lines.append("")

        # å¼‚å¸¸äº‹ä»¶ç»Ÿè®¡
        lines.extend([
            "âš ï¸ å¼‚å¸¸äº‹ä»¶ç»Ÿè®¡:",
            f"  â€¢ OOMäº‹ä»¶: {int(anomaly_metrics['oom_events'].value)} æ¬¡ {self._get_status_icon(anomaly_metrics['oom_events'].status)}",
            f"  â€¢ é«˜CPUä½¿ç”¨ç‡èŠ‚ç‚¹: {int(anomaly_metrics['high_cpu_nodes'].value)} ä¸ª {self._get_status_icon(anomaly_metrics['high_cpu_nodes'].status)}",
            f"  â€¢ é«˜å†…å­˜ä½¿ç”¨ç‡èŠ‚ç‚¹: {int(anomaly_metrics['high_memory_nodes'].value)} ä¸ª {self._get_status_icon(anomaly_metrics['high_memory_nodes'].status)}",
            f"  â€¢ ç½‘ç»œé”™è¯¯: {int(anomaly_metrics['network_errors'].value)} ä¸ª {self._get_status_icon(anomaly_metrics['network_errors'].status)}",
            ""
        ])

        # è¿ç»´å»ºè®®
        lines.extend([
            "ã€ğŸ’¡ ä¸‰ã€è¿ç»´å»ºè®®ã€‘",
            ""
        ])

        recommendations = self._generate_cluster_recommendations(
            cluster, core_metrics, system_metrics, connection_metrics, anomaly_metrics
        )

        for category, recs in recommendations.items():
            if recs:
                lines.append(f"ğŸ” {category}:")
                for rec in recs:
                    lines.append(f"  â€¢ {rec}")
                lines.append("")

        lines.extend([
            "=" * 100,
            ""
        ])

        return "\n".join(lines)

    def _get_status_icon(self, status: str) -> str:
        """è·å–çŠ¶æ€å›¾æ ‡"""
        icons = {
            "normal": "âœ…",
            "warning": "âš ï¸",
            "critical": "ğŸš¨"
        }
        return icons.get(status, "â“")

    def _generate_recommendations(self, core_metrics: Dict, system_metrics: Dict,
                                  connection_metrics: Dict, anomaly_metrics: Dict) -> Dict[str, List[str]]:
        """ç”Ÿæˆè¿ç»´å»ºè®®"""
        recommendations = {
            "æ€§èƒ½ä¼˜åŒ–": [],
            "èµ„æºç®¡ç†": [],
            "å®‰å…¨åŠ å›º": [],
            "å®¹ç¾å¤‡ä»½": []
        }

        # æ€§èƒ½ç›¸å…³å»ºè®®
        if system_metrics["cpu_usage"].value > 70:
            recommendations["æ€§èƒ½ä¼˜åŒ–"].append(
                f"CPUä½¿ç”¨ç‡è¾¾åˆ°{system_metrics['cpu_usage'].value:.1f}%ï¼Œå»ºè®®ä¼˜åŒ–åº”ç”¨æ€§èƒ½æˆ–æ‰©å®¹")

        if system_metrics["memory_usage"].value > 75:
            recommendations["æ€§èƒ½ä¼˜åŒ–"].append(
                f"å†…å­˜ä½¿ç”¨ç‡è¾¾åˆ°{system_metrics['memory_usage'].value:.1f}%ï¼Œå»ºè®®ä¼˜åŒ–å†…å­˜ä½¿ç”¨æˆ–å¢åŠ å†…å­˜")

        if connection_metrics["conn_peak"].value > 10000:
            recommendations["æ€§èƒ½ä¼˜åŒ–"].append(
                f"è¿æ¥æ•°å³°å€¼è¾¾åˆ°{int(connection_metrics['conn_peak'].value)}ï¼Œå»ºè®®ä¼˜åŒ–è¿æ¥æ± é…ç½®")

        # èµ„æºç®¡ç†å»ºè®®
        if system_metrics["node_availability"].value < 100:
            offline_nodes = int(system_metrics["total_nodes"].value - system_metrics["online_nodes"].value)
            recommendations["èµ„æºç®¡ç†"].append(f"æœ‰{offline_nodes}ä¸ªèŠ‚ç‚¹ç¦»çº¿ï¼Œè¯·æ£€æŸ¥èŠ‚ç‚¹çŠ¶æ€")

        if anomaly_metrics["oom_events"].value > 0:
            recommendations["èµ„æºç®¡ç†"].append(
                f"å‘ç”Ÿ{int(anomaly_metrics['oom_events'].value)}æ¬¡OOMäº‹ä»¶ï¼Œè¯·æ£€æŸ¥å†…å­˜é…ç½®")

        # å®‰å…¨ç›¸å…³å»ºè®®
        if anomaly_metrics["network_errors"].value > 1000:
            recommendations["å®‰å…¨åŠ å›º"].append(
                f"ç½‘ç»œé”™è¯¯æ•°é‡è¾ƒé«˜({int(anomaly_metrics['network_errors'].value)}ä¸ª)ï¼Œè¯·æ£€æŸ¥ç½‘ç»œå®‰å…¨")

        # å®¹ç¾ç›¸å…³å»ºè®®
        if core_metrics["availability"].value < 99.9:
            recommendations["å®¹ç¾å¤‡ä»½"].append(
                f"æœåŠ¡å¯ç”¨æ€§ä¸º{core_metrics['availability'].value:.3f}%ï¼Œå»ºè®®å®Œå–„å®¹ç¾æœºåˆ¶")

        # å¦‚æœæ²¡æœ‰é—®é¢˜ï¼Œç»™å‡ºç§¯æå»ºè®®
        if not any(recommendations.values()):
            recommendations["æ€§èƒ½ä¼˜åŒ–"].append("ç³»ç»Ÿè¿è¡ŒçŠ¶æ€è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ä¿æŒå½“å‰è¿ç»´æ°´å¹³")
            recommendations["èµ„æºç®¡ç†"].append("èµ„æºä½¿ç”¨åˆç†ï¼Œå¯è€ƒè™‘åˆ¶å®šå®¹é‡è§„åˆ’")
            recommendations["å®‰å…¨åŠ å›º"].append("å»ºè®®å®šæœŸè¿›è¡Œå®‰å…¨æ£€æŸ¥å’Œæ¼æ´æ‰«æ")
            recommendations["å®¹ç¾å¤‡ä»½"].append("å»ºè®®å®šæœŸæ¼”ç»ƒå®¹ç¾æ¢å¤æµç¨‹")

        return recommendations


def create_nightingale_dashboard():
    """åˆ›å»ºå¤œèºç›‘æ§å¤§å±é…ç½®"""
    dashboard_config = {
        "name": "Nginxæ—¥æŠ¥ç›‘æ§å¤§å±",
        "tags": ["nginx", "daily-report"],
        "configs": {
            "panels": [
                {
                    "title": "æœåŠ¡å¯ç”¨æ€§",
                    "type": "stat",
                    "targets": [
                        {
                            "expr": "min(system_uptime{cluster=~\"$cluster\"}) / 86400 * 99.99",
                            "legend": "å¯ç”¨æ€§"
                        }
                    ],
                    "options": {
                        "valueName": "current",
                        "unit": "percent",
                        "thresholds": [
                            {"color": "red", "value": 99.0},
                            {"color": "yellow", "value": 99.9},
                            {"color": "green", "value": 99.95}
                        ]
                    }
                },
                {
                    "title": "æ€»è¯·æ±‚æ•°",
                    "type": "stat",
                    "targets": [
                        {
                            "expr": "sum(increase(nginx_requests{cluster=~\"$cluster\"}[24h]))",
                            "legend": "æ€»è¯·æ±‚æ•°"
                        }
                    ],
                    "options": {
                        "valueName": "current",
                        "unit": "short"
                    }
                },
                {
                    "title": "QPSè¶‹åŠ¿",
                    "type": "graph",
                    "targets": [
                        {
                            "expr": "sum(irate(nginx_requests{cluster=~\"$cluster\"}[2m]))",
                            "legend": "QPS"
                        }
                    ],
                    "options": {
                        "unit": "reqps"
                    }
                },
                {
                    "title": "å¸¦å®½ä½¿ç”¨è¶‹åŠ¿",
                    "type": "graph",
                    "targets": [
                        {
                            "expr": "sum(irate(net_bytes_recv{cluster=~\"$cluster\"}[2m]) * 8 + irate(net_bytes_sent{cluster=~\"$cluster\"}[2m]) * 8) / 1024 / 1024 / 1024",
                            "legend": "å¸¦å®½"
                        }
                    ],
                    "options": {
                        "unit": "bps"
                    }
                },
                {
                    "title": "ç³»ç»Ÿèµ„æºæ¦‚è§ˆ",
                    "type": "table",
                    "targets": [
                        {
                            "expr": "avg(cpu_usage_active{cluster=~\"$cluster\"})",
                            "legend": "CPUä½¿ç”¨ç‡"
                        },
                        {
                            "expr": "avg(mem_used_percent{cluster=~\"$cluster\"})",
                            "legend": "å†…å­˜ä½¿ç”¨ç‡"
                        },
                        {
                            "expr": "avg(system_load5{cluster=~\"$cluster\"})",
                            "legend": "ç³»ç»Ÿè´Ÿè½½"
                        }
                    ]
                },
                {
                    "title": "è¿æ¥çŠ¶æ€åˆ†å¸ƒ",
                    "type": "piechart",
                    "targets": [
                        {
                            "expr": "sum(nginx_active{cluster=~\"$cluster\"})",
                            "legend": "æ´»è·ƒ"
                        },
                        {
                            "expr": "sum(nginx_waiting{cluster=~\"$cluster\"})",
                            "legend": "ç­‰å¾…"
                        },
                        {
                            "expr": "sum(nginx_reading{cluster=~\"$cluster\"})",
                            "legend": "è¯»å–"
                        },
                        {
                            "expr": "sum(nginx_writing{cluster=~\"$cluster\"})",
                            "legend": "å†™å…¥"
                        }
                    ]
                },
                {
                    "title": "å¼‚å¸¸äº‹ä»¶ç»Ÿè®¡",
                    "type": "table",
                    "targets": [
                        {
                            "expr": "sum(increase(kernel_vmstat_oom_kill{cluster=~\"$cluster\"}[24h]))",
                            "legend": "OOMäº‹ä»¶"
                        },
                        {
                            "expr": "count(cpu_usage_active{cluster=~\"$cluster\"} > 85)",
                            "legend": "é«˜CPUèŠ‚ç‚¹"
                        },
                        {
                            "expr": "count(mem_used_percent{cluster=~\"$cluster\"} > 90)",
                            "legend": "é«˜å†…å­˜èŠ‚ç‚¹"
                        },
                        {
                            "expr": "sum(increase(net_err_in{cluster=~\"$cluster\"}[24h]) + increase(net_err_out{cluster=~\"$cluster\"}[24h]))",
                            "legend": "ç½‘ç»œé”™è¯¯"
                        }
                    ]
                }
            ],
            "templating": {
                "list": [
                    {
                        "name": "cluster",
                        "type": "query",
                        "query": "label_values(nginx_requests, cluster)",
                        "multi": True,
                        "includeAll": True,
                        "current": {
                            "value": "self-prod-nginx|zgtapp-prod-nginx"
                        }
                    },
                    {
                        "name": "date",
                        "type": "textbox",
                        "current": {
                            "value": (datetime.datetime.now() - datetime.timedelta(days=1)).strftime("%Y-%m-%d")
                        }
                    }
                ]
            },
            "time": {
                "from": "now-1d",
                "to": "now"
            },
            "refresh": "1m"
        }
    }

    return json.dumps(dashboard_config, indent=2, ensure_ascii=False)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Nginxé›†ç¾¤ç›‘æ§æ—¥æŠ¥è‡ªåŠ¨åŒ–ç”Ÿæˆå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
    ä½¿ç”¨ç¤ºä¾‹:
      %(prog)s --url http://nightingale.company.com --datasource-id 1
      %(prog)s --url http://nightingale.company.com --datasource-id 1 --date 2024-01-15
      %(prog)s --url http://nightingale.company.com --datasource-id 1 --clusters prod-web,prod-api --weekly
      %(prog)s --url http://nightingale.company.com --datasource-id 1 --username admin --password secret
      %(prog)s --generate-dashboard > nginx_dashboard.json
            """
    )

    # å¿…éœ€å‚æ•°
    parser.add_argument('--url', default='http://11.11.11.11:17000',
                        help='å¤œèºæœåŠ¡åœ°å€ (é»˜è®¤: http://11.11.11.11:17000)')
    parser.add_argument('--datasource-id', type=int, default=1,
                        help='Prometheusæ•°æ®æºID (é»˜è®¤: 1)')

    # è®¤è¯å‚æ•°
    parser.add_argument('--username', default='root',
                        help='ç™»å½•ç”¨æˆ·å (é»˜è®¤: root)')
    parser.add_argument('--password', default='root',
                        help='ç™»å½•å¯†ç  (é»˜è®¤: root)')

    # æŠ¥å‘Šå‚æ•°
    parser.add_argument('--date',
                        default=(datetime.datetime.now() - datetime.timedelta(days=6)).strftime("%Y-%m-%d"),
                        help='ç»Ÿè®¡æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD, é»˜è®¤: æ˜¨å¤©)')
    parser.add_argument('--clusters',
                        default='self-prod-nginx,zgtapp-prod-nginx',
                        help='ç›‘æ§é›†ç¾¤åˆ—è¡¨ï¼Œé€—å·åˆ†éš” (é»˜è®¤: self-prod-nginx,zgtapp-prod-nginx)')

    # æŠ¥å‘Šç±»å‹
    report_group = parser.add_mutually_exclusive_group()
    report_group.add_argument('--daily', action='store_true', default=True,
                              help='ç”Ÿæˆæ—¥æŠ¥ (é»˜è®¤)')
    report_group.add_argument('--weekly', action='store_true',
                              help='ç”Ÿæˆå‘¨æŠ¥')
    report_group.add_argument('--monthly', action='store_true',
                              help='ç”ŸæˆæœˆæŠ¥')

    # è¾“å‡ºé€‰é¡¹
    parser.add_argument('--no-comparison', action='store_true',
                        help='ä¸åŒ…å«ç¯æ¯”å¯¹æ¯”æ•°æ®')
    parser.add_argument('--output', '-o',
                        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: è¾“å‡ºåˆ°æ§åˆ¶å°)')
    parser.add_argument('--generate-dashboard', action='store_true',
                        help='ç”Ÿæˆå¤œèºç›‘æ§å¤§å±é…ç½®')

    # è°ƒè¯•é€‰é¡¹
    parser.add_argument('--debug', action='store_true',
                        help='å¯ç”¨è°ƒè¯•æ¨¡å¼')

    args = parser.parse_args()

    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)

    # ç”Ÿæˆç›‘æ§å¤§å±é…ç½®
    if args.generate_dashboard:
        print("# å¤œèºç›‘æ§å¤§å±é…ç½® - Nginxæ—¥æŠ¥")
        print("# ä½¿ç”¨æ–¹æ³•: åœ¨å¤œèºç®¡ç†ç•Œé¢å¯¼å…¥æ­¤é…ç½®")
        print(create_nightingale_dashboard())
        return

    try:
        # ç¡®å®šæŠ¥å‘Šç±»å‹
        if args.weekly:
            report_type = ReportType.WEEKLY
        elif args.monthly:
            report_type = ReportType.MONTHLY
        else:
            report_type = ReportType.DAILY

        # è§£æé›†ç¾¤åˆ—è¡¨
        clusters = [c.strip() for c in args.clusters.split(',') if c.strip()]

        # åˆ›å»ºå®¢æˆ·ç«¯
        logger.info(f"ğŸ”— è¿æ¥å¤œèºæœåŠ¡: {args.url}")
        client = NightingaleClient(
            base_url=args.url,
            datasource_id=args.datasource_id,
            username=args.username,
            password=args.password
        )

        # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
        generator = NginxReportGenerator(client)

        # ç”ŸæˆæŠ¥å‘Š
        report_list = generator.generate_report(
            target_date=args.date,
            clusters=clusters,
            report_type=report_type,
            include_comparison=not args.no_comparison
        )

        # è¾“å‡ºæŠ¥å‘Š
        for report in report_list:
            if args.output:
                with open(args.output, 'a', encoding='utf-8') as f:
                    f.write(report)
                    f.write("\n")
                logger.info(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜è‡³: {args.output}")
            else:
                print(report)

    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        sys.exit(0)
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        if args.debug:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()