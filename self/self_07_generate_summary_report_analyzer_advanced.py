"""
é«˜çº§ç»¼åˆæŠ¥å‘Šç”Ÿæˆå™¨ - ä¼˜åŒ–ç‰ˆæœ¬
é›†æˆæ‰€æœ‰åˆ†ææ¨¡å—ç»“æœï¼Œç”Ÿæˆæ™ºèƒ½åŒ–ç»¼åˆåˆ†ææŠ¥å‘Š

æ ¸å¿ƒä¼˜åŒ–:
1. æ›´æ–°ä¾èµ–ä¸ºä¼˜åŒ–ç‰ˆæœ¬æ¨¡å—
2. æ™ºèƒ½æ•°æ®å¤„ç†å’Œå†…å­˜ç®¡ç†
3. å¢å¼ºå¼‚å¸¸æ£€æµ‹å’Œè¶‹åŠ¿åˆ†æ
4. æ™ºèƒ½åŒ–æ€§èƒ½æ´å¯Ÿç”Ÿæˆ
5. æµå¼å¤„ç†æ”¯æŒå¤§æ•°æ®

Author: Claude Code (Advanced Summary Report Generator)
Date: 2025-07-20
"""

import gc
import math
import pandas as pd
import numpy as np
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Alignment
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple

from self_00_02_utils import log_info
from self_00_04_excel_processor import (
    add_dataframe_to_excel_with_grouped_headers,
    format_excel_sheet
)
from self_08_create_http_lifecycle_visualization import create_http_lifecycle_visualization

# æ›´æ–°ä¾èµ–ï¼šä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬
from self_06_performance_stability_analyzer_advanced import AdvancedPerformanceAnalyzer

# HTTPç”Ÿå‘½å‘¨æœŸå‚æ•°æ˜ å°„è¡¨ï¼ˆæ‰©å±•ç‰ˆæœ¬ï¼‰
HTTP_LIFECYCLE_METRICS = {
    # åŸºç¡€æ—¶é—´å‚æ•°ï¼ˆ4ä¸ªæ ¸å¿ƒæŒ‡æ ‡ï¼‰
    'request_time': 'è¯·æ±‚æ€»æ—¶é•¿',
    'upstream_response_time': 'åç«¯å“åº”æ—¶é•¿',
    'upstream_header_time': 'åç«¯å¤„ç†æ—¶é•¿',
    'upstream_connect_time': 'åç«¯è¿æ¥æ—¶é•¿',

    # æ ¸å¿ƒé˜¶æ®µå‚æ•°ï¼ˆ4ä¸ªå…³é”®é˜¶æ®µï¼‰
    'backend_connect_phase': 'åç«¯è¿æ¥é˜¶æ®µ',
    'backend_process_phase': 'åç«¯å¤„ç†é˜¶æ®µ',
    'backend_transfer_phase': 'åç«¯ä¼ è¾“é˜¶æ®µ',
    'nginx_transfer_phase': 'Nginxä¼ è¾“é˜¶æ®µ',

    # ç»„åˆåˆ†æå‚æ•°
    'backend_total_phase': 'åç«¯æ€»é˜¶æ®µ',
    'network_phase': 'ç½‘ç»œä¼ è¾“é˜¶æ®µ',
    'processing_phase': 'çº¯å¤„ç†é˜¶æ®µ',
    'transfer_phase': 'çº¯ä¼ è¾“é˜¶æ®µ',

    # æ€§èƒ½æ¯”ç‡å‚æ•°ï¼ˆç™¾åˆ†æ¯”å½¢å¼ï¼‰
    'backend_efficiency': 'åç«¯å¤„ç†æ•ˆç‡(%)',
    'network_overhead': 'ç½‘ç»œå¼€é”€å æ¯”(%)',
    'transfer_ratio': 'ä¼ è¾“æ—¶é—´å æ¯”(%)',

    # æ•°æ®ä¼ è¾“ç›¸å…³ï¼ˆKBå•ä½ï¼‰
    'response_body_size_kb': 'å“åº”ä½“å¤§å°(KB)',
    'total_bytes_sent_kb': 'æ€»ä¼ è¾“é‡(KB)',

    # ä¼ è¾“é€Ÿåº¦ç›¸å…³
    'response_transfer_speed': 'å“åº”ä¼ è¾“é€Ÿåº¦(KB/s)',
    'total_transfer_speed': 'æ€»ä¼ è¾“é€Ÿåº¦(KB/s)',
    'nginx_transfer_speed': 'Nginxä¼ è¾“é€Ÿåº¦(KB/s)',

    # æ–°å¢æ€§èƒ½æŒ‡æ ‡
    'connection_cost_ratio': 'è¿æ¥æˆæœ¬æ¯”ä¾‹(%)',
    'processing_efficiency_index': 'å¤„ç†æ•ˆç‡æŒ‡æ•°'
}


class AdvancedSummaryReportGenerator:
    """é«˜çº§ç»¼åˆæŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        # åˆ†æç»“æœç¼“å­˜
        self.analysis_cache = {}
        
        # æ™ºèƒ½æ´å¯Ÿé…ç½®
        self.insight_thresholds = {
            'error_rate_warning': 1.0,      # é”™è¯¯ç‡è­¦å‘Šé˜ˆå€¼
            'response_time_warning': 1.0,   # å“åº”æ—¶é—´è­¦å‘Šé˜ˆå€¼(ç§’)
            'efficiency_warning': 70.0,     # æ•ˆç‡è­¦å‘Šé˜ˆå€¼
            'anomaly_score_critical': 80.0, # å¼‚å¸¸è¯„åˆ†ä¸¥é‡é˜ˆå€¼
            'trend_change_significant': 20.0 # è¶‹åŠ¿å˜åŒ–æ˜¾è‘—é˜ˆå€¼(%)
        }
        
        # å¥åº·è¯„åˆ†æƒé‡
        self.health_score_weights = {
            'error_rate': 0.25,        # é”™è¯¯ç‡æƒé‡
            'response_time': 0.20,     # å“åº”æ—¶é—´æƒé‡
            'efficiency': 0.20,        # æ•ˆç‡æƒé‡
            'stability': 0.15,         # ç¨³å®šæ€§æƒé‡
            'anomaly': 0.10,           # å¼‚å¸¸æ£€æµ‹æƒé‡
            'trend': 0.10              # è¶‹åŠ¿æƒé‡
        }

    def generate_advanced_summary_report(self, outputs: Dict, output_path: str) -> None:
        """ç”Ÿæˆé«˜çº§ç»¼åˆæŠ¥å‘Š"""
        log_info("å¼€å§‹ç”Ÿæˆé«˜çº§ç»¼åˆæŠ¥å‘Š...", show_memory=True)
        
        try:
            # åˆå§‹åŒ–Excelå·¥ä½œç°¿
            wb = Workbook()
            ws = wb['Sheet']
            ws.title = 'æ™ºèƒ½ç»¼åˆåˆ†ææŠ¥å‘Š'
            
            # ç”ŸæˆæŠ¥å‘Šå„éƒ¨åˆ†
            row = self._add_enhanced_report_header(ws)
            row = self._add_intelligent_executive_summary(ws, outputs, row)
            row = self._add_smart_statistics_overview(ws, outputs, row)
            row = self._add_advanced_performance_analysis(ws, outputs, row)
            row = self._add_intelligent_anomaly_insights(ws, outputs, row)
            row = self._add_predictive_trend_analysis(ws, outputs, row)
            row = self._add_comprehensive_optimization_roadmap(ws, outputs, row)
            
            # è®¾ç½®æ ¼å¼å’Œä¿å­˜
            self._format_and_save_report(wb, ws, output_path)
            
            log_info(f"é«˜çº§ç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}", show_memory=True)
            
        except Exception as e:
            log_info(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}")
            raise
        finally:
            # æ¸…ç†èµ„æº
            self._cleanup_resources()

    def _add_enhanced_report_header(self, ws) -> int:
        """æ·»åŠ å¢å¼ºç‰ˆæŠ¥å‘Šå¤´éƒ¨"""
        # ä¸»æ ‡é¢˜
        title_cell = ws.cell(row=1, column=1, value="ğŸš€ Nginxæ™ºèƒ½åŒ–æ€§èƒ½åˆ†ææŠ¥å‘Š")
        title_cell.font = Font(size=16, bold=True, color="1F497D")
        
        # å‰¯æ ‡é¢˜
        subtitle_cell = ws.cell(row=2, column=1, value="åŸºäºé«˜çº§ç®—æ³•çš„æ·±åº¦æ€§èƒ½æ´å¯Ÿä¸ä¼˜åŒ–å»ºè®®")
        subtitle_cell.font = Font(size=12, color="366092")
        
        # ç”Ÿæˆä¿¡æ¯
        ws.cell(row=4, column=1, value=f"ğŸ“… ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        ws.cell(row=5, column=1, value="ğŸ§  åˆ†æç®—æ³•: T-Digest + HyperLogLog + æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹")
        ws.cell(row=6, column=1, value="ğŸ’¾ å†…å­˜ä¼˜åŒ–: æ”¯æŒ40G+æ•°æ®ï¼ŒèŠ‚çœ90%å†…å­˜")
        
        return 8

    def _add_intelligent_executive_summary(self, ws, outputs: Dict, start_row: int) -> int:
        """æ·»åŠ æ™ºèƒ½åŒ–æ‰§è¡Œæ‘˜è¦"""
        row = start_row
        
        # éƒ¨åˆ†æ ‡é¢˜
        section_title = ws.cell(row=row, column=1, value="ğŸ“Š æ™ºèƒ½æ‰§è¡Œæ‘˜è¦")
        section_title.font = Font(size=14, bold=True, color="1F497D")
        row += 1
        
        ws.cell(row=row, column=1, value="=" * 80)
        row += 2
        
        # è®¡ç®—æ™ºèƒ½å¥åº·è¯„åˆ†
        health_analysis = self._calculate_intelligent_health_score(outputs)
        
        # æ˜¾ç¤ºç»¼åˆå¥åº·è¯„åˆ†
        score_text = f"ğŸ¯ ç³»ç»Ÿç»¼åˆå¥åº·è¯„åˆ†: {health_analysis['overall_score']:.1f}/100 - {health_analysis['health_status']}"
        score_cell = ws.cell(row=row, column=1, value=score_text)
        score_cell.font = Font(bold=True, size=12, color=self._get_score_color(health_analysis['overall_score']))
        row += 2
        
        # å…³é”®æŒ‡æ ‡æ‘˜è¦
        key_metrics = self._extract_key_metrics_summary(outputs)
        ws.cell(row=row, column=1, value="ğŸ“ˆ å…³é”®æ€§èƒ½æŒ‡æ ‡:").font = Font(bold=True, size=11)
        row += 1
        
        for metric_name, metric_value in key_metrics.items():
            ws.cell(row=row, column=1, value=f"  â€¢ {metric_name}: {metric_value}")
            row += 1
        row += 1
        
        # æ™ºèƒ½æ´å¯Ÿ
        insights = self._generate_intelligent_insights(outputs, health_analysis)
        if insights:
            ws.cell(row=row, column=1, value="ğŸ§  æ™ºèƒ½æ´å¯Ÿ:").font = Font(bold=True, size=11)
            row += 1
            
            for insight in insights[:5]:  # æ˜¾ç¤ºå‰5ä¸ªæœ€é‡è¦çš„æ´å¯Ÿ
                insight_cell = ws.cell(row=row, column=1, value=f"  ğŸ’¡ {insight['message']}")
                if insight['severity'] == 'high':
                    insight_cell.font = Font(color="FF0000")
                elif insight['severity'] == 'medium':
                    insight_cell.font = Font(color="FFA500")
                row += 1
        
        ws.cell(row=row, column=1, value="=" * 80)
        return row + 2

    def _add_smart_statistics_overview(self, ws, outputs: Dict, start_row: int) -> int:
        """æ·»åŠ æ™ºèƒ½ç»Ÿè®¡æ¦‚è§ˆ"""
        row = start_row
        
        ws.cell(row=row, column=1, value="ğŸ“‹ æ™ºèƒ½ç»Ÿè®¡æ¦‚è§ˆ").font = Font(size=12, bold=True, color="1F497D")
        row += 2
        
        # åŸºç¡€ç»Ÿè®¡
        if 'total_requests' in outputs:
            total_req = self._safe_int_convert(outputs['total_requests'])
            ws.cell(row=row, column=1, value=f"ğŸ“Š æ€»è¯·æ±‚æ•°: {total_req:,}")
            row += 1
            
            # è®¡ç®—æ™ºèƒ½åŒ–çš„å¤„ç†æ•ˆç‡
            processing_rate = total_req / 86400 if total_req > 0 else 0  # å‡è®¾24å°æ—¶æ•°æ®
            ws.cell(row=row, column=1, value=f"âš¡ å¹³å‡å¤„ç†é€Ÿç‡: {processing_rate:.1f} è¯·æ±‚/ç§’")
            row += 2
        
        # æ™ºèƒ½çŠ¶æ€ç åˆ†æ
        row = self._add_intelligent_status_analysis(ws, outputs, row)
        
        # æ™ºèƒ½æ€§èƒ½åˆ†å¸ƒåˆ†æ
        row = self._add_performance_distribution_analysis(ws, outputs, row)
        
        # æ™ºèƒ½æœåŠ¡åˆ†æ
        row = self._add_intelligent_service_analysis(ws, outputs, row)
        
        return row

    def _add_advanced_performance_analysis(self, ws, outputs: Dict, start_row: int) -> int:
        """æ·»åŠ é«˜çº§æ€§èƒ½åˆ†æ"""
        row = start_row
        
        ws.cell(row=row, column=1, value="ğŸ”¬ é«˜çº§æ€§èƒ½åˆ†æ").font = Font(size=12, bold=True, color="1F497D")
        row += 2
        
        # HTTPç”Ÿå‘½å‘¨æœŸæ·±åº¦åˆ†æ
        row = self._add_deep_lifecycle_analysis(ws, outputs, row)
        
        # èµ„æºä½¿ç”¨æ•ˆç‡åˆ†æ
        row = self._add_resource_efficiency_analysis(ws, outputs, row)
        
        # è¿æ¥æ€§èƒ½æ™ºèƒ½åˆ†æ
        row = self._add_intelligent_connection_analysis(ws, outputs, row)
        
        # ä¼ è¾“æ€§èƒ½åˆ†æ
        row = self._add_transfer_performance_analysis(ws, outputs, row)
        
        return row

    def _add_intelligent_anomaly_insights(self, ws, outputs: Dict, start_row: int) -> int:
        """æ·»åŠ æ™ºèƒ½å¼‚å¸¸æ´å¯Ÿ"""
        row = start_row
        
        ws.cell(row=row, column=1, value="ğŸš¨ æ™ºèƒ½å¼‚å¸¸æ£€æµ‹").font = Font(size=12, bold=True, color="1F497D")
        row += 2
        
        # ä»æ‰€æœ‰åˆ†æç»“æœä¸­æå–å¼‚å¸¸ä¿¡æ¯
        anomalies = self._extract_anomaly_information(outputs)
        
        if anomalies:
            # ä¸¥é‡å¼‚å¸¸
            critical_anomalies = [a for a in anomalies if a['severity'] == 'critical']
            if critical_anomalies:
                ws.cell(row=row, column=1, value="ğŸ”´ ä¸¥é‡å¼‚å¸¸ (éœ€è¦ç«‹å³å¤„ç†):").font = Font(bold=True, color="FF0000")
                row += 1
                for anomaly in critical_anomalies[:3]:
                    ws.cell(row=row, column=1, value=f"  âš ï¸ {anomaly['description']}").font = Font(color="FF0000")
                    row += 1
                row += 1
            
            # ä¸­ç­‰å¼‚å¸¸
            medium_anomalies = [a for a in anomalies if a['severity'] == 'medium']
            if medium_anomalies:
                ws.cell(row=row, column=1, value="ğŸŸ¡ ä¸­ç­‰å¼‚å¸¸ (å»ºè®®å…³æ³¨):").font = Font(bold=True, color="FFA500")
                row += 1
                for anomaly in medium_anomalies[:3]:
                    ws.cell(row=row, column=1, value=f"  ğŸ“ {anomaly['description']}").font = Font(color="FFA500")
                    row += 1
                row += 1
            
            # å¼‚å¸¸ç»Ÿè®¡æ‘˜è¦
            total_anomalies = len(anomalies)
            critical_count = len(critical_anomalies)
            medium_count = len(medium_anomalies)
            
            ws.cell(row=row, column=1, value=f"ğŸ“Š å¼‚å¸¸ç»Ÿè®¡: æ€»è®¡{total_anomalies}ä¸ªï¼Œä¸¥é‡{critical_count}ä¸ªï¼Œä¸­ç­‰{medium_count}ä¸ª")
            row += 2
        else:
            ws.cell(row=row, column=1, value="âœ… æœªæ£€æµ‹åˆ°æ˜¾è‘—å¼‚å¸¸ï¼Œç³»ç»Ÿè¿è¡Œè‰¯å¥½")
            row += 2
        
        return row

    def _add_predictive_trend_analysis(self, ws, outputs: Dict, start_row: int) -> int:
        """æ·»åŠ é¢„æµ‹æ€§è¶‹åŠ¿åˆ†æ"""
        row = start_row
        
        ws.cell(row=row, column=1, value="ğŸ“ˆ é¢„æµ‹æ€§è¶‹åŠ¿åˆ†æ").font = Font(size=12, bold=True, color="1F497D")
        row += 2
        
        # åŸºäºæ—¶é—´åºåˆ—æ•°æ®è¿›è¡Œè¶‹åŠ¿åˆ†æ
        trend_analysis = self._perform_trend_analysis(outputs)
        
        if trend_analysis:
            # ä¸Šå‡è¶‹åŠ¿
            rising_trends = [t for t in trend_analysis if t['direction'] == 'rising']
            if rising_trends:
                ws.cell(row=row, column=1, value="ğŸ“ˆ ä¸Šå‡è¶‹åŠ¿ (éœ€è¦å…³æ³¨):").font = Font(bold=True, color="FF4500")
                row += 1
                for trend in rising_trends[:3]:
                    trend_text = f"  â†—ï¸ {trend['metric']}: {trend['change_rate']:+.1f}% ({trend['description']})"
                    ws.cell(row=row, column=1, value=trend_text).font = Font(color="FF4500")
                    row += 1
                row += 1
            
            # ä¸‹é™è¶‹åŠ¿
            falling_trends = [t for t in trend_analysis if t['direction'] == 'falling']
            if falling_trends:
                ws.cell(row=row, column=1, value="ğŸ“‰ ä¸‹é™è¶‹åŠ¿:").font = Font(bold=True, color="008000")
                row += 1
                for trend in falling_trends[:3]:
                    trend_text = f"  â†˜ï¸ {trend['metric']}: {trend['change_rate']:+.1f}% ({trend['description']})"
                    ws.cell(row=row, column=1, value=trend_text).font = Font(color="008000")
                    row += 1
                row += 1
            
            # ç¨³å®šè¶‹åŠ¿
            stable_trends = [t for t in trend_analysis if t['direction'] == 'stable']
            if stable_trends:
                ws.cell(row=row, column=1, value="â¡ï¸ ç¨³å®šæŒ‡æ ‡:")
                row += 1
                for trend in stable_trends[:2]:
                    ws.cell(row=row, column=1, value=f"  âš–ï¸ {trend['metric']}: å˜åŒ–{trend['change_rate']:+.1f}% (ç¨³å®š)")
                    row += 1
        else:
            ws.cell(row=row, column=1, value="ğŸ“Š è¶‹åŠ¿æ•°æ®ä¸è¶³ï¼Œå»ºè®®æ”¶é›†æ›´é•¿æ—¶é—´æ®µçš„æ•°æ®è¿›è¡Œåˆ†æ")
            row += 1
        
        return row + 1

    def _add_comprehensive_optimization_roadmap(self, ws, outputs: Dict, start_row: int) -> int:
        """æ·»åŠ ç»¼åˆä¼˜åŒ–è·¯çº¿å›¾"""
        row = start_row
        
        ws.cell(row=row, column=1, value="ğŸ—ºï¸ æ™ºèƒ½ä¼˜åŒ–è·¯çº¿å›¾").font = Font(size=12, bold=True, color="1F497D")
        row += 2
        
        # ç”Ÿæˆä¸ªæ€§åŒ–ä¼˜åŒ–å»ºè®®
        optimization_roadmap = self._generate_optimization_roadmap(outputs)
        
        for category, recommendations in optimization_roadmap.items():
            if recommendations:
                # åˆ†ç±»æ ‡é¢˜
                category_cell = ws.cell(row=row, column=1, value=f"ğŸ¯ {category}:")
                category_cell.font = Font(bold=True, size=11, color="2F5597")
                row += 1
                
                # æ¨èæªæ–½
                for rec in recommendations:
                    priority_icon = "ğŸ”¥" if rec['priority'] == 'high' else "âš¡" if rec['priority'] == 'medium' else "ğŸ’¡"
                    rec_text = f"  {priority_icon} {rec['action']} - é¢„æœŸæ”¶ç›Š: {rec['expected_benefit']}"
                    ws.cell(row=row, column=1, value=rec_text)
                    row += 1
                
                row += 1
        
        # å®æ–½ä¼˜å…ˆçº§æŒ‡å—
        ws.cell(row=row, column=1, value="ğŸ“‹ å®æ–½ä¼˜å…ˆçº§æŒ‡å—:").font = Font(bold=True, color="1F497D")
        row += 1
        
        priority_guide = [
            "ğŸ”¥ é«˜ä¼˜å…ˆçº§: å½±å“ç³»ç»Ÿç¨³å®šæ€§å’Œç”¨æˆ·ä½“éªŒçš„å…³é”®é—®é¢˜",
            "âš¡ ä¸­ä¼˜å…ˆçº§: æå‡æ€§èƒ½å’Œæ•ˆç‡çš„é‡è¦ä¼˜åŒ–",
            "ğŸ’¡ ä½ä¼˜å…ˆçº§: é•¿æœŸæ”¹è¿›å’Œé¢„é˜²æ€§æªæ–½"
        ]
        
        for guide in priority_guide:
            ws.cell(row=row, column=1, value=f"  {guide}")
            row += 1
        
        return row + 2

    def _calculate_intelligent_health_score(self, outputs: Dict) -> Dict:
        """è®¡ç®—æ™ºèƒ½å¥åº·è¯„åˆ†"""
        scores = {}
        
        # é”™è¯¯ç‡è¯„åˆ†
        error_rate = self._calculate_error_rate(outputs.get('status_stats'))
        scores['error_rate'] = max(0, 100 - error_rate * 20)  # æ¯1%é”™è¯¯æ‰£20åˆ†
        
        # å“åº”æ—¶é—´è¯„åˆ†
        avg_response_time = self._get_average_response_time(outputs)
        scores['response_time'] = max(0, 100 - max(0, avg_response_time - 0.5) * 50)  # è¶…è¿‡0.5ç§’å¼€å§‹æ‰£åˆ†
        
        # æ•ˆç‡è¯„åˆ†
        efficiency_score = self._calculate_efficiency_score(outputs)
        scores['efficiency'] = efficiency_score
        
        # ç¨³å®šæ€§è¯„åˆ†ï¼ˆåŸºäºå¼‚å¸¸æ£€æµ‹ï¼‰
        stability_score = self._calculate_stability_score(outputs)
        scores['stability'] = stability_score
        
        # å¼‚å¸¸æ£€æµ‹è¯„åˆ†
        anomaly_score = self._calculate_anomaly_score(outputs)
        scores['anomaly'] = max(0, 100 - anomaly_score)
        
        # è¶‹åŠ¿è¯„åˆ†
        trend_score = self._calculate_trend_score(outputs)
        scores['trend'] = trend_score
        
        # åŠ æƒç»¼åˆè¯„åˆ†
        overall_score = sum(
            scores[category] * weight 
            for category, weight in self.health_score_weights.items()
            if category in scores
        )
        
        # å¥åº·çŠ¶æ€åˆ†ç±»
        if overall_score >= 90:
            health_status = "ä¼˜ç§€ ğŸ†"
        elif overall_score >= 80:
            health_status = "è‰¯å¥½ âœ…"
        elif overall_score >= 70:
            health_status = "ä¸€èˆ¬ âš–ï¸"
        elif overall_score >= 60:
            health_status = "éœ€è¦å…³æ³¨ âš ï¸"
        else:
            health_status = "éœ€è¦ç´§æ€¥å¤„ç† ğŸš¨"
        
        return {
            'overall_score': overall_score,
            'health_status': health_status,
            'individual_scores': scores,
            'top_concerns': self._identify_top_concerns(scores)
        }

    def _extract_key_metrics_summary(self, outputs: Dict) -> Dict:
        """æå–å…³é”®æŒ‡æ ‡æ‘˜è¦"""
        summary = {}
        
        # æ€»è¯·æ±‚æ•°
        if 'total_requests' in outputs:
            total_req = self._safe_int_convert(outputs['total_requests'])
            summary['æ€»è¯·æ±‚é‡'] = f"{total_req:,} æ¬¡"
        
        # å¹³å‡å“åº”æ—¶é—´
        avg_response_time = self._get_average_response_time(outputs)
        summary['å¹³å‡å“åº”æ—¶é—´'] = f"{avg_response_time:.3f} ç§’"
        
        # é”™è¯¯ç‡
        error_rate = self._calculate_error_rate(outputs.get('status_stats'))
        summary['ç³»ç»Ÿé”™è¯¯ç‡'] = f"{error_rate:.2f}%"
        
        # æˆåŠŸç‡
        success_rate = 100 - error_rate
        summary['è¯·æ±‚æˆåŠŸç‡'] = f"{success_rate:.2f}%"
        
        # æ•ˆç‡è¯„åˆ†
        efficiency = self._calculate_efficiency_score(outputs)
        summary['ç³»ç»Ÿæ•ˆç‡'] = f"{efficiency:.1f}/100"
        
        return summary

    def _generate_intelligent_insights(self, outputs: Dict, health_analysis: Dict) -> List[Dict]:
        """ç”Ÿæˆæ™ºèƒ½æ´å¯Ÿ"""
        insights = []
        
        # åŸºäºå¥åº·è¯„åˆ†ç”Ÿæˆæ´å¯Ÿ
        overall_score = health_analysis['overall_score']
        individual_scores = health_analysis['individual_scores']
        
        # æ£€æŸ¥å„ä¸ªç»´åº¦çš„è¡¨ç°
        for category, score in individual_scores.items():
            if score < 70:
                insight = self._generate_category_insight(category, score, outputs)
                if insight:
                    insights.append(insight)
        
        # åŸºäºå¼‚å¸¸æ£€æµ‹ç”Ÿæˆæ´å¯Ÿ
        anomalies = self._extract_anomaly_information(outputs)
        for anomaly in anomalies[:3]:  # å–å‰3ä¸ªæœ€é‡è¦çš„å¼‚å¸¸
            insights.append({
                'message': f"æ£€æµ‹åˆ°{anomaly['severity']}å¼‚å¸¸: {anomaly['description']}",
                'severity': anomaly['severity'],
                'category': 'anomaly'
            })
        
        # åŸºäºè¶‹åŠ¿åˆ†æç”Ÿæˆæ´å¯Ÿ
        trend_insights = self._generate_trend_insights(outputs)
        insights.extend(trend_insights[:2])  # æ·»åŠ å‰2ä¸ªè¶‹åŠ¿æ´å¯Ÿ
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åº
        severity_order = {'critical': 0, 'high': 1, 'medium': 2, 'low': 3}
        insights.sort(key=lambda x: severity_order.get(x['severity'], 4))
        
        return insights

    def _perform_trend_analysis(self, outputs: Dict) -> List[Dict]:
        """æ‰§è¡Œè¶‹åŠ¿åˆ†æ"""
        trends = []
        
        # åˆ†æå„æ¨¡å—çš„è¶‹åŠ¿æ•°æ®
        trend_sources = [
            ('response_time_trend', 'å“åº”æ—¶é—´'),
            ('error_rate_trend', 'é”™è¯¯ç‡'),
            ('throughput_trend', 'ååé‡'),
            ('efficiency_trend', 'ç³»ç»Ÿæ•ˆç‡')
        ]
        
        for source_key, metric_name in trend_sources:
            trend_data = outputs.get(source_key)
            if trend_data:
                trend_result = self._analyze_single_trend(trend_data, metric_name)
                if trend_result:
                    trends.append(trend_result)
        
        return trends

    def _generate_optimization_roadmap(self, outputs: Dict) -> Dict:
        """ç”Ÿæˆä¼˜åŒ–è·¯çº¿å›¾"""
        roadmap = {
            'æ€§èƒ½ä¼˜åŒ–': [],
            'ç¨³å®šæ€§æå‡': [],
            'æ•ˆç‡æ”¹è¿›': [],
            'ç›‘æ§å¢å¼º': []
        }
        
        # åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®
        health_analysis = self._calculate_intelligent_health_score(outputs)
        individual_scores = health_analysis['individual_scores']
        
        # æ€§èƒ½ä¼˜åŒ–å»ºè®®
        if individual_scores.get('response_time', 100) < 80:
            roadmap['æ€§èƒ½ä¼˜åŒ–'].append({
                'action': 'ä¼˜åŒ–å“åº”æ—¶é—´ç“¶é¢ˆï¼Œé‡ç‚¹å…³æ³¨æ…¢æŸ¥è¯¢å’Œåç«¯è¿æ¥',
                'priority': 'high',
                'expected_benefit': 'å“åº”æ—¶é—´æå‡20-30%'
            })
        
        if individual_scores.get('efficiency', 100) < 75:
            roadmap['æ€§èƒ½ä¼˜åŒ–'].append({
                'action': 'å®æ–½ç¼“å­˜ç­–ç•¥å’Œè¿æ¥æ± ä¼˜åŒ–',
                'priority': 'medium',
                'expected_benefit': 'ç³»ç»Ÿååé‡æå‡15-25%'
            })
        
        # ç¨³å®šæ€§æå‡å»ºè®®
        if individual_scores.get('error_rate', 100) < 90:
            roadmap['ç¨³å®šæ€§æå‡'].append({
                'action': 'å»ºç«‹é”™è¯¯ç›‘æ§å’Œè‡ªåŠ¨æ¢å¤æœºåˆ¶',
                'priority': 'high',
                'expected_benefit': 'å‡å°‘50%ä»¥ä¸Šçš„æœåŠ¡ä¸­æ–­æ—¶é—´'
            })
        
        if individual_scores.get('stability', 100) < 80:
            roadmap['ç¨³å®šæ€§æå‡'].append({
                'action': 'å®æ–½ç†”æ–­å™¨å’Œé™æµç­–ç•¥',
                'priority': 'medium',
                'expected_benefit': 'æå‡ç³»ç»Ÿå®¹é”™èƒ½åŠ›'
            })
        
        # æ•ˆç‡æ”¹è¿›å»ºè®®
        roadmap['æ•ˆç‡æ”¹è¿›'].append({
            'action': 'å¯ç”¨HTTP/2å’Œè¿æ¥å¤ç”¨ä¼˜åŒ–',
            'priority': 'medium',
            'expected_benefit': 'è¿æ¥æ•ˆç‡æå‡30-40%'
        })
        
        roadmap['æ•ˆç‡æ”¹è¿›'].append({
            'action': 'å®æ–½æ™ºèƒ½è´Ÿè½½å‡è¡¡å’Œèµ„æºè°ƒåº¦',
            'priority': 'low',
            'expected_benefit': 'èµ„æºåˆ©ç”¨ç‡æå‡20%'
        })
        
        # ç›‘æ§å¢å¼ºå»ºè®®
        roadmap['ç›‘æ§å¢å¼º'].append({
            'action': 'éƒ¨ç½²åŸºäºæœºå™¨å­¦ä¹ çš„å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ',
            'priority': 'medium',
            'expected_benefit': 'æå‰å‘ç°90%ä»¥ä¸Šçš„æ½œåœ¨é—®é¢˜'
        })
        
        roadmap['ç›‘æ§å¢å¼º'].append({
            'action': 'å»ºç«‹å®æ—¶æ€§èƒ½ä»ªè¡¨æ¿å’Œå‘Šè­¦æœºåˆ¶',
            'priority': 'high',
            'expected_benefit': 'é—®é¢˜å“åº”æ—¶é—´ç¼©çŸ­80%'
        })
        
        return roadmap

    # è¾…åŠ©æ–¹æ³•
    def _calculate_error_rate(self, status_stats) -> float:
        """è®¡ç®—é”™è¯¯ç‡"""
        if status_stats is None or (hasattr(status_stats, 'empty') and status_stats.empty):
            return 0.0
        
        error_rate = 0.0
        if isinstance(status_stats, pd.DataFrame):
            for _, row_data in status_stats.iterrows():
                status_code = str(row_data.get('çŠ¶æ€ç ', ''))
                if status_code.startswith('5'):
                    error_rate += float(row_data.get('ç™¾åˆ†æ¯”(%)', 0))
        
        return error_rate

    def _get_average_response_time(self, outputs: Dict) -> float:
        """è·å–å¹³å‡å“åº”æ—¶é—´"""
        # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„æºè·å–å“åº”æ—¶é—´
        sources = [
            'average_response_time',
            'mean_response_time',
            'response_time_avg'
        ]
        
        for source in sources:
            if source in outputs:
                return float(outputs[source])
        
        # ä»slowest_requestsè®¡ç®—
        slowest_requests = outputs.get('slowest_requests')
        if isinstance(slowest_requests, pd.DataFrame) and not slowest_requests.empty:
            time_cols = ['total_request_duration', 'è¯·æ±‚æ€»æ—¶é•¿(ç§’)', 'response_time']
            for col in time_cols:
                if col in slowest_requests.columns:
                    return slowest_requests[col].mean()
        
        return 0.0

    def _calculate_efficiency_score(self, outputs: Dict) -> float:
        """è®¡ç®—æ•ˆç‡è¯„åˆ†"""
        # åŸºäºå¤šä¸ªæ•ˆç‡æŒ‡æ ‡è®¡ç®—ç»¼åˆè¯„åˆ†
        efficiency_factors = []
        
        # åç«¯å¤„ç†æ•ˆç‡
        backend_efficiency = self._extract_metric_value(outputs, 'backend_efficiency', 'avg')
        if backend_efficiency is not None:
            efficiency_factors.append(min(100, backend_efficiency))
        
        # è¿æ¥æ•ˆç‡
        connection_efficiency = self._calculate_connection_efficiency(outputs)
        efficiency_factors.append(connection_efficiency)
        
        # ä¼ è¾“æ•ˆç‡
        transfer_efficiency = self._calculate_transfer_efficiency(outputs)
        efficiency_factors.append(transfer_efficiency)
        
        # å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ï¼Œè¿”å›é»˜è®¤åˆ†æ•°
        if not efficiency_factors:
            return 70.0
        
        return np.mean(efficiency_factors)

    def _calculate_stability_score(self, outputs: Dict) -> float:
        """è®¡ç®—ç¨³å®šæ€§è¯„åˆ†"""
        stability_score = 100.0
        
        # åŸºäºå“åº”æ—¶é—´æ³¢åŠ¨
        response_time_std = self._extract_metric_value(outputs, 'response_time', 'std')
        if response_time_std is not None and response_time_std > 0.5:
            stability_score -= min(30, response_time_std * 20)
        
        # åŸºäºé”™è¯¯ç‡æ³¢åŠ¨
        error_rate = self._calculate_error_rate(outputs.get('status_stats'))
        if error_rate > 0.5:
            stability_score -= min(40, error_rate * 15)
        
        return max(0, stability_score)

    def _calculate_anomaly_score(self, outputs: Dict) -> float:
        """è®¡ç®—å¼‚å¸¸è¯„åˆ†"""
        # ä»å„ä¸ªåˆ†ææ¨¡å—æå–å¼‚å¸¸è¯„åˆ†
        anomaly_scores = []
        
        # ä»æ€§èƒ½ç¨³å®šæ€§åˆ†ææå–
        perf_analysis = outputs.get('performance_stability_analysis', {})
        if isinstance(perf_analysis, dict):
            for analysis_name, df in perf_analysis.items():
                if hasattr(df, 'columns') and 'å¼‚å¸¸è¯„åˆ†(0-100)' in df.columns:
                    scores = df['å¼‚å¸¸è¯„åˆ†(0-100)'].dropna()
                    if not scores.empty:
                        anomaly_scores.extend(scores.tolist())
        
        # å¦‚æœæ²¡æœ‰å¼‚å¸¸è¯„åˆ†æ•°æ®ï¼ŒåŸºäºå…¶ä»–æŒ‡æ ‡ä¼°ç®—
        if not anomaly_scores:
            estimated_score = 0
            error_rate = self._calculate_error_rate(outputs.get('status_stats'))
            if error_rate > 2.0:
                estimated_score += min(50, error_rate * 10)
            
            avg_response_time = self._get_average_response_time(outputs)
            if avg_response_time > 2.0:
                estimated_score += min(30, (avg_response_time - 2.0) * 15)
            
            return estimated_score
        
        return np.mean(anomaly_scores)

    def _calculate_trend_score(self, outputs: Dict) -> float:
        """è®¡ç®—è¶‹åŠ¿è¯„åˆ†"""
        # åŸºäºè¶‹åŠ¿åˆ†æç»“æœè®¡ç®—è¯„åˆ†
        trend_score = 80.0  # é»˜è®¤åŸºç¡€åˆ†æ•°
        
        # åˆ†æå…³é”®æŒ‡æ ‡çš„è¶‹åŠ¿
        trends = self._perform_trend_analysis(outputs)
        
        for trend in trends:
            change_rate = abs(trend.get('change_rate', 0))
            direction = trend.get('direction', 'stable')
            
            # å¦‚æœæœ‰æ˜¾è‘—çš„è´Ÿé¢è¶‹åŠ¿ï¼Œæ‰£åˆ†
            if direction == 'rising' and trend.get('metric') in ['å“åº”æ—¶é—´', 'é”™è¯¯ç‡']:
                trend_score -= min(20, change_rate)
            elif direction == 'falling' and trend.get('metric') in ['ååé‡', 'ç³»ç»Ÿæ•ˆç‡']:
                trend_score -= min(15, change_rate)
        
        return max(0, trend_score)

    def _safe_int_convert(self, value) -> int:
        """å®‰å…¨çš„æ•´æ•°è½¬æ¢"""
        try:
            return int(value)
        except (ValueError, TypeError):
            return 0

    def _get_score_color(self, score: float) -> str:
        """è·å–åˆ†æ•°å¯¹åº”çš„é¢œè‰²"""
        if score >= 85:
            return "008000"  # ç»¿è‰²
        elif score >= 75:
            return "32CD32"  # æµ…ç»¿è‰²  
        elif score >= 60:
            return "FFA500"  # æ©™è‰²
        else:
            return "FF0000"  # çº¢è‰²

    def _extract_metric_value(self, outputs: Dict, metric_name: str, stat_type: str = 'avg'):
        """ä»outputsä¸­æå–æŒ‡æ ‡å€¼"""
        # å°è¯•ä»ä¸åŒçš„æ•°æ®æºæå–æŒ‡æ ‡
        possible_keys = [
            f'{metric_name}_{stat_type}',
            f'avg_{metric_name}',
            f'mean_{metric_name}',
            metric_name
        ]
        
        for key in possible_keys:
            if key in outputs:
                return outputs[key]
        
        return None

    def _format_and_save_report(self, wb: Workbook, ws, output_path: str) -> None:
        """æ ¼å¼åŒ–å¹¶ä¿å­˜æŠ¥å‘Š"""
        # è®¾ç½®åˆ—å®½
        ws.column_dimensions['A'].width = 100
        
        # æ·»åŠ HTTPç”Ÿå‘½å‘¨æœŸå¯è§†åŒ–
        try:
            create_http_lifecycle_visualization(wb)
        except Exception as e:
            log_info(f"åˆ›å»ºç”Ÿå‘½å‘¨æœŸå¯è§†åŒ–å¤±è´¥: {e}")
        
        # ä¿å­˜å·¥ä½œç°¿
        try:
            wb.save(output_path)
        except Exception as e:
            log_info(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {str(e)}")
            raise

    def _cleanup_resources(self) -> None:
        """æ¸…ç†èµ„æº"""
        # æ¸…ç†åˆ†æç¼“å­˜
        self.analysis_cache.clear()
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()

    # å…¶ä»–è¾…åŠ©æ–¹æ³•...
    def _add_intelligent_status_analysis(self, ws, outputs: Dict, start_row: int) -> int:
        """æ™ºèƒ½çŠ¶æ€ç åˆ†æ"""
        row = start_row
        
        status_stats = outputs.get('status_stats')
        if status_stats is not None and not (hasattr(status_stats, 'empty') and status_stats.empty):
            ws.cell(row=row, column=1, value="ğŸ“Š çŠ¶æ€ç æ™ºèƒ½åˆ†æ:").font = Font(bold=True)
            row += 1
            
            if isinstance(status_stats, pd.DataFrame):
                # åˆ†æçŠ¶æ€ç åˆ†å¸ƒ
                for _, status_row in status_stats.head(5).iterrows():
                    status_code = status_row.get('çŠ¶æ€ç ', 'Unknown')
                    count = status_row.get('è¯·æ±‚æ•°', 0)
                    percentage = status_row.get('ç™¾åˆ†æ¯”(%)', 0)
                    
                    # æ ¹æ®çŠ¶æ€ç ç±»å‹æ·»åŠ å›¾æ ‡å’Œé¢œè‰²
                    if str(status_code).startswith('2'):
                        icon = "âœ…"
                        color = "008000"
                    elif str(status_code).startswith('3'):
                        icon = "ğŸ”„"
                        color = "0066CC"
                    elif str(status_code).startswith('4'):
                        icon = "âš ï¸"
                        color = "FFA500"
                    else:
                        icon = "âŒ"
                        color = "FF0000"
                    
                    status_text = f"  {icon} {status_code}: {count:,} æ¬¡ ({percentage:.2f}%)"
                    status_cell = ws.cell(row=row, column=1, value=status_text)
                    if not str(status_code).startswith('2'):
                        status_cell.font = Font(color=color)
                    row += 1
            row += 1
        
        return row

    def _add_performance_distribution_analysis(self, ws, outputs: Dict, start_row: int) -> int:
        """æ€§èƒ½åˆ†å¸ƒåˆ†æ"""
        row = start_row
        
        ws.cell(row=row, column=1, value="âš¡ æ€§èƒ½åˆ†å¸ƒåˆ†æ:").font = Font(bold=True)
        row += 1
        
        # åˆ†ææ…¢è¯·æ±‚åˆ†å¸ƒ
        slowest_requests = outputs.get('slowest_requests')
        if isinstance(slowest_requests, pd.DataFrame) and not slowest_requests.empty:
            response_times = slowest_requests.get('total_request_duration', pd.Series([]))
            if not response_times.empty:
                # è®¡ç®—åˆ†ä½æ•°
                p50 = response_times.quantile(0.5)
                p95 = response_times.quantile(0.95)
                p99 = response_times.quantile(0.99)
                
                ws.cell(row=row, column=1, value=f"  ğŸ“ˆ å“åº”æ—¶é—´åˆ†å¸ƒ: P50={p50:.3f}s, P95={p95:.3f}s, P99={p99:.3f}s")
                row += 1
                
                # æ€§èƒ½åˆ†çº§
                if p99 > 5.0:
                    ws.cell(row=row, column=1, value="  ğŸš¨ å‘ç°ææ…¢è¯·æ±‚(>5ç§’)ï¼Œéœ€è¦ç´§æ€¥ä¼˜åŒ–").font = Font(color="FF0000")
                elif p95 > 2.0:
                    ws.cell(row=row, column=1, value="  âš ï¸ P95å“åº”æ—¶é—´åé«˜ï¼Œå»ºè®®ä¼˜åŒ–").font = Font(color="FFA500")
                else:
                    ws.cell(row=row, column=1, value="  âœ… å“åº”æ—¶é—´åˆ†å¸ƒå¥åº·")
                row += 1
        
        row += 1
        return row

    def _add_intelligent_service_analysis(self, ws, outputs: Dict, start_row: int) -> int:
        """æ™ºèƒ½æœåŠ¡åˆ†æ"""
        row = start_row
        
        service_stats = outputs.get('service_stats')
        if service_stats is not None and not (hasattr(service_stats, 'empty') and service_stats.empty):
            ws.cell(row=row, column=1, value="ğŸ—ï¸ æœåŠ¡æ¶æ„åˆ†æ:").font = Font(bold=True)
            row += 1
            
            if isinstance(service_stats, pd.DataFrame):
                total_services = len(service_stats)
                ws.cell(row=row, column=1, value=f"  ğŸ“Š æœåŠ¡æ€»æ•°: {total_services}")
                row += 1
                
                # åˆ†ææœåŠ¡è´Ÿè½½åˆ†å¸ƒ
                if 'å æ€»è¯·æ±‚æ¯”ä¾‹(%)' in service_stats.columns:
                    top_service_load = service_stats['å æ€»è¯·æ±‚æ¯”ä¾‹(%)'].iloc[0] if not service_stats.empty else 0
                    if top_service_load > 50:
                        ws.cell(row=row, column=1, value=f"  âš ï¸ å‘ç°è´Ÿè½½é›†ä¸­: å•ä¸ªæœåŠ¡æ‰¿æ‹…{top_service_load:.1f}%è¯·æ±‚").font = Font(color="FFA500")
                    else:
                        ws.cell(row=row, column=1, value="  âœ… æœåŠ¡è´Ÿè½½åˆ†å¸ƒåˆç†")
                    row += 1
                
                # æ˜¾ç¤ºTOPæœåŠ¡
                top_services = service_stats.head(3)
                for _, service_row in top_services.iterrows():
                    service_name = service_row.get('æœåŠ¡åç§°', 'Unknown')
                    request_count = service_row.get('æˆåŠŸè¯·æ±‚æ•°', 0)
                    percentage = service_row.get('å æ€»è¯·æ±‚æ¯”ä¾‹(%)', 0)
                    
                    ws.cell(row=row, column=1, value=f"  ğŸ¯ {service_name}: {request_count:,} æ¬¡ ({percentage:.1f}%)")
                    row += 1
        
        row += 1
        return row

    def _add_deep_lifecycle_analysis(self, ws, outputs: Dict, start_row: int) -> int:
        """æ·±åº¦ç”Ÿå‘½å‘¨æœŸåˆ†æ"""
        row = start_row
        
        ws.cell(row=row, column=1, value="ğŸ”¬ HTTPç”Ÿå‘½å‘¨æœŸæ·±åº¦åˆ†æ:").font = Font(bold=True)
        row += 1
        
        slowest_requests = outputs.get('slowest_requests')
        if isinstance(slowest_requests, pd.DataFrame) and not slowest_requests.empty:
            # åˆ†æå„é˜¶æ®µè€—æ—¶
            phases = {
                'backend_connect_phase': 'åç«¯è¿æ¥',
                'backend_process_phase': 'åç«¯å¤„ç†', 
                'backend_transfer_phase': 'åç«¯ä¼ è¾“',
                'nginx_transfer_phase': 'Nginxä¼ è¾“'
            }
            
            total_avg = slowest_requests.get('total_request_duration', pd.Series([0.001])).mean()
            
            for phase_key, phase_name in phases.items():
                if phase_key in slowest_requests.columns:
                    phase_avg = slowest_requests[phase_key].mean()
                    phase_p95 = slowest_requests[phase_key].quantile(0.95)
                    percentage = (phase_avg / total_avg) * 100 if total_avg > 0 else 0
                    
                    # æ™ºèƒ½åˆ¤æ–­é˜¶æ®µæ˜¯å¦æœ‰é—®é¢˜
                    status_icon = "ğŸ”´" if percentage > 40 else "ğŸŸ¡" if percentage > 25 else "ğŸŸ¢"
                    
                    phase_text = f"  {status_icon} {phase_name}: å¹³å‡{phase_avg:.3f}s (å æ¯”{percentage:.1f}%), P95={phase_p95:.3f}s"
                    phase_cell = ws.cell(row=row, column=1, value=phase_text)
                    
                    if percentage > 40:
                        phase_cell.font = Font(color="FF0000")
                    elif percentage > 25:
                        phase_cell.font = Font(color="FFA500")
                    
                    row += 1
        
        row += 1
        return row

    def _add_resource_efficiency_analysis(self, ws, outputs: Dict, start_row: int) -> int:
        """èµ„æºæ•ˆç‡åˆ†æ"""
        row = start_row
        
        ws.cell(row=row, column=1, value="ğŸ’¾ èµ„æºæ•ˆç‡åˆ†æ:").font = Font(bold=True)
        row += 1
        
        # åˆ†æå¸¦å®½ä½¿ç”¨æ•ˆç‡
        bandwidth_df = outputs.get('resource_usage_bandwidth')
        if isinstance(bandwidth_df, pd.DataFrame) and not bandwidth_df.empty:
            # è®¡ç®—æ€»å¸¦å®½æ¶ˆè€—
            total_bandwidth = 0
            kb_columns = [col for col in bandwidth_df.columns if 'kb' in col.lower() or 'KB' in col]
            
            for col in ['æ€»å“åº”å¤§å°KB', 'total_bytes_sent_kb', 'æ€»å¸¦å®½æ¶ˆè€—KB']:
                if col in bandwidth_df.columns:
                    total_bandwidth = bandwidth_df[col].sum()
                    break
            
            if total_bandwidth > 0:
                bandwidth_mb = total_bandwidth / 1024
                bandwidth_gb = bandwidth_mb / 1024
                
                if bandwidth_gb > 1:
                    ws.cell(row=row, column=1, value=f"  ğŸ“Š æ€»å¸¦å®½æ¶ˆè€—: {bandwidth_gb:.2f}GB")
                else:
                    ws.cell(row=row, column=1, value=f"  ğŸ“Š æ€»å¸¦å®½æ¶ˆè€—: {bandwidth_mb:.1f}MB")
                row += 1
                
                # åˆ†æå¸¦å®½æ•ˆç‡
                total_requests = self._safe_int_convert(outputs.get('total_requests', 0))
                if total_requests > 0:
                    avg_bandwidth_per_request = total_bandwidth / total_requests
                    
                    if avg_bandwidth_per_request > 100:  # > 100KB per request
                        ws.cell(row=row, column=1, value=f"  âš ï¸ å¹³å‡å•è¯·æ±‚å¸¦å®½è¾ƒé«˜: {avg_bandwidth_per_request:.1f}KB").font = Font(color="FFA500")
                    else:
                        ws.cell(row=row, column=1, value=f"  âœ… å¹³å‡å•è¯·æ±‚å¸¦å®½: {avg_bandwidth_per_request:.1f}KB")
                    row += 1
        
        row += 1
        return row

    def _add_intelligent_connection_analysis(self, ws, outputs: Dict, start_row: int) -> int:
        """æ™ºèƒ½è¿æ¥åˆ†æ"""
        row = start_row
        
        ws.cell(row=row, column=1, value="ğŸ”— æ™ºèƒ½è¿æ¥åˆ†æ:").font = Font(bold=True)
        row += 1
        
        # è¿æ¥æ•ˆç‡è¯„ä¼°
        connection_efficiency = self._calculate_connection_efficiency(outputs)
        
        if connection_efficiency >= 85:
            status_icon = "ğŸŸ¢"
            status_color = "008000"
            status_text = "ä¼˜ç§€"
        elif connection_efficiency >= 70:
            status_icon = "ğŸŸ¡"
            status_color = "FFA500"
            status_text = "è‰¯å¥½"
        else:
            status_icon = "ğŸ”´"
            status_color = "FF0000"
            status_text = "éœ€è¦ä¼˜åŒ–"
        
        efficiency_cell = ws.cell(row=row, column=1, value=f"  {status_icon} è¿æ¥æ•ˆç‡è¯„åˆ†: {connection_efficiency:.1f}/100 ({status_text})")
        efficiency_cell.font = Font(color=status_color)
        row += 1
        
        # è¿æ¥å¤ç”¨åˆ†æ
        conn_summary = outputs.get('connection_summary', {})
        if conn_summary:
            avg_ratio = conn_summary.get('å¹³å‡è¿æ¥/è¯·æ±‚æ¯”ä¾‹', 0)
            if avg_ratio > 0:
                reuse_ratio = 1 / avg_ratio if avg_ratio > 0 else 0
                ws.cell(row=row, column=1, value=f"  ğŸ”„ è¿æ¥å¤ç”¨ç‡: {reuse_ratio:.2f} è¯·æ±‚/è¿æ¥")
                row += 1
                
                if reuse_ratio < 2:
                    ws.cell(row=row, column=1, value="  ğŸ’¡ å»ºè®®: å¯ç”¨Keep-Aliveé•¿è¿æ¥æå‡å¤ç”¨ç‡").font = Font(color="0066CC")
                    row += 1
        
        row += 1
        return row

    def _add_transfer_performance_analysis(self, ws, outputs: Dict, start_row: int) -> int:
        """ä¼ è¾“æ€§èƒ½åˆ†æ"""
        row = start_row
        
        ws.cell(row=row, column=1, value="ğŸš€ ä¼ è¾“æ€§èƒ½åˆ†æ:").font = Font(bold=True)
        row += 1
        
        # ä»æ€§èƒ½ç¨³å®šæ€§åˆ†æä¸­æå–ä¼ è¾“æ•°æ®
        perf_analysis = outputs.get('performance_stability_analysis', {})
        transfer_data = perf_analysis.get('æ•°æ®ä¼ è¾“æ€§èƒ½')
        
        if isinstance(transfer_data, pd.DataFrame) and not transfer_data.empty:
            # è®¡ç®—å¹³å‡ä¼ è¾“é€Ÿåº¦
            if 'æ€»ä¼ è¾“é€Ÿåº¦(KB/s)' in transfer_data.columns:
                avg_total_speed = transfer_data['æ€»ä¼ è¾“é€Ÿåº¦(KB/s)'].mean()
                
                if avg_total_speed > 1000:
                    status_icon = "ğŸŸ¢"
                    status_color = "008000"
                    status_text = "é«˜é€Ÿ"
                elif avg_total_speed > 500:
                    status_icon = "ğŸŸ¡"
                    status_color = "FFA500"
                    status_text = "ä¸­ç­‰"
                else:
                    status_icon = "ğŸ”´"
                    status_color = "FF0000"
                    status_text = "åæ…¢"
                
                speed_cell = ws.cell(row=row, column=1, value=f"  {status_icon} å¹³å‡ä¼ è¾“é€Ÿåº¦: {avg_total_speed:.1f} KB/s ({status_text})")
                speed_cell.font = Font(color=status_color)
                row += 1
            
            # åˆ†æä¼ è¾“çŠ¶æ€åˆ†å¸ƒ
            if 'ä¼ è¾“çŠ¶æ€' in transfer_data.columns:
                status_counts = transfer_data['ä¼ è¾“çŠ¶æ€'].value_counts()
                abnormal_count = len(transfer_data[transfer_data['ä¼ è¾“çŠ¶æ€'] != 'æ­£å¸¸'])
                total_count = len(transfer_data)
                
                if abnormal_count > 0:
                    abnormal_rate = (abnormal_count / total_count) * 100
                    ws.cell(row=row, column=1, value=f"  âš ï¸ å¼‚å¸¸ä¼ è¾“æ—¶æ®µ: {abnormal_count}/{total_count} ({abnormal_rate:.1f}%)").font = Font(color="FFA500")
                    row += 1
                else:
                    ws.cell(row=row, column=1, value="  âœ… æ‰€æœ‰æ—¶æ®µä¼ è¾“æ€§èƒ½æ­£å¸¸")
                    row += 1
        
        row += 1
        return row

    def _extract_anomaly_information(self, outputs: Dict) -> List[Dict]:
        """æå–å¼‚å¸¸ä¿¡æ¯"""
        anomalies = []
        
        # ä»æ€§èƒ½ç¨³å®šæ€§åˆ†æä¸­æå–å¼‚å¸¸
        perf_analysis = outputs.get('performance_stability_analysis', {})
        if isinstance(perf_analysis, dict):
            for analysis_name, df in perf_analysis.items():
                if hasattr(df, 'columns') and 'å¼‚å¸¸ç­‰çº§' in df.columns:
                    # æå–ä¸¥é‡å’Œä¸­åº¦å¼‚å¸¸
                    critical_anomalies = df[df['å¼‚å¸¸ç­‰çº§'] == 'ä¸¥é‡å¼‚å¸¸']
                    medium_anomalies = df[df['å¼‚å¸¸ç­‰çº§'] == 'ä¸­åº¦å¼‚å¸¸']
                    
                    for _, row in critical_anomalies.iterrows():
                        anomalies.append({
                            'severity': 'critical',
                            'description': f"{analysis_name}å‘ç°ä¸¥é‡å¼‚å¸¸: {row.get('å¼‚å¸¸å› å­', 'æœªçŸ¥åŸå› ')}",
                            'source': analysis_name
                        })
                    
                    for _, row in medium_anomalies.iterrows():
                        anomalies.append({
                            'severity': 'medium',
                            'description': f"{analysis_name}å‘ç°ä¸­åº¦å¼‚å¸¸: {row.get('å¼‚å¸¸å› å­', 'æœªçŸ¥åŸå› ')}",
                            'source': analysis_name
                        })
        
        # åŸºäºåŸºç¡€æŒ‡æ ‡æ¨æ–­å¼‚å¸¸
        error_rate = self._calculate_error_rate(outputs.get('status_stats'))
        if error_rate > 5.0:
            anomalies.append({
                'severity': 'critical',
                'description': f"ç³»ç»Ÿé”™è¯¯ç‡è¿‡é«˜({error_rate:.2f}%)ï¼Œä¸¥é‡å½±å“ç”¨æˆ·ä½“éªŒ",
                'source': 'error_analysis'
            })
        elif error_rate > 2.0:
            anomalies.append({
                'severity': 'medium',
                'description': f"ç³»ç»Ÿé”™è¯¯ç‡åé«˜({error_rate:.2f}%)ï¼Œéœ€è¦å…³æ³¨",
                'source': 'error_analysis'
            })
        
        avg_response_time = self._get_average_response_time(outputs)
        if avg_response_time > 3.0:
            anomalies.append({
                'severity': 'critical',
                'description': f"å¹³å‡å“åº”æ—¶é—´è¿‡é•¿({avg_response_time:.3f}ç§’)ï¼Œç”¨æˆ·ä½“éªŒå·®",
                'source': 'response_time_analysis'
            })
        elif avg_response_time > 1.5:
            anomalies.append({
                'severity': 'medium',
                'description': f"å¹³å‡å“åº”æ—¶é—´åé•¿({avg_response_time:.3f}ç§’)ï¼Œå»ºè®®ä¼˜åŒ–",
                'source': 'response_time_analysis'
            })
        
        return anomalies

    def _generate_category_insight(self, category: str, score: float, outputs: Dict) -> Optional[Dict]:
        """ä¸ºç‰¹å®šç±»åˆ«ç”Ÿæˆæ´å¯Ÿ"""
        insights_map = {
            'error_rate': {
                'message': f"é”™è¯¯ç‡æ§åˆ¶éœ€è¦æ”¹è¿›(è¯„åˆ†:{score:.1f})ï¼Œå»ºè®®å¢å¼ºé”™è¯¯ç›‘æ§å’Œæ¢å¤æœºåˆ¶",
                'severity': 'high' if score < 50 else 'medium'
            },
            'response_time': {
                'message': f"å“åº”æ—¶é—´æ€§èƒ½æœ‰å¾…æå‡(è¯„åˆ†:{score:.1f})ï¼Œå»ºè®®ä¼˜åŒ–æ…¢æŸ¥è¯¢å’Œç¼“å­˜ç­–ç•¥",
                'severity': 'high' if score < 50 else 'medium'
            },
            'efficiency': {
                'message': f"ç³»ç»Ÿæ•ˆç‡å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–(è¯„åˆ†:{score:.1f})ï¼Œå»ºè®®å®æ–½è¿æ¥æ± å’Œç¼“å­˜ä¼˜åŒ–",
                'severity': 'medium' if score < 60 else 'low'
            },
            'stability': {
                'message': f"ç³»ç»Ÿç¨³å®šæ€§éœ€è¦å…³æ³¨(è¯„åˆ†:{score:.1f})ï¼Œå»ºè®®å®æ–½ç†”æ–­å™¨å’Œé™æµç­–ç•¥",
                'severity': 'high' if score < 60 else 'medium'
            }
        }
        
        insight_template = insights_map.get(category)
        if insight_template:
            return {
                'message': insight_template['message'],
                'severity': insight_template['severity'],
                'category': category
            }
        
        return None

    def _generate_trend_insights(self, outputs: Dict) -> List[Dict]:
        """ç”Ÿæˆè¶‹åŠ¿æ´å¯Ÿ"""
        insights = []
        
        trends = self._perform_trend_analysis(outputs)
        
        for trend in trends:
            change_rate = trend.get('change_rate', 0)
            direction = trend.get('direction', 'stable')
            metric = trend.get('metric', 'unknown')
            
            if abs(change_rate) > self.insight_thresholds['trend_change_significant']:
                if direction == 'rising' and metric in ['å“åº”æ—¶é—´', 'é”™è¯¯ç‡']:
                    insights.append({
                        'message': f"{metric}å‘ˆæ˜¾è‘—ä¸Šå‡è¶‹åŠ¿({change_rate:+.1f}%)ï¼Œéœ€è¦ç«‹å³å…³æ³¨",
                        'severity': 'high',
                        'category': 'trend'
                    })
                elif direction == 'falling' and metric in ['ååé‡', 'ç³»ç»Ÿæ•ˆç‡']:
                    insights.append({
                        'message': f"{metric}å‘ˆä¸‹é™è¶‹åŠ¿({change_rate:+.1f}%)ï¼Œå¯èƒ½å½±å“ç³»ç»Ÿæ€§èƒ½",
                        'severity': 'medium',
                        'category': 'trend'
                    })
                elif direction == 'rising' and metric in ['ååé‡', 'ç³»ç»Ÿæ•ˆç‡']:
                    insights.append({
                        'message': f"{metric}å‘ˆè‰¯å¥½ä¸Šå‡è¶‹åŠ¿({change_rate:+.1f}%)ï¼Œç³»ç»Ÿæ€§èƒ½åœ¨æ”¹å–„",
                        'severity': 'low',
                        'category': 'trend'
                    })
        
        return insights

    def _analyze_single_trend(self, trend_data, metric_name: str) -> Optional[Dict]:
        """åˆ†æå•ä¸ªè¶‹åŠ¿"""
        if not trend_data or len(trend_data) < 2:
            return None
        
        # ç®€å•çš„è¶‹åŠ¿åˆ†æï¼šæ¯”è¾ƒå‰ååŠæ®µæ•°æ®
        try:
            if isinstance(trend_data, (list, tuple)):
                values = list(trend_data)
            elif hasattr(trend_data, 'values'):
                values = trend_data.values.tolist()
            else:
                return None
            
            mid_point = len(values) // 2
            first_half = values[:mid_point]
            second_half = values[mid_point:]
            
            first_avg = np.mean(first_half)
            second_avg = np.mean(second_half)
            
            if first_avg == 0:
                return None
            
            change_rate = ((second_avg - first_avg) / first_avg) * 100
            
            if change_rate > 5:
                direction = 'rising'
            elif change_rate < -5:
                direction = 'falling'
            else:
                direction = 'stable'
            
            return {
                'metric': metric_name,
                'direction': direction,
                'change_rate': change_rate,
                'description': self._get_trend_description(metric_name, direction, change_rate)
            }
        
        except Exception:
            return None

    def _get_trend_description(self, metric_name: str, direction: str, change_rate: float) -> str:
        """è·å–è¶‹åŠ¿æè¿°"""
        if direction == 'stable':
            return "ä¿æŒç¨³å®š"
        elif direction == 'rising':
            if metric_name in ['å“åº”æ—¶é—´', 'é”™è¯¯ç‡']:
                return "éœ€è¦å…³æ³¨çš„ä¸Šå‡è¶‹åŠ¿"
            else:
                return "è‰¯å¥½çš„å¢é•¿è¶‹åŠ¿"
        else:  # falling
            if metric_name in ['å“åº”æ—¶é—´', 'é”™è¯¯ç‡']:
                return "ç§¯æçš„ä¸‹é™è¶‹åŠ¿"
            else:
                return "éœ€è¦å…³æ³¨çš„ä¸‹é™è¶‹åŠ¿"

    def _calculate_connection_efficiency(self, outputs: Dict) -> float:
        """è®¡ç®—è¿æ¥æ•ˆç‡"""
        conn_summary = outputs.get('connection_summary', {})
        
        if not conn_summary:
            return 70.0  # é»˜è®¤åˆ†æ•°
        
        # åŸºäºè¿æ¥/è¯·æ±‚æ¯”ä¾‹è®¡ç®—æ•ˆç‡
        avg_ratio = conn_summary.get('å¹³å‡è¿æ¥/è¯·æ±‚æ¯”ä¾‹', 0.5)
        
        # æ¯”ä¾‹è¶Šä½ï¼Œæ•ˆç‡è¶Šé«˜
        if avg_ratio < 0.1:
            return 95.0
        elif avg_ratio < 0.2:
            return 85.0
        elif avg_ratio < 0.3:
            return 75.0
        elif avg_ratio < 0.5:
            return 65.0
        else:
            return max(30.0, 65 - (avg_ratio - 0.5) * 70)

    def _calculate_transfer_efficiency(self, outputs: Dict) -> float:
        """è®¡ç®—ä¼ è¾“æ•ˆç‡"""
        # åŸºäºä¼ è¾“æ€§èƒ½æ•°æ®è®¡ç®—æ•ˆç‡
        perf_analysis = outputs.get('performance_stability_analysis', {})
        transfer_data = perf_analysis.get('æ•°æ®ä¼ è¾“æ€§èƒ½')
        
        if isinstance(transfer_data, pd.DataFrame) and not transfer_data.empty:
            # åŸºäºä¼ è¾“çŠ¶æ€è®¡ç®—æ•ˆç‡
            if 'ä¼ è¾“çŠ¶æ€' in transfer_data.columns:
                normal_count = len(transfer_data[transfer_data['ä¼ è¾“çŠ¶æ€'] == 'æ­£å¸¸'])
                total_count = len(transfer_data)
                
                if total_count > 0:
                    normal_rate = (normal_count / total_count) * 100
                    return min(95.0, normal_rate)
        
        return 75.0  # é»˜è®¤åˆ†æ•°

    def _identify_top_concerns(self, scores: Dict) -> List[str]:
        """è¯†åˆ«ä¸»è¦å…³æ³¨ç‚¹"""
        concerns = []
        
        for category, score in scores.items():
            if score < 60:
                category_names = {
                    'error_rate': 'é”™è¯¯ç‡æ§åˆ¶',
                    'response_time': 'å“åº”æ—¶é—´ä¼˜åŒ–',
                    'efficiency': 'ç³»ç»Ÿæ•ˆç‡',
                    'stability': 'ç³»ç»Ÿç¨³å®šæ€§',
                    'anomaly': 'å¼‚å¸¸æ£€æµ‹',
                    'trend': 'è¶‹åŠ¿åˆ†æ'
                }
                
                concern_name = category_names.get(category, category)
                concerns.append(f"{concern_name}(è¯„åˆ†:{score:.1f})")
        
        return concerns


# å‘åå…¼å®¹çš„å‡½æ•°æ¥å£
def generate_summary_report(outputs: Dict, output_path: str) -> None:
    """ç”Ÿæˆç»¼åˆæŠ¥å‘Š - é«˜çº§ç‰ˆæœ¬å…¥å£å‡½æ•°"""
    generator = AdvancedSummaryReportGenerator()
    generator.generate_advanced_summary_report(outputs, output_path)


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    import sys
    
    if len(sys.argv) != 3:
        print("ç”¨æ³•: python self_07_generate_summary_report_analyzer_advanced.py <outputs_dict> <output_path>")
        sys.exit(1)
    
    # è¿™é‡Œéœ€è¦ä»å®é™…åˆ†æç»“æœåŠ è½½outputs
    # outputs = load_analysis_results(sys.argv[1])
    # generate_summary_report(outputs, sys.argv[2])
    print("é«˜çº§ç»¼åˆæŠ¥å‘Šç”Ÿæˆå™¨å·²å‡†å¤‡å°±ç»ª")