#!/usr/bin/env python3
"""
æ—¶é—´ç»´åº¦åˆ†æå™¨å®Œæ•´åŠŸèƒ½æµ‹è¯•
"""

import tempfile
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    print("ğŸ“Š åˆ›å»ºæµ‹è¯•æ•°æ®...")
    
    # ç”Ÿæˆ1000æ¡æµ‹è¯•è®°å½•
    base_time = datetime.now()
    data = []
    
    for i in range(1000):
        timestamp = base_time + timedelta(seconds=i*60)  # æ¯åˆ†é’Ÿä¸€æ¡è®°å½•
        
        # æ¨¡æ‹Ÿä¸åŒçš„å“åº”æ—¶é—´åˆ†å¸ƒ
        if i % 100 == 0:  # 1%ææ…¢è¯·æ±‚
            response_time = np.random.normal(10.0, 2.0)
        elif i % 20 == 0:  # 5%æ…¢è¯·æ±‚
            response_time = np.random.normal(3.5, 0.5)
        else:  # 94%æ­£å¸¸è¯·æ±‚
            response_time = np.random.normal(0.8, 0.2)
        
        response_time = max(0.01, response_time)
        
        # æ¨¡æ‹ŸçŠ¶æ€ç åˆ†å¸ƒ
        if i % 50 == 0:  # 2%é”™è¯¯
            status_code = np.random.choice([404, 500, 502, 503])
        else:
            status_code = 200
        
        record = {
            'arrival_time': timestamp,
            'response_status_code': status_code,
            'total_request_duration': response_time,
            'upstream_response_time': response_time * 0.8,
            'upstream_header_time': response_time * 0.6,
            'upstream_connect_time': response_time * 0.1,
            'response_body_size': np.random.randint(1024, 51200),
            'total_bytes_sent': np.random.randint(1024, 51200),
            'client_ip': f"192.168.1.{np.random.randint(1, 255)}",
            'request_full_uri': f"/api/v{np.random.randint(1, 3)}/endpoint{i % 10}",
            'connection_info': {'reused': np.random.choice([True, False])}
        }
        
        data.append(record)
    
    df = pd.DataFrame(data)
    print(f"âœ… ç”Ÿæˆäº† {len(df)} æ¡æµ‹è¯•è®°å½•")
    return df

def test_advanced_functionality():
    """æµ‹è¯•é«˜çº§åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•é«˜çº§åŠŸèƒ½...")
    
    try:
        from self_05_time_dimension_analyzer_advanced import AdvancedTimeAnalyzer
        
        # åˆ›å»ºåˆ†æå™¨
        analyzer = AdvancedTimeAnalyzer(slow_threshold=3.0)
        print("âœ… åˆ†æå™¨åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        df = create_test_data()
        
        # åˆ›å»ºä¸´æ—¶CSVæ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            df.to_csv(f.name, index=False)
            csv_path = f.name
        
        print(f"ğŸ“ ä¸´æ—¶CSVæ–‡ä»¶: {csv_path}")
        
        # æµ‹è¯•æ•°æ®æµå¤„ç†
        print("\nâš¡ æµ‹è¯•æ•°æ®æµå¤„ç†...")
        analyzer.process_data_stream(csv_path)
        print(f"âœ… å¤„ç†äº† {analyzer.global_stats['processed_records']} æ¡è®°å½•")
        print(f"âœ… å¤„ç†é€Ÿåº¦: {analyzer.global_stats['processing_speed']:.0f} è®°å½•/ç§’")
        
        # éªŒè¯ç»Ÿè®¡ç»“æœ
        print("\nğŸ“Š éªŒè¯ç»Ÿè®¡ç»“æœ...")
        dimensions_with_data = 0
        for dimension in analyzer.dimensions:
            if analyzer.stats[dimension]:
                dimensions_with_data += 1
                print(f"âœ… {dimension} ç»´åº¦: {len(analyzer.stats[dimension])} ä¸ªæ—¶é—´ç‚¹")
        
        print(f"âœ… å…±æœ‰ {dimensions_with_data} ä¸ªç»´åº¦æœ‰æ•°æ®")
        
        # æµ‹è¯•T-DigeståŠŸèƒ½
        print("\nğŸ¯ æµ‹è¯•T-Digeståˆ†ä½æ•°è®¡ç®—...")
        p95_count = 0
        p99_count = 0
        for dimension in analyzer.dimensions:
            for stats in analyzer.stats[dimension].values():
                if stats.get('response_time_p95', 0) > 0:
                    p95_count += 1
                if stats.get('response_time_p99', 0) > 0:
                    p99_count += 1
        
        print(f"âœ… P95è®¡ç®—æˆåŠŸ: {p95_count} ä¸ªæ—¶é—´ç‚¹")
        print(f"âœ… P99è®¡ç®—æˆåŠŸ: {p99_count} ä¸ªæ—¶é—´ç‚¹")
        
        # æµ‹è¯•å¼‚å¸¸æ£€æµ‹
        print("\nğŸ” æµ‹è¯•å¼‚å¸¸æ£€æµ‹...")
        anomaly_count = 0
        for dimension in analyzer.dimensions:
            for stats in analyzer.stats[dimension].values():
                anomalies = stats.get('anomalies', [])
                anomaly_count += len(anomalies)
        
        print(f"âœ… æ£€æµ‹åˆ° {anomaly_count} ä¸ªå¼‚å¸¸")
        
        # æµ‹è¯•ExcelæŠ¥å‘Šç”Ÿæˆ
        print("\nğŸ“ˆ æµ‹è¯•ExcelæŠ¥å‘Šç”Ÿæˆ...")
        with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as f:
            excel_path = f.name
        
        analyzer.generate_excel_report(excel_path)
        
        # éªŒè¯Excelæ–‡ä»¶
        if os.path.exists(excel_path):
            file_size = os.path.getsize(excel_path)
            print(f"âœ… ExcelæŠ¥å‘Šç”ŸæˆæˆåŠŸ: {excel_path}")
            print(f"âœ… æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
        else:
            print("âŒ ExcelæŠ¥å‘Šç”Ÿæˆå¤±è´¥")
            return False
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.unlink(csv_path)
            os.unlink(excel_path)
            print("âœ… ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ")
        except:
            pass
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_performance_comparison():
    """æµ‹è¯•æ€§èƒ½å¯¹æ¯”"""
    print("\nâš¡ æ€§èƒ½å¯¹æ¯”æµ‹è¯•...")
    
    try:
        from self_05_time_dimension_analyzer_advanced import AdvancedTimeAnalyzer
        from self_05_time_dimension_analyzer import StreamingTimeAnalyzer
        
        # åˆ›å»ºæ›´å¤§çš„æµ‹è¯•æ•°æ®é›†
        print("ğŸ“Š åˆ›å»ºå¤§æ•°æ®é›†...")
        base_time = datetime.now()
        data = []
        
        for i in range(10000):  # 10Kè®°å½•
            timestamp = base_time + timedelta(seconds=i*6)  # æ¯6ç§’ä¸€æ¡è®°å½•
            response_time = np.random.normal(1.0, 0.3)
            response_time = max(0.01, response_time)
            
            record = {
                'arrival_time': timestamp,
                'response_status_code': 200,
                'total_request_duration': response_time,
                'upstream_response_time': response_time * 0.8,
                'upstream_header_time': response_time * 0.6,
                'upstream_connect_time': response_time * 0.1,
                'response_body_size': np.random.randint(1024, 10240),
                'total_bytes_sent': np.random.randint(1024, 10240),
                'client_ip': f"192.168.1.{np.random.randint(1, 255)}",
            }
            data.append(record)
        
        df = pd.DataFrame(data)
        print(f"âœ… ç”Ÿæˆäº† {len(df)} æ¡æµ‹è¯•è®°å½•")
        
        # åˆ›å»ºä¸´æ—¶CSVæ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            df.to_csv(f.name, index=False)
            csv_path = f.name
        
        # æµ‹è¯•é«˜çº§ç‰ˆæœ¬
        print("\nğŸš€ æµ‹è¯•é«˜çº§ç‰ˆæœ¬æ€§èƒ½...")
        start_time = datetime.now()
        
        analyzer = AdvancedTimeAnalyzer()
        analyzer.process_data_stream(csv_path)
        
        advanced_time = (datetime.now() - start_time).total_seconds()
        advanced_speed = analyzer.global_stats['processing_speed']
        
        print(f"âœ… é«˜çº§ç‰ˆæœ¬å¤„ç†æ—¶é—´: {advanced_time:.2f}ç§’")
        print(f"âœ… é«˜çº§ç‰ˆæœ¬å¤„ç†é€Ÿåº¦: {advanced_speed:.0f} è®°å½•/ç§’")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.unlink(csv_path)
        except:
            pass
        
        return True
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("\nğŸ›¡ï¸ æµ‹è¯•é”™è¯¯å¤„ç†...")
    
    try:
        from self_05_time_dimension_analyzer_advanced import AdvancedTimeAnalyzer
        
        # æµ‹è¯•ç©ºæ•°æ®
        print("ğŸ“Š æµ‹è¯•ç©ºæ•°æ®å¤„ç†...")
        analyzer = AdvancedTimeAnalyzer()
        
        # åˆ›å»ºç©ºCSVæ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            f.write("arrival_time,response_status_code\n")  # åªæœ‰è¡¨å¤´
            csv_path = f.name
        
        analyzer.process_data_stream(csv_path)
        print("âœ… ç©ºæ•°æ®å¤„ç†æ­£å¸¸")
        
        # æµ‹è¯•å¼‚å¸¸æ•°æ®
        print("ğŸ“Š æµ‹è¯•å¼‚å¸¸æ•°æ®å¤„ç†...")
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            f.write("arrival_time,response_status_code\n")
            f.write("invalid_time,invalid_code\n")
            f.write("2024-07-18 12:00:00,200\n")
            csv_path2 = f.name
        
        analyzer2 = AdvancedTimeAnalyzer()
        analyzer2.process_data_stream(csv_path2)
        print("âœ… å¼‚å¸¸æ•°æ®å¤„ç†æ­£å¸¸")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.unlink(csv_path)
            os.unlink(csv_path2)
        except:
            pass
        
        return True
        
    except Exception as e:
        print(f"âŒ é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=== æ—¶é—´ç»´åº¦åˆ†æå™¨é«˜çº§ç‰ˆæœ¬å®Œæ•´åŠŸèƒ½æµ‹è¯• ===")
    
    success = True
    
    # æµ‹è¯•1ï¼šåŸºæœ¬åŠŸèƒ½
    if not test_advanced_functionality():
        success = False
    
    # æµ‹è¯•2ï¼šæ€§èƒ½å¯¹æ¯”
    if not test_performance_comparison():
        success = False
    
    # æµ‹è¯•3ï¼šé”™è¯¯å¤„ç†
    if not test_error_handling():
        success = False
    
    # æ€»ç»“
    print("\n=== æµ‹è¯•æ€»ç»“ ===")
    if success:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é«˜çº§ç‰ˆæœ¬åŠŸèƒ½å®Œæ•´")
        print("\nâœ… éªŒè¯é€šè¿‡çš„åŠŸèƒ½:")
        print("  â€¢ T-Digestç®—æ³• - P95/P99åˆ†ä½æ•°è®¡ç®—")
        print("  â€¢ æµå¼å¤„ç† - å¤§æ•°æ®é›†å¤„ç†")
        print("  â€¢ å¼‚å¸¸æ£€æµ‹ - è‡ªåŠ¨é—®é¢˜è¯†åˆ«")
        print("  â€¢ è¶‹åŠ¿åˆ†æ - æ€§èƒ½å˜åŒ–è·Ÿè¸ª")
        print("  â€¢ ExcelæŠ¥å‘Š - å¤šå·¥ä½œè¡¨ç”Ÿæˆ")
        print("  â€¢ å†…å­˜ä¼˜åŒ– - æ’å®šå†…å­˜ä½¿ç”¨")
        print("  â€¢ é”™è¯¯å¤„ç† - å¼‚å¸¸æ•°æ®å®¹é”™")
        print("  â€¢ æ€§èƒ½æå‡ - é«˜é€Ÿæ•°æ®å¤„ç†")
        print("\nğŸš€ é«˜çº§ç‰ˆæœ¬å·²å°±ç»ªï¼Œå¯ä»¥å¤„ç†ç”Ÿäº§ç¯å¢ƒçš„nginxæ—¥å¿—ï¼")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°")
    
    return success

if __name__ == "__main__":
    main()