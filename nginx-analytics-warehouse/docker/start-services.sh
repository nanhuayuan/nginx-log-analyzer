#!/bin/bash

# Nginx Analytics Platform - åˆ†ç»„å¯åŠ¨è„šæœ¬
# æŒ‰ç»„å¯åŠ¨æœåŠ¡ï¼Œæ”¯æŒçµæ´»çš„æœåŠ¡ç®¡ç†

set -e

echo "ğŸš€ Nginx Analytics Platform - åˆ†ç»„å¯åŠ¨è„šæœ¬"
echo "=" * 60

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# ç­‰å¾…æœåŠ¡å¥åº·
wait_for_health() {
    local service=$1
    local timeout=${2:-120}
    local interval=5
    local elapsed=0

    log_info "ç­‰å¾… $service æœåŠ¡å¥åº·æ£€æŸ¥..."

    while [ $elapsed -lt $timeout ]; do
        if docker-compose ps $service | grep -q "healthy"; then
            log_success "$service æœåŠ¡å·²å¥åº·"
            return 0
        fi

        if docker-compose ps $service | grep -q "unhealthy"; then
            log_error "$service æœåŠ¡ä¸å¥åº·ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"
            return 1
        fi

        sleep $interval
        elapsed=$((elapsed + interval))
        echo -n "."
    done

    log_error "$service æœåŠ¡å¥åº·æ£€æŸ¥è¶…æ—¶"
    return 1
}

# å¯åŠ¨æœåŠ¡ç»„
start_group() {
    local group_name=$1
    shift
    local services=("$@")

    log_info "å¯åŠ¨æœåŠ¡ç»„: $group_name"
    echo "æœåŠ¡åˆ—è¡¨: ${services[*]}"

    for service in "${services[@]}"; do
        log_info "å¯åŠ¨æœåŠ¡: $service"
        if docker-compose up -d $service; then
            log_success "$service å¯åŠ¨å®Œæˆ"
        else
            log_error "$service å¯åŠ¨å¤±è´¥"
            return 1
        fi
    done
}

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
check_services() {
    log_info "æ£€æŸ¥æ‰€æœ‰æœåŠ¡çŠ¶æ€..."
    docker-compose ps
}

# ä¸»å¯åŠ¨æµç¨‹
main() {
    case "${1:-all}" in
        "databases"|"db")
            log_info "å¯åŠ¨æ•°æ®å­˜å‚¨å±‚..."
            start_group "æ•°æ®å­˜å‚¨å±‚" clickhouse redis postgres n9e-mysql dataease-mysql
            ;;

        "timeseries"|"ts")
            log_info "å¯åŠ¨æ—¶åºæ•°æ®åº“..."
            start_group "æ—¶åºæ•°æ®åº“" victoriametrics
            ;;

        "compute"|"engine")
            log_info "å¯åŠ¨è®¡ç®—å¼•æ“..."
            start_group "è®¡ç®—å¼•æ“" spark-master spark-worker flink-jobmanager flink-taskmanager
            ;;

        "bi"|"visualization")
            log_info "å¯åŠ¨BIå¯è§†åŒ–å·¥å…·..."
            start_group "BIå·¥å…·" grafana superset dataease
            ;;

        "monitoring"|"monitor")
            log_info "å¯åŠ¨ç›‘æ§ç³»ç»Ÿ..."
            start_group "ç›‘æ§ç³»ç»Ÿ" nightingale categraf node-exporter
            ;;

        "etl"|"workflow")
            log_info "å¯åŠ¨ETLå’Œå·¥ä½œæµ..."
            start_group "ETLå·¥ä½œæµ" seatunnel-master dolphinscheduler-standalone
            ;;

        "all")
            log_info "å¯åŠ¨æ‰€æœ‰æœåŠ¡ (æ¨èé¡ºåº)..."

            # L0: åŸºç¡€æ•°æ®å­˜å‚¨
            start_group "L0-æ•°æ®å­˜å‚¨å±‚" clickhouse redis postgres n9e-mysql dataease-mysql
            sleep 10

            # L1: æ—¶åºæ•°æ®åº“å’Œè®¡ç®—å¼•æ“
            start_group "L1-æ—¶åºæ•°æ®åº“" victoriametrics
            start_group "L1-è®¡ç®—å¼•æ“" spark-master spark-worker flink-jobmanager flink-taskmanager
            sleep 15

            # L2: BIå’Œç›‘æ§åº”ç”¨
            start_group "L2-BIå·¥å…·" grafana superset dataease
            start_group "L2-ç›‘æ§ç³»ç»Ÿ" nightingale
            sleep 10

            # L3: ETLå’Œå·¥ä½œæµ
            start_group "L3-ETLå·¥ä½œæµ" seatunnel-master dolphinscheduler-standalone
            sleep 5

            # L4: ç›‘æ§ä»£ç†
            start_group "L4-ç›‘æ§ä»£ç†" categraf node-exporter
            ;;

        "help"|"-h"|"--help")
            echo "ç”¨æ³•: $0 [ç»„å]"
            echo ""
            echo "å¯ç”¨çš„æœåŠ¡ç»„:"
            echo "  databases, db       - æ•°æ®å­˜å‚¨å±‚ (ClickHouse, Redis, PostgreSQL, MySQL)"
            echo "  timeseries, ts      - æ—¶åºæ•°æ®åº“ (VictoriaMetrics)"
            echo "  compute, engine     - è®¡ç®—å¼•æ“ (Spark, Flink)"
            echo "  bi, visualization   - BIå¯è§†åŒ–å·¥å…· (Grafana, Superset, DataEase)"
            echo "  monitoring, monitor - ç›‘æ§ç³»ç»Ÿ (Nightingale, Categraf, Node-Exporter)"
            echo "  etl, workflow       - ETLå’Œå·¥ä½œæµ (SeaTunnel, DolphinScheduler)"
            echo "  all                 - æ‰€æœ‰æœåŠ¡ (æ¨èï¼ŒæŒ‰ä¾èµ–é¡ºåºå¯åŠ¨)"
            echo ""
            echo "ç¤ºä¾‹:"
            echo "  $0 all              # å¯åŠ¨æ‰€æœ‰æœåŠ¡"
            echo "  $0 databases        # åªå¯åŠ¨æ•°æ®åº“"
            echo "  $0 bi               # åªå¯åŠ¨BIå·¥å…·"
            exit 0
            ;;

        *)
            log_error "æœªçŸ¥çš„æœåŠ¡ç»„: $1"
            log_info "ä½¿ç”¨ '$0 help' æŸ¥çœ‹å¯ç”¨é€‰é¡¹"
            exit 1
            ;;
    esac

    # æœ€ç»ˆçŠ¶æ€æ£€æŸ¥
    sleep 5
    check_services

    log_success "å¯åŠ¨æµç¨‹å®Œæˆï¼"
    log_info "è®¿é—®åœ°å€:"
    echo "  Grafana:        http://localhost:3000  (admin/admin123)"
    echo "  Superset:       http://localhost:8088"
    echo "  DataEase:       http://localhost:8810"
    echo "  Nightingale:    http://localhost:17000"
    echo "  Spark Master:   http://localhost:8080"
    echo "  Flink:          http://localhost:8082"
    echo "  DolphinScheduler: http://localhost:12345"
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"