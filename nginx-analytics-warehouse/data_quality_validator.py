#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®è´¨é‡éªŒè¯å’Œä¿è¯æœºåˆ¶
éªŒè¯7ä¸ªç‰©åŒ–è§†å›¾çš„å¥åº·çŠ¶æ€å’Œæ•°æ®å®Œæ•´æ€§
"""

import clickhouse_connect
from datetime import datetime, timedelta

class DataQualityValidator:
    def __init__(self):
        self.client = clickhouse_connect.get_client(
            host='localhost', 
            port=8123,
            username='analytics_user',
            password='analytics_password'
        )
        
    def validate_all(self):
        """è¿è¡Œå®Œæ•´çš„æ•°æ®è´¨é‡éªŒè¯"""
        print("ğŸ” å¯åŠ¨æ•°æ®è´¨é‡éªŒè¯...")
        print("="*80)
        
        results = {}
        
        # 1. åŸºç¡€è¿æ¥éªŒè¯
        results['connection'] = self._validate_connection()
        
        # 2. æ¶æ„å®Œæ•´æ€§éªŒè¯
        results['architecture'] = self._validate_architecture()
        
        # 3. ç‰©åŒ–è§†å›¾çŠ¶æ€éªŒè¯
        results['materialized_views'] = self._validate_materialized_views()
        
        # 4. æ•°æ®æµéªŒè¯
        results['data_flow'] = self._validate_data_flow()
        
        # 5. æ€§èƒ½éªŒè¯
        results['performance'] = self._validate_performance()
        
        # 6. ç”Ÿæˆè´¨é‡æŠ¥å‘Š
        self._generate_quality_report(results)
        
        return results
        
    def _validate_connection(self):
        """éªŒè¯æ•°æ®åº“è¿æ¥"""
        print("\n1ï¸âƒ£ éªŒè¯æ•°æ®åº“è¿æ¥...")
        try:
            result = self.client.query("SELECT 1")
            print("   âœ… ClickHouseè¿æ¥æ­£å¸¸")
            return {"status": "healthy", "message": "è¿æ¥æ­£å¸¸"}
        except Exception as e:
            print(f"   âŒ è¿æ¥å¤±è´¥: {e}")
            return {"status": "failed", "message": str(e)}
    
    def _validate_architecture(self):
        """éªŒè¯æ¶æ„å®Œæ•´æ€§"""
        print("\n2ï¸âƒ£ éªŒè¯æ¶æ„å®Œæ•´æ€§...")
        
        expected_tables = {
            "ODSå±‚": ["ods_nginx_raw"],
            "DWDå±‚": ["dwd_nginx_enriched_v2"],
            "ADSå±‚": [
                "ads_api_performance_analysis",
                "ads_service_level_analysis", 
                "ads_slow_request_analysis",
                "ads_status_code_analysis",
                "ads_time_dimension_analysis",
                "ads_error_analysis_detailed",
                "ads_request_header_analysis"
            ]
        }
        
        result = {"status": "healthy", "missing_tables": [], "table_counts": {}}
        
        for layer, tables in expected_tables.items():
            print(f"\n   ğŸ“‹ æ£€æŸ¥{layer}:")
            for table in tables:
                try:
                    count_result = self.client.query(f"SELECT count() FROM nginx_analytics.{table}")
                    count = count_result.result_rows[0][0]
                    result["table_counts"][table] = count
                    print(f"      âœ… {table}: {count:,} æ¡")
                except Exception as e:
                    result["missing_tables"].append(table)
                    print(f"      âŒ {table}: ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®")
        
        if result["missing_tables"]:
            result["status"] = "degraded"
            
        return result
    
    def _validate_materialized_views(self):
        """éªŒè¯ç‰©åŒ–è§†å›¾çŠ¶æ€"""
        print("\n3ï¸âƒ£ éªŒè¯ç‰©åŒ–è§†å›¾çŠ¶æ€...")
        
        expected_views = [
            "mv_api_performance_hourly",
            "mv_service_level_hourly",
            "mv_slow_request_hourly", 
            "mv_status_code_hourly",
            "mv_time_dimension_hourly",
            "mv_error_analysis_hourly",
            "mv_request_header_hourly"
        ]
        
        result = {"status": "healthy", "active_views": 0, "total_views": len(expected_views)}
        
        for view in expected_views:
            try:
                # æ£€æŸ¥è§†å›¾æ˜¯å¦å­˜åœ¨
                view_check = self.client.query(f"""
                    SELECT count() FROM system.tables 
                    WHERE database = 'nginx_analytics' 
                    AND name = '{view}' 
                    AND engine = 'MaterializedView'
                """)
                
                if view_check.result_rows[0][0] > 0:
                    result["active_views"] += 1
                    print(f"   âœ… {view}: è¿è¡Œä¸­")
                else:
                    print(f"   âŒ {view}: ä¸å­˜åœ¨")
                    
            except Exception as e:
                print(f"   âŒ {view}: æ£€æŸ¥å¤±è´¥ - {str(e)[:50]}")
        
        success_rate = (result["active_views"] / result["total_views"]) * 100
        print(f"\n   ğŸ“Š ç‰©åŒ–è§†å›¾æˆåŠŸç‡: {success_rate:.1f}% ({result['active_views']}/{result['total_views']})")
        
        if success_rate < 100:
            result["status"] = "degraded"
        
        return result
    
    def _validate_data_flow(self):
        """éªŒè¯æ•°æ®æµ"""
        print("\n4ï¸âƒ£ éªŒè¯æ•°æ®æµ...")
        
        result = {"status": "healthy", "flow_health": {}}
        
        try:
            # ODS â†’ DWD æµéªŒè¯
            ods_count = self.client.query("SELECT count() FROM nginx_analytics.ods_nginx_raw").result_rows[0][0]
            dwd_count = self.client.query("SELECT count() FROM nginx_analytics.dwd_nginx_enriched_v2").result_rows[0][0]
            
            ods_dwd_ratio = (dwd_count / ods_count) * 100 if ods_count > 0 else 0
            result["flow_health"]["ods_to_dwd"] = ods_dwd_ratio
            
            print(f"   ğŸ“Š ODS â†’ DWD æ•°æ®æµ: {ods_dwd_ratio:.1f}% ({dwd_count:,}/{ods_count:,})")
            
            if ods_dwd_ratio < 95:
                print(f"   âš ï¸  æ•°æ®æµå¥åº·åº¦è¾ƒä½: {ods_dwd_ratio:.1f}%")
                result["status"] = "degraded"
            else:
                print(f"   âœ… æ•°æ®æµå¥åº·: {ods_dwd_ratio:.1f}%")
            
            # æ£€æŸ¥æ•°æ®æ—¶é—´åˆ†å¸ƒ
            time_dist = self.client.query("""
                SELECT 
                    toDate(min(log_time)) as earliest_date,
                    toDate(max(log_time)) as latest_date,
                    dateDiff('day', min(log_time), max(log_time)) as time_span_days
                FROM nginx_analytics.dwd_nginx_enriched_v2
            """)
            
            if time_dist.result_rows:
                earliest, latest, span = time_dist.result_rows[0]
                print(f"   ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {earliest} è‡³ {latest} (å…±{span}å¤©)")
                result["flow_health"]["time_span_days"] = span
            
        except Exception as e:
            print(f"   âŒ æ•°æ®æµéªŒè¯å¤±è´¥: {e}")
            result["status"] = "failed"
        
        return result
    
    def _validate_performance(self):
        """éªŒè¯æ€§èƒ½æŒ‡æ ‡"""
        print("\n5ï¸âƒ£ éªŒè¯æ€§èƒ½æŒ‡æ ‡...")
        
        result = {"status": "healthy", "query_times": {}}
        
        # ç®€å•æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
        test_queries = {
            "basic_count": "SELECT count() FROM nginx_analytics.dwd_nginx_enriched_v2",
            "aggregation": "SELECT platform, count() FROM nginx_analytics.dwd_nginx_enriched_v2 GROUP BY platform",
            "time_query": "SELECT toHour(log_time), count() FROM nginx_analytics.dwd_nginx_enriched_v2 GROUP BY toHour(log_time)"
        }
        
        for query_name, query in test_queries.items():
            try:
                start_time = datetime.now()
                self.client.query(query)
                end_time = datetime.now()
                
                query_time = (end_time - start_time).total_seconds()
                result["query_times"][query_name] = query_time
                
                if query_time < 1.0:
                    print(f"   âœ… {query_name}: {query_time:.3f}s")
                elif query_time < 5.0:
                    print(f"   âš ï¸  {query_name}: {query_time:.3f}s (è¾ƒæ…¢)")
                else:
                    print(f"   âŒ {query_name}: {query_time:.3f}s (è¿‡æ…¢)")
                    result["status"] = "degraded"
                    
            except Exception as e:
                print(f"   âŒ {query_name}: æŸ¥è¯¢å¤±è´¥")
                result["status"] = "degraded"
        
        return result
    
    def _generate_quality_report(self, results):
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        print("\n6ï¸âƒ£ ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š...")
        print("="*80)
        
        # è®¡ç®—æ€»ä½“å¥åº·åˆ†æ•°
        health_scores = []
        for component, result in results.items():
            if result.get("status") == "healthy":
                health_scores.append(100)
            elif result.get("status") == "degraded":
                health_scores.append(70)
            else:
                health_scores.append(0)
        
        overall_health = sum(health_scores) / len(health_scores) if health_scores else 0
        
        print(f"ğŸ“Š æ•´ä½“æ•°æ®è´¨é‡è¯„åˆ†: {overall_health:.1f}/100")
        
        if overall_health >= 90:
            print("ğŸ‰ æ•°æ®è´¨é‡: ä¼˜ç§€")
            health_status = "excellent"
        elif overall_health >= 75:
            print("âœ… æ•°æ®è´¨é‡: è‰¯å¥½")
            health_status = "good"
        elif overall_health >= 60:
            print("âš ï¸  æ•°æ®è´¨é‡: ä¸€èˆ¬")
            health_status = "fair"
        else:
            print("âŒ æ•°æ®è´¨é‡: éœ€è¦æ”¹è¿›")
            health_status = "poor"
        
        # ä¿å­˜æŠ¥å‘Š
        report = {
            "timestamp": datetime.now().isoformat(),
            "overall_health_score": overall_health,
            "health_status": health_status,
            "component_results": results
        }
        
        return report
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if self.client:
            self.client.close()

def main():
    validator = DataQualityValidator()
    
    try:
        report = validator.validate_all()
        print("\n" + "="*80)
        print("âœ… æ•°æ®è´¨é‡éªŒè¯å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        validator.close()

if __name__ == "__main__":
    main()