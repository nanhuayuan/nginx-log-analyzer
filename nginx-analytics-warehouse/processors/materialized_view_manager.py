#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‰©åŒ–è§†å›¾ç®¡ç†å™¨æ¨¡å— - ä¸“é—¨è´Ÿè´£ClickHouseç‰©åŒ–è§†å›¾çš„åˆ›å»ºå’Œç®¡ç†
Materialized View Manager Module - Specialized for ClickHouse Materialized View Creation and Management

ä¸“é—¨è´Ÿè´£ï¼š
1. ç‰©åŒ–è§†å›¾çš„åˆ›å»ºã€åˆ é™¤ã€é‡å»º
2. ç‰©åŒ–è§†å›¾çŠ¶æ€æ£€æŸ¥å’Œç›‘æ§
3. ADSå±‚æ•°æ®çš„è‡ªåŠ¨èšåˆé…ç½®
4. å¼‚å¸¸å¤„ç†å’Œé”™è¯¯æ¢å¤
"""

import logging
import time
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path
import clickhouse_connect
from clickhouse_connect.driver.exceptions import ClickHouseError

class MaterializedViewManager:
    """ç‰©åŒ–è§†å›¾ç®¡ç†å™¨ - ä¸“é—¨ç®¡ç†ClickHouseç‰©åŒ–è§†å›¾"""
    
    def __init__(self, host: str = 'localhost', port: int = 8123, 
                 database: str = 'nginx_analytics', user: str = 'analytics_user', 
                 password: str = 'analytics_password'):
        """
        åˆå§‹åŒ–ç‰©åŒ–è§†å›¾ç®¡ç†å™¨
        
        Args:
            host: ClickHouseæœåŠ¡å™¨åœ°å€
            port: ClickHouse HTTPç«¯å£
            database: æ•°æ®åº“åç§°
            user: ç”¨æˆ·å
            password: å¯†ç 
        """
        self.config = {
            'host': host,
            'port': port,
            'username': user,
            'password': password,
            'database': database
        }
        self.database = database
        self.client = None
        self.logger = logging.getLogger(__name__)
        
        # ç‰©åŒ–è§†å›¾é…ç½® - è§£è€¦è®¾è®¡ï¼Œæ–¹ä¾¿ç»´æŠ¤
        self.materialized_views = self._initialize_view_definitions()
        
    def _initialize_view_definitions(self) -> Dict[str, Dict[str, Any]]:
        """
        åˆå§‹åŒ–ç‰©åŒ–è§†å›¾å®šä¹‰ - é›†ä¸­ç®¡ç†æ‰€æœ‰ç‰©åŒ–è§†å›¾é…ç½®
        
        Returns:
            Dict: ç‰©åŒ–è§†å›¾é…ç½®å­—å…¸
        """
        return {
            # 1. APIæ€§èƒ½åˆ†æç‰©åŒ–è§†å›¾
            'mv_api_performance_hourly': {
                'target_table': 'ads_api_performance_analysis',
                'description': 'æ¥å£æ€§èƒ½å°æ—¶çº§èšåˆ - å¯¹åº”01.æ¥å£æ€§èƒ½åˆ†æ.xlsx',
                'sql_template': """
                CREATE MATERIALIZED VIEW IF NOT EXISTS {database}.{view_name}
                TO {database}.{target_table}
                AS SELECT
                    toStartOfHour(log_time) as stat_time,
                    'hour' as time_granularity,
                    platform,
                    access_type,
                    request_uri as api_path,
                    api_module,
                    api_category,
                    business_domain,
                    
                    -- è¯·æ±‚é‡æŒ‡æ ‡
                    count() as total_requests,
                    uniq(client_ip) as unique_clients,
                    count() / 3600.0 as qps,
                    
                    -- æ€§èƒ½æŒ‡æ ‡
                    avg(total_request_duration) as avg_response_time,
                    quantile(0.5)(total_request_duration) as p50_response_time,
                    quantile(0.9)(total_request_duration) as p90_response_time,
                    quantile(0.95)(total_request_duration) as p95_response_time,
                    quantile(0.99)(total_request_duration) as p99_response_time,
                    max(total_request_duration) as max_response_time,
                    
                    -- æˆåŠŸç‡æŒ‡æ ‡
                    countIf(is_success) as success_requests,
                    countIf(is_error) as error_requests,
                    countIf(is_success) * 100.0 / count() as success_rate,
                    countIf(is_error) * 100.0 / count() as error_rate,
                    countIf(is_business_success) * 100.0 / count() as business_success_rate,
                    
                    -- æ…¢è¯·æ±‚åˆ†æ
                    countIf(is_slow) as slow_requests,
                    countIf(is_very_slow) as very_slow_requests,
                    countIf(is_slow) * 100.0 / count() as slow_rate,
                    countIf(is_very_slow) * 100.0 / count() as very_slow_rate,
                    
                    -- ç”¨æˆ·ä½“éªŒæŒ‡æ ‡ (Apdex: æ»¡æ„é˜ˆå€¼1.5s, å®¹å¿é˜ˆå€¼6s)
                    (countIf(total_request_duration <= 1.5) + 
                     countIf(total_request_duration > 1.5 AND total_request_duration <= 6.0) * 0.5) 
                     / count() as apdex_score,
                    multiIf(
                        avg(total_request_duration) <= 1.5, 100.0,
                        avg(total_request_duration) <= 6.0, 80.0,
                        60.0
                    ) as user_satisfaction_score,
                    
                    -- ä¸šåŠ¡ä»·å€¼
                    avg(business_value_score) as avg_business_value_score,
                    multiIf(
                        avg(business_value_score) >= 8, 'Critical',
                        avg(business_value_score) >= 6, 'High', 
                        avg(business_value_score) >= 4, 'Medium',
                        'Low'
                    ) as importance_level,
                    
                    now() as created_at
                FROM {database}.dwd_nginx_enriched_v2
                GROUP BY stat_time, platform, access_type, api_path, api_module, api_category, business_domain
                """
            },
            
            # 2. æœåŠ¡å±‚çº§åˆ†æç‰©åŒ–è§†å›¾
            'mv_service_level_hourly': {
                'target_table': 'ads_service_level_analysis',
                'description': 'æœåŠ¡å±‚çº§å°æ—¶çº§èšåˆ - å¯¹åº”02.æœåŠ¡å±‚çº§åˆ†æ.xlsx',
                'sql_template': """
                CREATE MATERIALIZED VIEW IF NOT EXISTS {database}.{view_name}
                TO {database}.{target_table}
                AS SELECT
                    toStartOfHour(log_time) as stat_time,
                    'hour' as time_granularity,
                    platform,
                    service_name,
                    cluster_node,
                    upstream_server,
                    
                    -- æœåŠ¡å¥åº·æŒ‡æ ‡
                    count() as total_requests,
                    countIf(is_success) as success_requests,
                    countIf(is_error) as error_requests,
                    countIf(total_request_duration >= 30.0) as timeout_requests,
                    
                    -- æœåŠ¡æ€§èƒ½
                    avg(total_request_duration) as avg_response_time,
                    quantile(0.95)(total_request_duration) as p95_response_time,
                    avg(upstream_response_time) as avg_upstream_time,
                    avg(upstream_connect_time) as avg_connect_time,
                    
                    -- æœåŠ¡è´¨é‡
                    countIf(is_success) * 100.0 / count() as availability,
                    countIf(NOT has_anomaly) * 100.0 / count() as reliability,
                    (countIf(is_success) * 0.6 + countIf(NOT has_anomaly) * 0.4) as health_score,
                    
                    -- å®¹é‡æŒ‡æ ‡
                    max(connection_requests) as max_concurrent_requests,
                    count() / 3600.0 as avg_qps,
                    count() as request_count_for_peak_qps,
                    
                    now() as created_at
                FROM {database}.dwd_nginx_enriched_v2
                WHERE log_time >= now() - INTERVAL 1 DAY
                GROUP BY stat_time, platform, service_name, cluster_node, upstream_server
                """
            },
            
            # 3. æ…¢è¯·æ±‚åˆ†æç‰©åŒ–è§†å›¾
            'mv_slow_request_hourly': {
                'target_table': 'ads_slow_request_analysis',
                'description': 'æ…¢è¯·æ±‚å°æ—¶çº§èšåˆ - å¯¹åº”03_æ…¢è¯·æ±‚åˆ†æ.xlsx',
                'sql_template': """
                CREATE MATERIALIZED VIEW IF NOT EXISTS {database}.{view_name}
                TO {database}.{target_table}
                AS SELECT
                    toStartOfHour(log_time) as stat_time,
                    'hour' as time_granularity,
                    platform,
                    access_type,
                    request_uri as api_path,
                    api_module,
                    api_category,
                    business_domain,
                    
                    -- æ…¢è¯·æ±‚ç»Ÿè®¡
                    count() as total_requests,
                    countIf(is_slow) as slow_requests,
                    countIf(is_very_slow) as very_slow_requests,
                    countIf(is_slow) * 100.0 / count() as slow_rate,
                    countIf(is_very_slow) * 100.0 / count() as very_slow_rate,
                    
                    -- æ€§èƒ½åˆ†æ
                    avg(total_request_duration) as avg_response_time,
                    quantile(0.95)(total_request_duration) as p95_response_time,
                    quantile(0.99)(total_request_duration) as p99_response_time,
                    max(total_request_duration) as max_response_time,
                    
                    -- æ…¢è¯·æ±‚åŸå› åˆ†æ
                    avgIf(upstream_response_time, is_slow) as avg_upstream_time_slow,
                    avgIf(network_phase, is_slow) as avg_network_time_slow,
                    avgIf(processing_phase, is_slow) as avg_processing_time_slow,
                    
                    -- å½±å“åˆ†æ
                    uniq(client_ip) as affected_users,
                    sum(response_body_size) as total_data_transferred,
                    avg(business_value_score) as business_impact_score,
                    
                    now() as created_at
                FROM {database}.dwd_nginx_enriched_v2
                WHERE log_time >= now() - INTERVAL 1 DAY
                GROUP BY stat_time, platform, access_type, api_path, api_module, api_category, business_domain
                """
            },
            
            # 4. çŠ¶æ€ç åˆ†æç‰©åŒ–è§†å›¾
            'mv_status_code_hourly': {
                'target_table': 'ads_status_code_analysis',
                'description': 'çŠ¶æ€ç å°æ—¶çº§èšåˆ - å¯¹åº”04.çŠ¶æ€ç ç»Ÿè®¡.xlsx',
                'sql_template': """
                CREATE MATERIALIZED VIEW IF NOT EXISTS {database}.{view_name}
                TO {database}.{target_table}
                AS SELECT
                    toStartOfHour(log_time) as stat_time,
                    'hour' as time_granularity,
                    platform,
                    access_type,
                    response_status_code as status_code,
                    
                    -- åŸºç¡€ç»Ÿè®¡
                    count() as request_count,
                    uniq(client_ip) as unique_clients,
                    uniq(request_uri) as unique_apis,
                    
                    -- åˆ†ç±»ç»Ÿè®¡
                    multiIf(
                        response_status_code LIKE '2%', 'Success',
                        response_status_code LIKE '3%', 'Redirect', 
                        response_status_code LIKE '4%', 'Client Error',
                        response_status_code LIKE '5%', 'Server Error',
                        'Other'
                    ) as status_category,
                    
                    -- æ€§èƒ½å½±å“
                    avg(total_request_duration) as avg_response_time,
                    quantile(0.95)(total_request_duration) as p95_response_time,
                    
                    -- ä¸šåŠ¡å½±å“
                    avg(business_value_score) as avg_business_impact,
                    
                    now() as created_at
                FROM {database}.dwd_nginx_enriched_v2
                WHERE log_time >= now() - INTERVAL 1 DAY
                GROUP BY stat_time, platform, access_type, response_status_code
                """
            },
            
            # 5. æ—¶é—´ç»´åº¦åˆ†æç‰©åŒ–è§†å›¾
            'mv_time_dimension_hourly': {
                'target_table': 'ads_time_dimension_analysis', 
                'description': 'æ—¶é—´ç»´åº¦å°æ—¶çº§èšåˆ - å¯¹åº”05.æ—¶é—´ç»´åº¦åˆ†æ.xlsx',
                'sql_template': """
                CREATE MATERIALIZED VIEW IF NOT EXISTS {database}.{view_name}
                TO {database}.{target_table}
                AS SELECT
                    toStartOfHour(log_time) as stat_time,
                    'hour' as time_granularity,
                    platform,
                    toHour(log_time) as hour_of_day,
                    toDayOfWeek(log_time) as day_of_week,
                    if(toDayOfWeek(log_time) IN (6, 7), true, false) as is_weekend,
                    
                    -- æµé‡ç»Ÿè®¡
                    count() as total_requests,
                    count() / 3600.0 as avg_qps,
                    uniq(client_ip) as unique_clients,
                    
                    -- æ€§èƒ½ç»Ÿè®¡
                    avg(total_request_duration) as avg_response_time,
                    quantile(0.95)(total_request_duration) as p95_response_time,
                    
                    -- è´¨é‡ç»Ÿè®¡
                    countIf(is_success) * 100.0 / count() as success_rate,
                    countIf(is_error) * 100.0 / count() as error_rate,
                    countIf(is_slow) * 100.0 / count() as slow_rate,
                    
                    -- ç”¨æˆ·ä½“éªŒ
                    (countIf(total_request_duration <= 1.5) + 
                     countIf(total_request_duration > 1.5 AND total_request_duration <= 6.0) * 0.5) 
                     / count() as apdex_score,
                    
                    now() as created_at
                FROM {database}.dwd_nginx_enriched_v2
                WHERE log_time >= now() - INTERVAL 1 DAY
                GROUP BY stat_time, platform, hour_of_day, day_of_week, is_weekend
                """
            }
        }
    
    def connect(self) -> bool:
        """
        è¿æ¥ClickHouseæ•°æ®åº“
        
        Returns:
            bool: è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        try:
            self.client = clickhouse_connect.get_client(**self.config)
            # æµ‹è¯•è¿æ¥
            result = self.client.query("SELECT 1")
            self.logger.info(f"âœ… æˆåŠŸè¿æ¥åˆ°ClickHouse: {self.config['host']}:{self.config['port']}")
            return True
        except Exception as e:
            self.logger.error(f"âŒ ClickHouseè¿æ¥å¤±è´¥: {str(e)}")
            return False
    
    def check_view_exists(self, view_name: str) -> bool:
        """
        æ£€æŸ¥ç‰©åŒ–è§†å›¾æ˜¯å¦å­˜åœ¨
        
        Args:
            view_name: ç‰©åŒ–è§†å›¾åç§°
            
        Returns:
            bool: è§†å›¾æ˜¯å¦å­˜åœ¨
        """
        try:
            query = f"""
            SELECT count() 
            FROM system.tables 
            WHERE database = '{self.database}' 
            AND name = '{view_name}' 
            AND engine = 'MaterializedView'
            """
            result = self.client.query(query)
            return result.result_rows[0][0] > 0
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥ç‰©åŒ–è§†å›¾å­˜åœ¨æ€§å¤±è´¥ {view_name}: {str(e)}")
            return False
    
    def create_materialized_view(self, view_name: str) -> Tuple[bool, str]:
        """
        åˆ›å»ºå•ä¸ªç‰©åŒ–è§†å›¾
        
        Args:
            view_name: ç‰©åŒ–è§†å›¾åç§°
            
        Returns:
            Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, æ¶ˆæ¯)
        """
        if view_name not in self.materialized_views:
            return False, f"æœªçŸ¥çš„ç‰©åŒ–è§†å›¾: {view_name}"
        
        view_config = self.materialized_views[view_name]
        
        try:
            # æ ¼å¼åŒ–SQL
            sql = view_config['sql_template'].format(
                database=self.database,
                view_name=view_name,
                target_table=view_config['target_table']
            )
            
            # æ‰§è¡Œåˆ›å»º
            start_time = time.time()
            self.client.query(sql)
            duration = time.time() - start_time
            
            success_msg = f"âœ… ç‰©åŒ–è§†å›¾ {view_name} åˆ›å»ºæˆåŠŸ ({view_config['description']})ï¼Œè€—æ—¶ {duration:.2f}s"
            self.logger.info(success_msg)
            return True, success_msg
            
        except ClickHouseError as e:
            error_msg = f"âŒ ç‰©åŒ–è§†å›¾ {view_name} åˆ›å»ºå¤±è´¥: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg
        except Exception as e:
            error_msg = f"âŒ ç‰©åŒ–è§†å›¾ {view_name} åˆ›å»ºå¼‚å¸¸: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg
    
    def drop_materialized_view(self, view_name: str) -> Tuple[bool, str]:
        """
        åˆ é™¤ç‰©åŒ–è§†å›¾
        
        Args:
            view_name: ç‰©åŒ–è§†å›¾åç§°
            
        Returns:
            Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, æ¶ˆæ¯)
        """
        try:
            sql = f"DROP VIEW IF EXISTS {self.database}.{view_name}"
            self.client.query(sql)
            
            success_msg = f"âœ… ç‰©åŒ–è§†å›¾ {view_name} åˆ é™¤æˆåŠŸ"
            self.logger.info(success_msg)
            return True, success_msg
            
        except Exception as e:
            error_msg = f"âŒ ç‰©åŒ–è§†å›¾ {view_name} åˆ é™¤å¤±è´¥: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg
    
    def create_all_views(self, force_recreate: bool = False) -> Dict[str, Any]:
        """
        åˆ›å»ºæ‰€æœ‰ç‰©åŒ–è§†å›¾
        
        Args:
            force_recreate: æ˜¯å¦å¼ºåˆ¶é‡æ–°åˆ›å»º
            
        Returns:
            Dict: åˆ›å»ºç»“æœç»Ÿè®¡
        """
        results = {
            'total': len(self.materialized_views),
            'success': 0,
            'failed': 0,
            'skipped': 0,
            'details': []
        }
        
        self.logger.info(f"ğŸš€ å¼€å§‹åˆ›å»º {results['total']} ä¸ªç‰©åŒ–è§†å›¾...")
        
        for view_name in self.materialized_views.keys():
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                if self.check_view_exists(view_name):
                    if force_recreate:
                        self.logger.info(f"ğŸ”„ ç‰©åŒ–è§†å›¾ {view_name} å·²å­˜åœ¨ï¼Œå¼ºåˆ¶é‡æ–°åˆ›å»º...")
                        drop_success, drop_msg = self.drop_materialized_view(view_name)
                        if not drop_success:
                            results['failed'] += 1
                            results['details'].append({'view': view_name, 'status': 'failed', 'message': drop_msg})
                            continue
                    else:
                        skip_msg = f"â­ï¸ ç‰©åŒ–è§†å›¾ {view_name} å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º"
                        self.logger.info(skip_msg)
                        results['skipped'] += 1
                        results['details'].append({'view': view_name, 'status': 'skipped', 'message': skip_msg})
                        continue
                
                # åˆ›å»ºç‰©åŒ–è§†å›¾
                success, message = self.create_materialized_view(view_name)
                if success:
                    results['success'] += 1
                    results['details'].append({'view': view_name, 'status': 'success', 'message': message})
                else:
                    results['failed'] += 1
                    results['details'].append({'view': view_name, 'status': 'failed', 'message': message})
                    
            except Exception as e:
                error_msg = f"âŒ å¤„ç†ç‰©åŒ–è§†å›¾ {view_name} æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}"
                self.logger.error(error_msg)
                results['failed'] += 1
                results['details'].append({'view': view_name, 'status': 'failed', 'message': error_msg})
        
        # è¾“å‡ºæ€»ç»“
        self.logger.info(f"ğŸ“Š ç‰©åŒ–è§†å›¾åˆ›å»ºå®Œæˆ: æˆåŠŸ {results['success']}, å¤±è´¥ {results['failed']}, è·³è¿‡ {results['skipped']}")
        return results
    
    def get_view_status(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰ç‰©åŒ–è§†å›¾çŠ¶æ€
        
        Returns:
            List: ç‰©åŒ–è§†å›¾çŠ¶æ€åˆ—è¡¨
        """
        status_list = []
        
        for view_name, config in self.materialized_views.items():
            try:
                exists = self.check_view_exists(view_name)
                
                # è·å–ç›®æ ‡è¡¨æ•°æ®é‡
                target_count = 0
                if exists:
                    try:
                        query = f"SELECT count() FROM {self.database}.{config['target_table']}"
                        result = self.client.query(query)
                        target_count = result.result_rows[0][0]
                    except:
                        target_count = -1  # è¡¨ç¤ºæŸ¥è¯¢å¤±è´¥
                
                status_list.append({
                    'view_name': view_name,
                    'target_table': config['target_table'],
                    'description': config['description'],
                    'exists': exists,
                    'target_records': target_count,
                    'status': 'active' if exists and target_count >= 0 else 'inactive'
                })
                
            except Exception as e:
                status_list.append({
                    'view_name': view_name,
                    'target_table': config['target_table'],
                    'description': config['description'],
                    'exists': False,
                    'target_records': -1,
                    'status': 'error',
                    'error': str(e)
                })
        
        return status_list
    
    def print_status_report(self):
        """æ‰“å°ç‰©åŒ–è§†å›¾çŠ¶æ€æŠ¥å‘Š"""
        if not self.client:
            if not self.connect():
                return
        
        status_list = self.get_view_status()
        
        print("\n" + "="*80)
        print("ğŸ“Š ç‰©åŒ–è§†å›¾çŠ¶æ€æŠ¥å‘Š")
        print("="*80)
        
        for status in status_list:
            icon = "âœ…" if status['exists'] else "âŒ"
            records = status['target_records'] if status['target_records'] >= 0 else "N/A"
            
            print(f"{icon} {status['view_name']:<30} â†’ {status['target_table']:<30} ({records:>6} æ¡)")
            print(f"   ğŸ“ {status['description']}")
            
            if 'error' in status:
                print(f"   âš ï¸  é”™è¯¯: {status['error']}")
            print()
        
        # ç»Ÿè®¡
        total = len(status_list)
        active = sum(1 for s in status_list if s['exists'])
        print(f"ğŸ“ˆ æ€»è®¡: {total} ä¸ªç‰©åŒ–è§†å›¾, {active} ä¸ªå·²æ¿€æ´», {total-active} ä¸ªæœªæ¿€æ´»")
        print("="*80)


def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•å’Œç®¡ç†ç‰©åŒ–è§†å›¾"""
    import sys
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºç®¡ç†å™¨
    mv_manager = MaterializedViewManager()
    
    if not mv_manager.connect():
        print("âŒ æ— æ³•è¿æ¥åˆ°ClickHouseï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€")
        sys.exit(1)
    
    # æ ¹æ®å‚æ•°æ‰§è¡Œä¸åŒæ“ä½œ
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == 'create':
            force = '--force' in sys.argv
            results = mv_manager.create_all_views(force_recreate=force)
            print(f"\nâœ… ç‰©åŒ–è§†å›¾åˆ›å»ºå®Œæˆ: æˆåŠŸ {results['success']}, å¤±è´¥ {results['failed']}, è·³è¿‡ {results['skipped']}")
            
        elif command == 'status':
            mv_manager.print_status_report()
            
        elif command == 'drop':
            if len(sys.argv) > 2:
                view_name = sys.argv[2]
                success, msg = mv_manager.drop_materialized_view(view_name)
                print(msg)
            else:
                print("âŒ è¯·æŒ‡å®šè¦åˆ é™¤çš„ç‰©åŒ–è§†å›¾åç§°")
                
        else:
            print("âŒ æœªçŸ¥å‘½ä»¤ï¼Œæ”¯æŒçš„å‘½ä»¤: create, status, drop")
    else:
        # é»˜è®¤æ˜¾ç¤ºçŠ¶æ€
        mv_manager.print_status_report()


if __name__ == "__main__":
    main()