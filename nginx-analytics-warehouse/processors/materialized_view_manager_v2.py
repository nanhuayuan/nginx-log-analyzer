#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‰©åŒ–è§†å›¾ç®¡ç†å™¨V2 - ä¿®å¤ç‰ˆï¼Œä¸“é—¨è§£å†³æœåŠ¡å±‚çº§åˆ†æå’Œå…¶ä»–ç‰©åŒ–è§†å›¾çš„æ•°æ®é—®é¢˜
Materialized View Manager V2 - Fixed version for service-level analysis and other materialized views

ä¿®å¤å†…å®¹ï¼š
1. æœåŠ¡å±‚çº§åˆ†æï¼šä»URIæ­£ç¡®è§£æåº”ç”¨å’ŒæœåŠ¡å±‚çº§
2. æ…¢è¯·æ±‚åˆ†æï¼šä¿®å¤å­—æ®µåŒ¹é…å’Œæ¡ä»¶é€»è¾‘
3. çŠ¶æ€ç åˆ†æï¼šå¤„ç†ç©ºå€¼å’Œåˆ†ç»„é—®é¢˜
4. æ—¶é—´ç»´åº¦åˆ†æï¼šä¼˜åŒ–æ—¶é—´å­—æ®µå¤„ç†
"""

import logging
import time
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path
import clickhouse_connect
from clickhouse_connect.driver.exceptions import ClickHouseError

class MaterializedViewManagerV2:
    """ç‰©åŒ–è§†å›¾ç®¡ç†å™¨V2 - ä¿®å¤ç‰ˆ"""
    
    def __init__(self, host: str = 'localhost', port: int = 8123, 
                 database: str = 'nginx_analytics', user: str = 'analytics_user', 
                 password: str = 'analytics_password'):
        """åˆå§‹åŒ–ç‰©åŒ–è§†å›¾ç®¡ç†å™¨V2"""
        self.config = {
            'host': host,
            'port': port,
            'username': user,
            'password': password,
            'database': database
        }
        self.database = database
        self.client = None
        self.logger = logging.getLogger(__name__)
        
        # ä¿®å¤ç‰ˆç‰©åŒ–è§†å›¾é…ç½®
        self.materialized_views = self._initialize_fixed_view_definitions()
        
    def _initialize_fixed_view_definitions(self) -> Dict[str, Dict[str, Any]]:
        """åˆå§‹åŒ–ä¿®å¤ç‰ˆç‰©åŒ–è§†å›¾å®šä¹‰"""
        return {
            # 1. APIæ€§èƒ½åˆ†æç‰©åŒ–è§†å›¾ï¼ˆä¿æŒä¸å˜ï¼Œå› ä¸ºå·¥ä½œæ­£å¸¸ï¼‰
            'mv_api_performance_hourly': {
                'target_table': 'ads_api_performance_analysis',
                'description': 'æ¥å£æ€§èƒ½å°æ—¶çº§èšåˆ - å¯¹åº”01.æ¥å£æ€§èƒ½åˆ†æ.xlsx',
                'sql_template': """
                CREATE MATERIALIZED VIEW IF NOT EXISTS {database}.{view_name}
                TO {database}.{target_table}
                AS SELECT
                    toStartOfHour(log_time) as stat_time,
                    'hour' as time_granularity,
                    platform,
                    access_type,
                    request_uri as api_path,
                    api_module,
                    api_category,
                    business_domain,
                    
                    -- è¯·æ±‚é‡æŒ‡æ ‡
                    count() as total_requests,
                    uniq(client_ip) as unique_clients,
                    count() / 3600.0 as qps,
                    
                    -- æ€§èƒ½æŒ‡æ ‡
                    avg(total_request_duration) as avg_response_time,
                    quantile(0.5)(total_request_duration) as p50_response_time,
                    quantile(0.9)(total_request_duration) as p90_response_time,
                    quantile(0.95)(total_request_duration) as p95_response_time,
                    quantile(0.99)(total_request_duration) as p99_response_time,
                    max(total_request_duration) as max_response_time,
                    
                    -- æˆåŠŸç‡æŒ‡æ ‡
                    countIf(is_success) as success_requests,
                    countIf(is_error) as error_requests,
                    countIf(is_success) * 100.0 / count() as success_rate,
                    countIf(is_error) * 100.0 / count() as error_rate,
                    countIf(is_business_success) * 100.0 / count() as business_success_rate,
                    
                    -- æ…¢è¯·æ±‚åˆ†æ
                    countIf(is_slow) as slow_requests,
                    countIf(is_very_slow) as very_slow_requests,
                    countIf(is_slow) * 100.0 / count() as slow_rate,
                    countIf(is_very_slow) * 100.0 / count() as very_slow_rate,
                    
                    -- ç”¨æˆ·ä½“éªŒæŒ‡æ ‡
                    (countIf(total_request_duration <= 1.5) + 
                     countIf(total_request_duration > 1.5 AND total_request_duration <= 6.0) * 0.5) 
                     / count() as apdex_score,
                    multiIf(
                        avg(total_request_duration) <= 1.5, 100.0,
                        avg(total_request_duration) <= 6.0, 80.0,
                        60.0
                    ) as user_satisfaction_score,
                    
                    -- ä¸šåŠ¡ä»·å€¼
                    avg(business_value_score) as avg_business_value_score,
                    multiIf(
                        avg(business_value_score) >= 8, 'Critical',
                        avg(business_value_score) >= 6, 'High', 
                        avg(business_value_score) >= 4, 'Medium',
                        'Low'
                    ) as importance_level,
                    
                    now() as created_at
                FROM {database}.dwd_nginx_enriched_v2
                GROUP BY stat_time, platform, access_type, api_path, api_module, api_category, business_domain
                """
            },
            
            # 2. æœåŠ¡å±‚çº§åˆ†æç‰©åŒ–è§†å›¾ - å®Œå…¨é‡å†™ï¼ŒåŸºäºURIè§£æ
            'mv_service_level_hourly': {
                'target_table': 'ads_service_level_analysis',
                'description': 'æœåŠ¡å±‚çº§å°æ—¶çº§èšåˆ - åŸºäºURIè§£æåº”ç”¨æœåŠ¡å±‚çº§',
                'sql_template': """
                CREATE MATERIALIZED VIEW IF NOT EXISTS {database}.{view_name}
                TO {database}.{target_table}
                AS SELECT
                    toStartOfHour(log_time) as stat_time,
                    'hour' as time_granularity,
                    COALESCE(platform, 'unknown') as platform,
                    
                    -- æ™ºèƒ½è§£æåº”ç”¨å’ŒæœåŠ¡å±‚çº§ï¼Œå‚è€ƒself_02çš„é€»è¾‘
                    -- URIæ ¼å¼: /scmp-gateway/gxrz-rest/api/method
                    -- application = scmp-gateway, service = gxrz-rest
                    CASE 
                        WHEN request_uri LIKE '/%/%' 
                        THEN splitByChar('/', request_uri)[2]
                        WHEN service_name != ''
                        THEN splitByChar('-', service_name)[1] 
                        ELSE 'unknown'
                    END as service_name,
                    
                    COALESCE(cluster_node, 'default-cluster') as cluster_node,
                    
                    -- upstream_serverå¤„ç†ï¼šå¦‚æœä¸ºç©ºï¼Œç”¨'direct'å¡«å……
                    CASE
                        WHEN upstream_server != '' THEN upstream_server
                        ELSE 'direct'
                    END as upstream_server,
                    
                    -- æœåŠ¡å¥åº·æŒ‡æ ‡
                    count() as total_requests,
                    countIf(response_status_code LIKE '2%') as success_requests,
                    countIf(response_status_code LIKE '4%' OR response_status_code LIKE '5%') as error_requests,
                    countIf(total_request_duration >= 30.0) as timeout_requests,
                    
                    -- æœåŠ¡æ€§èƒ½
                    avg(total_request_duration) as avg_response_time,
                    quantile(0.95)(total_request_duration) as p95_response_time,
                    avg(COALESCE(upstream_response_time, total_request_duration)) as avg_upstream_time,
                    avg(COALESCE(upstream_connect_time, 0)) as avg_connect_time,
                    
                    -- æœåŠ¡è´¨é‡ï¼ˆç®€åŒ–é€»è¾‘ï¼Œé¿å…å¤æ‚å­—æ®µä¾èµ–ï¼‰
                    countIf(response_status_code LIKE '2%') * 100.0 / count() as availability,
                    countIf(total_request_duration <= 10.0) * 100.0 / count() as reliability,
                    (countIf(response_status_code LIKE '2%') * 0.6 + countIf(total_request_duration <= 10.0) * 0.4) as health_score,
                    
                    -- å®¹é‡æŒ‡æ ‡
                    max(COALESCE(connection_requests, 1)) as max_concurrent_requests,
                    count() / 3600.0 as avg_qps,
                    count() as request_count_for_peak_qps,
                    
                    now() as created_at
                FROM {database}.dwd_nginx_enriched_v2
                WHERE request_uri IS NOT NULL 
                AND request_uri != ''
                AND request_uri != 'unknown'
                GROUP BY stat_time, platform, service_name, cluster_node, upstream_server
                """
            },
            
            # 3. æ…¢è¯·æ±‚åˆ†æç‰©åŒ–è§†å›¾ - ä¿®å¤ç‰ˆ
            'mv_slow_request_hourly': {
                'target_table': 'ads_slow_request_analysis',
                'description': 'æ…¢è¯·æ±‚å°æ—¶çº§èšåˆ - ä¿®å¤å­—æ®µåŒ¹é…é—®é¢˜',
                'sql_template': """
                CREATE MATERIALIZED VIEW IF NOT EXISTS {database}.{view_name}
                TO {database}.{target_table}
                AS SELECT
                    toStartOfHour(log_time) as stat_time,
                    'hour' as time_granularity,
                    COALESCE(platform, 'unknown') as platform,
                    COALESCE(access_type, 'unknown') as access_type,
                    request_uri as api_path,
                    COALESCE(api_module, 'unknown') as api_module,
                    COALESCE(api_category, 'unknown') as api_category,
                    COALESCE(business_domain, 'unknown') as business_domain,
                    
                    -- æ…¢è¯·æ±‚ç»Ÿè®¡ï¼ˆä½¿ç”¨ç›´æ¥çš„æ—¶é—´æ¡ä»¶ï¼Œè€Œä¸ä¾èµ–is_slowå­—æ®µï¼‰
                    count() as total_requests,
                    countIf(total_request_duration >= 3.0) as slow_requests,
                    countIf(total_request_duration >= 10.0) as very_slow_requests,
                    countIf(total_request_duration >= 3.0) * 100.0 / count() as slow_rate,
                    countIf(total_request_duration >= 10.0) * 100.0 / count() as very_slow_rate,
                    
                    -- æ€§èƒ½åˆ†æ
                    avg(total_request_duration) as avg_response_time,
                    quantile(0.95)(total_request_duration) as p95_response_time,
                    quantile(0.99)(total_request_duration) as p99_response_time,
                    max(total_request_duration) as max_response_time,
                    
                    -- æ…¢è¯·æ±‚åŸå› åˆ†æï¼ˆç®€åŒ–å¤„ç†ï¼‰
                    avgIf(COALESCE(upstream_response_time, 0), total_request_duration >= 3.0) as avg_upstream_time_slow,
                    avgIf(COALESCE(network_phase, 0), total_request_duration >= 3.0) as avg_network_time_slow,
                    avgIf(COALESCE(processing_phase, 0), total_request_duration >= 3.0) as avg_processing_time_slow,
                    
                    -- å½±å“åˆ†æ
                    uniq(client_ip) as affected_users,
                    sum(COALESCE(response_body_size, 0)) as total_data_transferred,
                    avg(COALESCE(business_value_score, 5)) as business_impact_score,
                    
                    now() as created_at
                FROM {database}.dwd_nginx_enriched_v2
                WHERE total_request_duration IS NOT NULL 
                AND total_request_duration > 0
                GROUP BY stat_time, platform, access_type, api_path, api_module, api_category, business_domain
                """
            },
            
            # 4. çŠ¶æ€ç åˆ†æç‰©åŒ–è§†å›¾ - ä¿®å¤ç‰ˆ
            'mv_status_code_hourly': {
                'target_table': 'ads_status_code_analysis',
                'description': 'çŠ¶æ€ç å°æ—¶çº§èšåˆ - ä¿®å¤åˆ†ç»„å’Œç™¾åˆ†æ¯”è®¡ç®—',
                'sql_template': """
                CREATE MATERIALIZED VIEW IF NOT EXISTS {database}.{view_name}
                TO {database}.{target_table}
                AS SELECT
                    toStartOfHour(log_time) as stat_time,
                    'hour' as time_granularity,
                    COALESCE(platform, 'unknown') as platform,
                    COALESCE(access_type, 'unknown') as access_type,
                    COALESCE(response_status_code, '200') as status_code,
                    
                    -- åŸºç¡€ç»Ÿè®¡
                    count() as request_count,
                    uniq(client_ip) as unique_clients,
                    uniq(request_uri) as unique_apis,
                    
                    -- åˆ†ç±»ç»Ÿè®¡
                    multiIf(
                        response_status_code LIKE '2%', 'Success',
                        response_status_code LIKE '3%', 'Redirect', 
                        response_status_code LIKE '4%', 'Client Error',
                        response_status_code LIKE '5%', 'Server Error',
                        'Other'
                    ) as status_category,
                    
                    -- æ€§èƒ½å½±å“
                    avg(total_request_duration) as avg_response_time,
                    quantile(0.95)(total_request_duration) as p95_response_time,
                    
                    -- ä¸šåŠ¡å½±å“
                    avg(COALESCE(business_value_score, 5)) as avg_business_impact,
                    
                    now() as created_at
                FROM {database}.dwd_nginx_enriched_v2
                WHERE response_status_code IS NOT NULL 
                AND response_status_code != ''
                GROUP BY stat_time, platform, access_type, response_status_code
                """
            },
            
            # 5. æ—¶é—´ç»´åº¦åˆ†æç‰©åŒ–è§†å›¾ - ä¿®å¤ç‰ˆ
            'mv_time_dimension_hourly': {
                'target_table': 'ads_time_dimension_analysis', 
                'description': 'æ—¶é—´ç»´åº¦å°æ—¶çº§èšåˆ - ä¼˜åŒ–æ—¶é—´å­—æ®µå¤„ç†',
                'sql_template': """
                CREATE MATERIALIZED VIEW IF NOT EXISTS {database}.{view_name}
                TO {database}.{target_table}
                AS SELECT
                    toStartOfHour(log_time) as stat_time,
                    'hour' as time_granularity,
                    COALESCE(platform, 'unknown') as platform,
                    toHour(log_time) as hour_of_day,
                    toDayOfWeek(log_time) as day_of_week,
                    toDayOfWeek(log_time) IN (6, 7) as is_weekend,
                    
                    -- æµé‡ç»Ÿè®¡
                    count() as total_requests,
                    count() / 3600.0 as avg_qps,
                    uniq(client_ip) as unique_clients,
                    
                    -- æ€§èƒ½ç»Ÿè®¡
                    avg(total_request_duration) as avg_response_time,
                    quantile(0.95)(total_request_duration) as p95_response_time,
                    
                    -- è´¨é‡ç»Ÿè®¡ï¼ˆä½¿ç”¨çŠ¶æ€ç ç›´æ¥åˆ¤æ–­ï¼‰
                    countIf(response_status_code LIKE '2%') * 100.0 / count() as success_rate,
                    countIf(response_status_code LIKE '4%' OR response_status_code LIKE '5%') * 100.0 / count() as error_rate,
                    countIf(total_request_duration >= 3.0) * 100.0 / count() as slow_rate,
                    
                    -- ç”¨æˆ·ä½“éªŒ
                    (countIf(total_request_duration <= 1.5) + 
                     countIf(total_request_duration > 1.5 AND total_request_duration <= 6.0) * 0.5) 
                     / count() as apdex_score,
                    
                    now() as created_at
                FROM {database}.dwd_nginx_enriched_v2
                WHERE log_time IS NOT NULL
                GROUP BY stat_time, platform, hour_of_day, day_of_week, is_weekend
                """
            }
        }
    
    def connect(self) -> bool:
        """è¿æ¥ClickHouseæ•°æ®åº“"""
        try:
            self.client = clickhouse_connect.get_client(**self.config)
            result = self.client.query("SELECT 1")
            self.logger.info(f"âœ… ç‰©åŒ–è§†å›¾ç®¡ç†å™¨V2è¿æ¥æˆåŠŸ: {self.config['host']}:{self.config['port']}")
            return True
        except Exception as e:
            self.logger.error(f"âŒ ç‰©åŒ–è§†å›¾ç®¡ç†å™¨V2è¿æ¥å¤±è´¥: {str(e)}")
            return False
    
    def check_view_exists(self, view_name: str) -> bool:
        """æ£€æŸ¥ç‰©åŒ–è§†å›¾æ˜¯å¦å­˜åœ¨"""
        try:
            query = f"""
            SELECT count() 
            FROM system.tables 
            WHERE database = '{self.database}' 
            AND name = '{view_name}' 
            AND engine = 'MaterializedView'
            """
            result = self.client.query(query)
            return result.result_rows[0][0] > 0
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥ç‰©åŒ–è§†å›¾å­˜åœ¨æ€§å¤±è´¥ {view_name}: {str(e)}")
            return False
    
    def create_materialized_view(self, view_name: str) -> Tuple[bool, str]:
        """åˆ›å»ºå•ä¸ªç‰©åŒ–è§†å›¾"""
        if view_name not in self.materialized_views:
            return False, f"æœªçŸ¥çš„ç‰©åŒ–è§†å›¾: {view_name}"
        
        view_config = self.materialized_views[view_name]
        
        try:
            # æ ¼å¼åŒ–SQL
            sql = view_config['sql_template'].format(
                database=self.database,
                view_name=view_name,
                target_table=view_config['target_table']
            )
            
            # æ‰§è¡Œåˆ›å»º
            start_time = time.time()
            self.client.query(sql)
            duration = time.time() - start_time
            
            success_msg = f"âœ… ç‰©åŒ–è§†å›¾V2 {view_name} åˆ›å»ºæˆåŠŸ ({view_config['description']})ï¼Œè€—æ—¶ {duration:.2f}s"
            self.logger.info(success_msg)
            return True, success_msg
            
        except ClickHouseError as e:
            error_msg = f"âŒ ç‰©åŒ–è§†å›¾V2 {view_name} åˆ›å»ºå¤±è´¥: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg
        except Exception as e:
            error_msg = f"âŒ ç‰©åŒ–è§†å›¾V2 {view_name} åˆ›å»ºå¼‚å¸¸: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg
    
    def drop_materialized_view(self, view_name: str) -> Tuple[bool, str]:
        """åˆ é™¤ç‰©åŒ–è§†å›¾"""
        try:
            sql = f"DROP VIEW IF EXISTS {self.database}.{view_name}"
            self.client.query(sql)
            
            success_msg = f"âœ… ç‰©åŒ–è§†å›¾V2 {view_name} åˆ é™¤æˆåŠŸ"
            self.logger.info(success_msg)
            return True, success_msg
            
        except Exception as e:
            error_msg = f"âŒ ç‰©åŒ–è§†å›¾V2 {view_name} åˆ é™¤å¤±è´¥: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg
    
    def create_all_views(self, force_recreate: bool = False) -> Dict[str, Any]:
        """åˆ›å»ºæ‰€æœ‰ç‰©åŒ–è§†å›¾V2"""
        results = {
            'total': len(self.materialized_views),
            'success': 0,
            'failed': 0,
            'skipped': 0,
            'details': []
        }
        
        self.logger.info(f"ğŸš€ å¼€å§‹åˆ›å»º {results['total']} ä¸ªç‰©åŒ–è§†å›¾V2...")
        
        for view_name in self.materialized_views.keys():
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                if self.check_view_exists(view_name):
                    if force_recreate:
                        self.logger.info(f"ğŸ”„ ç‰©åŒ–è§†å›¾V2 {view_name} å·²å­˜åœ¨ï¼Œå¼ºåˆ¶é‡æ–°åˆ›å»º...")
                        drop_success, drop_msg = self.drop_materialized_view(view_name)
                        if not drop_success:
                            results['failed'] += 1
                            results['details'].append({'view': view_name, 'status': 'failed', 'message': drop_msg})
                            continue
                    else:
                        skip_msg = f"â­ï¸ ç‰©åŒ–è§†å›¾V2 {view_name} å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º"
                        self.logger.info(skip_msg)
                        results['skipped'] += 1
                        results['details'].append({'view': view_name, 'status': 'skipped', 'message': skip_msg})
                        continue
                
                # åˆ›å»ºç‰©åŒ–è§†å›¾
                success, message = self.create_materialized_view(view_name)
                if success:
                    results['success'] += 1
                    results['details'].append({'view': view_name, 'status': 'success', 'message': message})
                else:
                    results['failed'] += 1
                    results['details'].append({'view': view_name, 'status': 'failed', 'message': message})
                    
            except Exception as e:
                error_msg = f"âŒ å¤„ç†ç‰©åŒ–è§†å›¾V2 {view_name} æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}"
                self.logger.error(error_msg)
                results['failed'] += 1
                results['details'].append({'view': view_name, 'status': 'failed', 'message': error_msg})
        
        self.logger.info(f"ğŸ“Š ç‰©åŒ–è§†å›¾V2åˆ›å»ºå®Œæˆ: æˆåŠŸ {results['success']}, å¤±è´¥ {results['failed']}, è·³è¿‡ {results['skipped']}")
        return results
    
    def get_view_status(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰ç‰©åŒ–è§†å›¾çŠ¶æ€"""
        status_list = []
        
        for view_name, config in self.materialized_views.items():
            try:
                exists = self.check_view_exists(view_name)
                
                # è·å–ç›®æ ‡è¡¨æ•°æ®é‡
                target_count = 0
                if exists:
                    try:
                        query = f"SELECT count() FROM {self.database}.{config['target_table']}"
                        result = self.client.query(query)
                        target_count = result.result_rows[0][0]
                    except:
                        target_count = -1
                
                status_list.append({
                    'view_name': view_name,
                    'target_table': config['target_table'],
                    'description': config['description'],
                    'exists': exists,
                    'target_records': target_count,
                    'status': 'active' if exists and target_count >= 0 else 'inactive'
                })
                
            except Exception as e:
                status_list.append({
                    'view_name': view_name,
                    'target_table': config['target_table'],
                    'description': config['description'],
                    'exists': False,
                    'target_records': -1,
                    'status': 'error',
                    'error': str(e)
                })
        
        return status_list
    
    def print_status_report(self):
        """æ‰“å°ç‰©åŒ–è§†å›¾V2çŠ¶æ€æŠ¥å‘Š"""
        if not self.client:
            if not self.connect():
                return
        
        status_list = self.get_view_status()
        
        print("\n" + "="*80)
        print("ğŸ“Š ç‰©åŒ–è§†å›¾V2çŠ¶æ€æŠ¥å‘Š (ä¿®å¤ç‰ˆ)")
        print("="*80)
        
        for status in status_list:
            icon = "âœ…" if status['exists'] else "âŒ"
            records = status['target_records'] if status['target_records'] >= 0 else "N/A"
            
            print(f"{icon} {status['view_name']:<30} â†’ {status['target_table']:<30} ({records:>6} æ¡)")
            print(f"   ğŸ“ {status['description']}")
            
            if 'error' in status:
                print(f"   âš ï¸  é”™è¯¯: {status['error']}")
            print()
        
        # ç»Ÿè®¡
        total = len(status_list)
        active = sum(1 for s in status_list if s['exists'])
        print(f"ğŸ“ˆ æ€»è®¡: {total} ä¸ªç‰©åŒ–è§†å›¾V2, {active} ä¸ªå·²æ¿€æ´», {total-active} ä¸ªæœªæ¿€æ´»")
        print("="*80)


def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•å’Œç®¡ç†ç‰©åŒ–è§†å›¾V2"""
    import sys
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºç®¡ç†å™¨V2
    mv_manager = MaterializedViewManagerV2()
    
    if not mv_manager.connect():
        print("âŒ æ— æ³•è¿æ¥åˆ°ClickHouseï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€")
        sys.exit(1)
    
    # æ ¹æ®å‚æ•°æ‰§è¡Œä¸åŒæ“ä½œ
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == 'create':
            force = '--force' in sys.argv
            results = mv_manager.create_all_views(force_recreate=force)
            print(f"\nâœ… ç‰©åŒ–è§†å›¾V2åˆ›å»ºå®Œæˆ: æˆåŠŸ {results['success']}, å¤±è´¥ {results['failed']}, è·³è¿‡ {results['skipped']}")
            
        elif command == 'status':
            mv_manager.print_status_report()
            
        elif command == 'drop':
            if len(sys.argv) > 2:
                view_name = sys.argv[2]
                success, msg = mv_manager.drop_materialized_view(view_name)
                print(msg)
            else:
                print("âŒ è¯·æŒ‡å®šè¦åˆ é™¤çš„ç‰©åŒ–è§†å›¾åç§°")
                
        else:
            print("âŒ æœªçŸ¥å‘½ä»¤ï¼Œæ”¯æŒçš„å‘½ä»¤: create, status, drop")
    else:
        # é»˜è®¤æ˜¾ç¤ºçŠ¶æ€
        mv_manager.print_status_report()


if __name__ == "__main__":
    main()