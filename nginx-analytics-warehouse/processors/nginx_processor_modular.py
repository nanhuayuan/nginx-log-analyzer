#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Nginxæ—¥å¿—å¤„ç†å™¨ - æ¨¡å—åŒ–æ¶æ„ä¸»æ§åˆ¶å™¨
Nginx Log Processor - Modular Architecture Main Controller

ç»Ÿä¸€è°ƒåº¦å’Œç®¡ç†æ—¥å¿—è§£æã€æ•°æ®å¤„ç†ã€æ•°æ®åº“å†™å…¥ç­‰æ¨¡å—
æ”¯æŒæ—¥å¸¸æ—¥å¿—å¤„ç†ã€çŠ¶æ€è·Ÿè¸ªã€æ•°æ®æ¸…ç†ç­‰åŠŸèƒ½
"""

import os
import json
import time
import argparse
from datetime import datetime, date, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import logging

# å¯¼å…¥æ¨¡å—åŒ–ç»„ä»¶
from log_parser import NginxLogParser
from data_processor import DataProcessor  
from database_writer import DatabaseWriter

class NginxProcessorModular:
    """æ¨¡å—åŒ–Nginxæ—¥å¿—å¤„ç†å™¨ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self, base_log_dir: str = None, state_file: str = None):
        # åŸºç¡€é…ç½®
        self.base_log_dir = Path(base_log_dir) if base_log_dir else Path("D:/project/nginx-log-analyzer/nginx-analytics-warehouse/nginx_logs")
        self.state_file = Path(state_file) if state_file else Path("processed_logs_state.json")
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.log_parser = NginxLogParser()
        self.data_processor = DataProcessor()
        self.database_writer = DatabaseWriter(host='localhost', port=8123,
                 database='nginx_analytics', user='analytics_user', password='analytics_password')
        
        # æ—¥å¿—é…ç½®
        self.logger = logging.getLogger(__name__)
        
        # å¤„ç†çŠ¶æ€
        self.processed_state = self.load_state()
        
        # æ€§èƒ½é…ç½®
        self.chunk_size = 500  # æ¯æ‰¹å¤„ç†çš„è®°å½•æ•°
        self.max_memory_mb = 512  # æœ€å¤§å†…å­˜ä½¿ç”¨MB
        
        print("âœ… æ¨¡å—åŒ–Nginxæ—¥å¿—å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ æ—¥å¿—ç›®å½•: {self.base_log_dir}")
        print(f"ğŸ“„ çŠ¶æ€æ–‡ä»¶: {self.state_file}")
    
    def load_state(self) -> Dict[str, Any]:
        """åŠ è½½å¤„ç†çŠ¶æ€"""
        if self.state_file.exists():
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    state = json.load(f)
                    self.logger.info(f"åŠ è½½çŠ¶æ€æ–‡ä»¶: {len(state.get('processed_files', {}))} ä¸ªå·²å¤„ç†æ–‡ä»¶")
                    return state
            except Exception as e:
                self.logger.error(f"åŠ è½½çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
        
        return {
            'processed_files': {},
            'last_update': None,
            'total_processed_records': 0,
            'processing_history': []
        }
    
    def save_state(self):
        """ä¿å­˜å¤„ç†çŠ¶æ€"""
        try:
            self.processed_state['last_update'] = datetime.now().isoformat()
            with open(self.state_file, 'w', encoding='utf-8') as f:
                json.dump(self.processed_state, f, indent=2, ensure_ascii=False, default=str)
            self.logger.info("çŠ¶æ€æ–‡ä»¶ä¿å­˜æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"ä¿å­˜çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
    
    def scan_log_directories(self) -> Dict[str, List[Path]]:
        """æ‰«ææ—¥å¿—ç›®å½•ï¼Œè¿”å›æŒ‰æ—¥æœŸåˆ†ç»„çš„æ—¥å¿—æ–‡ä»¶"""
        if not self.base_log_dir.exists():
            self.logger.error(f"æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {self.base_log_dir}")
            return {}
        
        log_files_by_date = {}
        
        # æ‰«æYYYYMMDDæ ¼å¼çš„ç›®å½•
        for date_dir in self.base_log_dir.iterdir():
            if date_dir.is_dir() and date_dir.name.isdigit() and len(date_dir.name) == 8:
                try:
                    # éªŒè¯æ—¥æœŸæ ¼å¼
                    datetime.strptime(date_dir.name, '%Y%m%d')
                    
                    # æŸ¥æ‰¾.logæ–‡ä»¶
                    log_files = list(date_dir.glob("*.log"))
                    if log_files:
                        log_files_by_date[date_dir.name] = sorted(log_files)
                        
                except ValueError:
                    self.logger.warning(f"å¿½ç•¥æ— æ•ˆæ—¥æœŸç›®å½•: {date_dir.name}")
        
        self.logger.info(f"æ‰«æåˆ° {len(log_files_by_date)} ä¸ªæ—¥æœŸç›®å½•")
        return log_files_by_date
    
    def is_file_processed(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å¤„ç†"""
        file_key = str(file_path)
        if file_key not in self.processed_state['processed_files']:
            return False
        
        # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ˜¯å¦å˜åŒ–
        try:
            current_mtime = file_path.stat().st_mtime
            recorded_mtime = self.processed_state['processed_files'][file_key].get('mtime', 0)
            return abs(current_mtime - recorded_mtime) < 1.0  # 1ç§’è¯¯å·®å®¹å¿
        except:
            return False
    
    def mark_file_processed(self, file_path: Path, record_count: int, processing_time: float):
        """æ ‡è®°æ–‡ä»¶ä¸ºå·²å¤„ç†"""
        file_key = str(file_path)
        try:
            mtime = file_path.stat().st_mtime
            self.processed_state['processed_files'][file_key] = {
                'processed_at': datetime.now().isoformat(),
                'record_count': record_count,
                'processing_time': processing_time,
                'mtime': mtime,
                'file_size': file_path.stat().st_size
            }
        except Exception as e:
            self.logger.error(f"æ ‡è®°æ–‡ä»¶çŠ¶æ€å¤±è´¥ {file_path}: {e}")
    
    def process_specific_date(self, date_str: str, force_reprocess: bool = False) -> Dict[str, Any]:
        """å¤„ç†æŒ‡å®šæ—¥æœŸçš„æ—¥å¿—"""
        self.logger.info(f"å¼€å§‹å¤„ç† {date_str} çš„æ—¥å¿— (å¼ºåˆ¶é‡æ–°å¤„ç†: {force_reprocess})")
        
        start_time = time.time()
        
        # æ£€æŸ¥æ—¥æœŸç›®å½•
        date_dir = self.base_log_dir / date_str
        if not date_dir.exists():
            return {
                'success': False,
                'error': f'æ—¥æœŸç›®å½•ä¸å­˜åœ¨: {date_dir}',
                'date': date_str,
                'processed_files': 0,
                'total_records': 0
            }
        
        log_files = list(date_dir.glob("*.log"))
        if not log_files:
            return {
                'success': False,
                'error': f'ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°.logæ–‡ä»¶: {date_dir}',
                'date': date_str,
                'processed_files': 0,
                'total_records': 0
            }
        
        self.logger.info(f"æ‰¾åˆ° {len(log_files)} ä¸ªæ—¥å¿—æ–‡ä»¶")
        
        # è¿æ¥æ•°æ®åº“
        if not self.database_writer.connect():
            return {
                'success': False,
                'error': 'ClickHouseè¿æ¥å¤±è´¥',
                'date': date_str,
                'processed_files': 0,
                'total_records': 0
            }
        
        try:
            total_records = 0
            processed_files = 0
            errors = []
            
            for log_file in sorted(log_files):
                self.logger.info(f"å¤„ç†æ–‡ä»¶: {log_file.name}")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†
                if not force_reprocess and self.is_file_processed(log_file):
                    self.logger.info(f"è·³è¿‡å·²å¤„ç†æ–‡ä»¶: {log_file.name}")
                    continue
                
                # å¤„ç†å•ä¸ªæ–‡ä»¶
                file_result = self.process_single_file(log_file)
                
                if file_result['success']:
                    total_records += file_result['record_count']
                    processed_files += 1
                    
                    # æ ‡è®°ä¸ºå·²å¤„ç†
                    self.mark_file_processed(log_file, file_result['record_count'], file_result['duration'])
                else:
                    errors.append(f"{log_file.name}: {file_result['error']}")
                    self.logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥ {log_file.name}: {file_result['error']}")
            
            # ä¿å­˜çŠ¶æ€
            self.save_state()
            
            duration = time.time() - start_time
            success = len(errors) == 0
            
            result = {
                'success': success,
                'date': date_str,
                'processed_files': processed_files,
                'total_records': total_records,
                'duration': duration,
                'errors': errors
            }
            
            if success:
                self.logger.info(f"æ—¥æœŸ {date_str} å¤„ç†å®Œæˆ: {processed_files} æ–‡ä»¶, {total_records} è®°å½•, è€—æ—¶ {duration:.2f}s")
                
                # è®°å½•å¤„ç†å†å²
                self.processed_state['processing_history'].append({
                    'date': date_str,
                    'processed_at': datetime.now().isoformat(),
                    'files': processed_files,
                    'records': total_records,
                    'duration': duration
                })
            
            return result
            
        finally:
            self.database_writer.close()
    
    def process_single_file(self, file_path: Path) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªæ—¥å¿—æ–‡ä»¶"""
        start_time = time.time()
        
        try:
            # è§£æé˜¶æ®µ
            self.logger.info(f"ç¬¬ä¸€é˜¶æ®µ: è§£ææ—¥å¿—æ–‡ä»¶ {file_path.name}")
            parsed_records = []
            
            for parsed_record in self.log_parser.parse_log_file(file_path):
                parsed_records.append(parsed_record)
                
                # åˆ†æ‰¹å¤„ç†é¿å…å†…å­˜é—®é¢˜
                if len(parsed_records) >= self.chunk_size:
                    # æ•°æ®å¤„ç†é˜¶æ®µ
                    processed_records = []
                    for record in parsed_records:
                        processed_record = self.data_processor.process_single_record(record)
                        processed_records.append(processed_record)
                    
                    # æ•°æ®åº“å†™å…¥é˜¶æ®µ
                    write_result = self.database_writer.write_processed_records(processed_records)
                    if not write_result['success']:
                        return {
                            'success': False,
                            'error': f"æ•°æ®å†™å…¥å¤±è´¥: {write_result['message']}",
                            'record_count': 0,
                            'duration': time.time() - start_time
                        }
                    
                    parsed_records = []  # æ¸…ç©ºç¼“å­˜
            
            # å¤„ç†å‰©ä½™è®°å½•
            if parsed_records:
                # æ•°æ®å¤„ç†é˜¶æ®µ
                processed_records = []
                for record in parsed_records:
                    processed_record = self.data_processor.process_single_record(record)
                    processed_records.append(processed_record)
                
                # æ•°æ®åº“å†™å…¥é˜¶æ®µ
                write_result = self.database_writer.write_processed_records(processed_records)
                if not write_result['success']:
                    return {
                        'success': False,
                        'error': f"æ•°æ®å†™å…¥å¤±è´¥: {write_result['message']}",
                        'record_count': 0,
                        'duration': time.time() - start_time
                    }
            
            duration = time.time() - start_time
            total_count = len(parsed_records) if parsed_records else 0
            
            return {
                'success': True,
                'record_count': total_count,
                'duration': duration
            }
            
        except Exception as e:
            self.logger.error(f"æ–‡ä»¶å¤„ç†å¼‚å¸¸ {file_path}: {e}")
            return {
                'success': False,
                'error': str(e),
                'record_count': 0,
                'duration': time.time() - start_time
            }
    
    def process_all_unprocessed_logs(self) -> Dict[str, Any]:
        """å¤„ç†æ‰€æœ‰æœªå¤„ç†çš„æ—¥å¿—"""
        self.logger.info("å¼€å§‹å¤„ç†æ‰€æœ‰æœªå¤„ç†çš„æ—¥å¿—")
        start_time = time.time()
        
        log_files_by_date = self.scan_log_directories()
        if not log_files_by_date:
            return {
                'success': False,
                'error': 'æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶',
                'processed_dates': 0,
                'total_records': 0
            }
        
        processed_dates = 0
        total_records = 0
        errors = []
        
        for date_str in sorted(log_files_by_date.keys()):
            self.logger.info(f"å¤„ç†æ—¥æœŸ: {date_str}")
            
            result = self.process_specific_date(date_str, force_reprocess=False)
            
            if result['success']:
                processed_dates += 1
                total_records += result['total_records']
            else:
                errors.extend(result.get('errors', [result.get('error', 'æœªçŸ¥é”™è¯¯')]))
        
        duration = time.time() - start_time
        success = len(errors) == 0
        
        return {
            'success': success,
            'processed_dates': processed_dates,
            'total_records': total_records,
            'duration': duration,
            'errors': errors
        }
    
    def clear_all_data(self):
        """æ¸…ç©ºæ‰€æœ‰æ•°æ®"""
        self.logger.info("å¼€å§‹æ¸…ç©ºæ‰€æœ‰æ•°æ®")
        
        if not self.database_writer.connect():
            print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
            return
        
        try:
            # æ¸…ç©ºæ•°æ®åº“è¡¨
            result = self.database_writer.clear_data()
            
            success_count = sum(1 for r in result.values() if r['success'])
            total_count = len(result)
            
            if success_count == total_count:
                print(f"âœ… æˆåŠŸæ¸…ç©º {total_count} ä¸ªè¡¨")
                
                # æ¸…ç©ºçŠ¶æ€æ–‡ä»¶
                self.processed_state = {
                    'processed_files': {},
                    'last_update': None,
                    'total_processed_records': 0,
                    'processing_history': []
                }
                self.save_state()
                print("âœ… çŠ¶æ€æ–‡ä»¶å·²é‡ç½®")
            else:
                print(f"âš ï¸  éƒ¨åˆ†æ¸…ç©ºæˆåŠŸ: {success_count}/{total_count}")
                for table, info in result.items():
                    if not info['success']:
                        print(f"   âŒ {table}: {info['message']}")
                        
        finally:
            self.database_writer.close()
    
    def show_status(self):
        """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
        print("=" * 60)
        print("ğŸ“Š ç³»ç»ŸçŠ¶æ€æ¦‚è§ˆ")
        print("=" * 60)
        
        # 1. æ—¥å¿—ç›®å½•çŠ¶æ€
        log_files_by_date = self.scan_log_directories()
        print(f"ğŸ“ æ—¥å¿—ç›®å½•: {self.base_log_dir}")
        print(f"   æ‰¾åˆ° {len(log_files_by_date)} ä¸ªæ—¥æœŸç›®å½•")
        
        if log_files_by_date:
            total_files = sum(len(files) for files in log_files_by_date.values())
            print(f"   æ€»è®¡ {total_files} ä¸ªæ—¥å¿—æ–‡ä»¶")
            
            # æ˜¾ç¤ºæœ€è¿‘çš„å‡ ä¸ªæ—¥æœŸ
            recent_dates = sorted(log_files_by_date.keys())[-5:]
            print(f"   æœ€è¿‘çš„æ—¥æœŸ: {', '.join(recent_dates)}")
        
        # 2. æ•°æ®åº“çŠ¶æ€
        if self.database_writer.connect():
            try:
                status = self.database_writer.check_table_status()
                counts = self.database_writer.get_data_counts()
                
                print(f"\nğŸ’¾ æ•°æ®åº“çŠ¶æ€:")
                for table, info in status.items():
                    count = counts.get(table, 0)
                    if info['exists']:
                        print(f"   âœ… {table}: {count:,} æ¡è®°å½•")
                        if info['last_update']:
                            print(f"      æœ€åæ›´æ–°: {info['last_update']}")
                    else:
                        print(f"   âŒ {table}: è¡¨ä¸å­˜åœ¨")
                        
            finally:
                self.database_writer.close()
        else:
            print(f"\nğŸ’¾ æ•°æ®åº“çŠ¶æ€: âŒ è¿æ¥å¤±è´¥")
        
        # 3. å¤„ç†çŠ¶æ€
        processed_files_count = len(self.processed_state.get('processed_files', {}))
        print(f"\nğŸ“ˆ å¤„ç†çŠ¶æ€:")
        print(f"   å·²å¤„ç†æ–‡ä»¶: {processed_files_count} ä¸ª")
        
        if self.processed_state.get('last_update'):
            print(f"   æœ€åæ›´æ–°: {self.processed_state['last_update']}")
        
        # æœ€è¿‘å¤„ç†å†å²
        history = self.processed_state.get('processing_history', [])
        if history:
            print(f"   æœ€è¿‘å¤„ç†è®°å½•:")
            for record in history[-3:]:  # æ˜¾ç¤ºæœ€è¿‘3æ¡
                date_str = record.get('date', 'Unknown')
                files = record.get('files', 0)
                records = record.get('records', 0)
                duration = record.get('duration', 0)
                print(f"     {date_str}: {files} æ–‡ä»¶, {records:,} è®°å½•, {duration:.1f}s")
    
    def interactive_menu(self):
        """äº¤äº’å¼èœå•"""
        while True:
            print("\n" + "=" * 60)
            print("ğŸš€  Nginxæ—¥å¿—å¤„ç†å™¨ - æ¨¡å—åŒ–æ¶æ„")
            print("=" * 60)
            print("1. å¤„ç†æ‰€æœ‰æœªå¤„ç†çš„æ—¥å¿— (æ¨è)")
            print("2. å¤„ç†æŒ‡å®šæ—¥æœŸçš„æ—¥å¿—")
            print("3. æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€")
            print("4. æ¸…ç©ºæ‰€æœ‰æ•°æ® (ä»…å¼€å‘ç¯å¢ƒ)")
            print("5. å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰æ—¥å¿—")
            print("0. é€€å‡º")
            print("-" * 60)
            
            try:
                choice = input("è¯·é€‰æ‹©æ“ä½œ [0-5]: ").strip()
                
                if choice == '0':
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                
                elif choice == '1':
                    print("\nğŸ”„ å¼€å§‹å¤„ç†æ‰€æœ‰æœªå¤„ç†çš„æ—¥å¿—...")
                    result = self.process_all_unprocessed_logs()
                    self._print_process_result(result, "æ‰¹é‡å¤„ç†")
                    input("\næŒ‰å›è½¦é”®ç»§ç»­...")
                
                elif choice == '2':
                    date_str = input("\nè¯·è¾“å…¥æ—¥æœŸ (YYYYMMDDæ ¼å¼ï¼Œå¦‚: 20250422): ").strip()
                    if not date_str or len(date_str) != 8 or not date_str.isdigit():
                        print("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨YYYYMMDDæ ¼å¼")
                        input("æŒ‰å›è½¦é”®ç»§ç»­...")
                        continue
                    
                    try:
                        datetime.strptime(date_str, '%Y%m%d')
                    except ValueError:
                        print("âŒ æ— æ•ˆçš„æ—¥æœŸ")
                        input("æŒ‰å›è½¦é”®ç»§ç»­...")
                        continue
                    
                    force = input("æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†ï¼Ÿ(y/N): ").strip().lower() == 'y'
                    
                    print(f"\nğŸ”„ å¼€å§‹å¤„ç† {date_str} çš„æ—¥å¿—...")
                    result = self.process_specific_date(date_str, force)
                    self._print_single_date_result(result)
                    input("\næŒ‰å›è½¦é”®ç»§ç»­...")
                
                elif choice == '3':
                    print()
                    self.show_status()
                    input("\næŒ‰å›è½¦é”®ç»§ç»­...")
                
                elif choice == '4':
                    print("\nâš ï¸  æ¸…ç©ºæ‰€æœ‰æ•°æ® (ä»…å¼€å‘ç¯å¢ƒä½¿ç”¨)")
                    confirm = input("ç¡®è®¤æ¸…ç©ºæ‰€æœ‰æ•°æ®ï¼Ÿè¿™å°†åˆ é™¤æ•°æ®åº“ä¸­çš„æ‰€æœ‰æ—¥å¿—æ•°æ® (y/N): ").strip().lower()
                    if confirm == 'y':
                        second_confirm = input("å†æ¬¡ç¡®è®¤ï¼è¿™å°†ä¸å¯æ¢å¤åœ°åˆ é™¤æ‰€æœ‰æ•°æ® (è¾“å…¥ 'DELETE' ç¡®è®¤): ").strip()
                        if second_confirm == 'DELETE':
                            print("\nğŸ”„ å¼€å§‹æ¸…ç©ºæ•°æ®...")
                            self.clear_all_data()
                        else:
                            print("âŒ ç¡®è®¤å¤±è´¥ï¼Œæ“ä½œå·²å–æ¶ˆ")
                    else:
                        print("âŒ æ“ä½œå·²å–æ¶ˆ")
                    input("\næŒ‰å›è½¦é”®ç»§ç»­...")
                
                elif choice == '5':
                    print("\nâš ï¸  å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰æ—¥å¿—")
                    confirm = input("ç¡®è®¤å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰æ—¥å¿—ï¼Ÿè¿™å°†å¿½ç•¥å¤„ç†çŠ¶æ€é‡æ–°å¤„ç† (y/N): ").strip().lower()
                    if confirm == 'y':
                        print("\nğŸ”„ å¼€å§‹å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰æ—¥å¿—...")
                        # ä¸´æ—¶æ¸…ç©ºçŠ¶æ€ä»¥å¼ºåˆ¶é‡å¤„ç†
                        backup_state = self.processed_state.copy()
                        self.processed_state = {'processed_files': {}, 'last_update': None, 'total_processed_records': 0, 'processing_history': []}
                        
                        result = self.process_all_unprocessed_logs()
                        
                        # å¦‚æœå¤±è´¥ï¼Œæ¢å¤çŠ¶æ€
                        if not result['success']:
                            self.processed_state = backup_state
                        
                        self._print_process_result(result, "å¼ºåˆ¶é‡æ–°å¤„ç†")
                    else:
                        print("âŒ æ“ä½œå·²å–æ¶ˆ")
                    input("\næŒ‰å›è½¦é”®ç»§ç»­...")
                
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 0-5")
                    input("æŒ‰å›è½¦é”®ç»§ç»­...")
                    
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
                break
            except Exception as e:
                print(f"\nâŒ æ“ä½œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                input("æŒ‰å›è½¦é”®ç»§ç»­...")
    
    def _print_process_result(self, result: Dict[str, Any], operation_name: str):
        """æ‰“å°å¤„ç†ç»“æœ"""
        if result['success']:
            print(f"âœ… {operation_name}æˆåŠŸ!")
            print(f"   å¤„ç†æ—¥æœŸ: {result.get('processed_dates', 0)} ä¸ª")
            print(f"   æ€»è®°å½•æ•°: {result.get('total_records', 0):,} æ¡")
            print(f"   è€—æ—¶: {result.get('duration', 0):.2f} ç§’")
        else:
            print(f"âŒ {operation_name}å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            errors = result.get('errors', [])
            if errors:
                print("   è¯¦ç»†é”™è¯¯:")
                for i, error in enumerate(errors[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                    print(f"     {i}. {error}")
                if len(errors) > 5:
                    print(f"     ... è¿˜æœ‰ {len(errors) - 5} ä¸ªé”™è¯¯")
    
    def _print_single_date_result(self, result: Dict[str, Any]):
        """æ‰“å°å•ä¸ªæ—¥æœŸçš„å¤„ç†ç»“æœ"""
        if result['success']:
            print(f"âœ… æ—¥å¿—å¤„ç†æˆåŠŸ!")
            print(f"   æ—¥æœŸ: {result['date']}")
            print(f"   å¤„ç†æ–‡ä»¶: {result['processed_files']} ä¸ª")
            print(f"   æ€»è®°å½•æ•°: {result['total_records']:,} æ¡")
            print(f"   è€—æ—¶: {result['duration']:.2f} ç§’")
        else:
            print(f"âŒ æ—¥å¿—å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            errors = result.get('errors', [])
            if errors:
                print("   è¯¦ç»†é”™è¯¯:")
                for i, error in enumerate(errors, 1):
                    print(f"     {i}. {error}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='æ¨¡å—åŒ–Nginxæ—¥å¿—å¤„ç†å™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python nginx_processor_modular.py                             # äº¤äº’å¼èœå• (æ¨è)
  python nginx_processor_modular.py process --date 20250422     # å¤„ç†æŒ‡å®šæ—¥æœŸ
  python nginx_processor_modular.py process --date 20250422 --force  # å¼ºåˆ¶é‡æ–°å¤„ç†
  python nginx_processor_modular.py process-all                 # å¤„ç†æ‰€æœ‰æœªå¤„ç†æ—¥å¿—
  python nginx_processor_modular.py status                      # æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
  python nginx_processor_modular.py clear-all                   # æ¸…ç©ºæ‰€æœ‰æ•°æ®
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # processå‘½ä»¤
    process_parser = subparsers.add_parser('process', help='å¤„ç†æŒ‡å®šæ—¥æœŸçš„æ—¥å¿—')
    process_parser.add_argument('--date', required=True, help='æ—¥æœŸ (YYYYMMDDæ ¼å¼)')
    process_parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°å¤„ç†')
    
    # å…¶ä»–å‘½ä»¤
    subparsers.add_parser('process-all', help='å¤„ç†æ‰€æœ‰æœªå¤„ç†çš„æ—¥å¿—')
    subparsers.add_parser('status', help='æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€')
    subparsers.add_parser('clear-all', help='æ¸…ç©ºæ‰€æœ‰æ•°æ® (å¼€å‘ç¯å¢ƒä½¿ç”¨)')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = NginxProcessorModular()
    
    # å¦‚æœæ²¡æœ‰å‚æ•°ï¼Œæ˜¾ç¤ºäº¤äº’å¼èœå•
    if not args.command:
        processor.interactive_menu()
        return
    
    # æ‰§è¡Œå¯¹åº”å‘½ä»¤
    if args.command == 'process':
        # éªŒè¯æ—¥æœŸæ ¼å¼
        try:
            datetime.strptime(args.date, '%Y%m%d')
        except ValueError:
            print("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨YYYYMMDDæ ¼å¼ï¼Œä¾‹å¦‚: 20250422")
            return
        
        result = processor.process_specific_date(args.date, args.force)
        processor._print_single_date_result(result)
    
    elif args.command == 'process-all':
        result = processor.process_all_unprocessed_logs()
        processor._print_process_result(result, "æ‰¹é‡å¤„ç†")
    
    elif args.command == 'status':
        processor.show_status()
    
    elif args.command == 'clear-all':
        confirm = input("âš ï¸  ç¡®è®¤æ¸…ç©ºæ‰€æœ‰æ•°æ®ï¼Ÿè¿™å°†åˆ é™¤æ•°æ®åº“ä¸­çš„æ‰€æœ‰æ—¥å¿—æ•°æ® (y/N): ")
        if confirm.lower() == 'y':
            second_confirm = input("å†æ¬¡ç¡®è®¤ï¼è¿™å°†ä¸å¯æ¢å¤åœ°åˆ é™¤æ‰€æœ‰æ•°æ® (è¾“å…¥ 'DELETE' ç¡®è®¤): ").strip()
            if second_confirm == 'DELETE':
                processor.clear_all_data()
            else:
                print("âŒ ç¡®è®¤å¤±è´¥ï¼Œæ“ä½œå·²å–æ¶ˆ")
        else:
            print("âŒ æ“ä½œå·²å–æ¶ˆ")

if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    main()