#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŠ¨æ€æ‰¹å¤§å°ä¼˜åŒ–å™¨
æ ¹æ®ç³»ç»Ÿæ€§èƒ½å’Œæ•°æ®é‡åŠ¨æ€è°ƒæ•´æ‰¹å¤„ç†å¤§å°ä»¥è·å¾—æœ€ä½³æ€§èƒ½
"""

import time
import logging
from typing import Dict, List, Tuple, Optional
from statistics import mean, median
from collections import deque

# å°è¯•å¯¼å…¥psutil
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    psutil = None


class DynamicBatchOptimizer:
    """åŠ¨æ€æ‰¹å¤§å°ä¼˜åŒ–å™¨"""

    def __init__(self,
                 initial_batch_size: int = 25000,
                 min_batch_size: int = 1000,
                 max_batch_size: int = 100000,
                 memory_threshold: float = 0.8,
                 cpu_threshold: float = 0.9,
                 optimization_window: int = 10):
        """
        åˆå§‹åŒ–åŠ¨æ€æ‰¹å¤§å°ä¼˜åŒ–å™¨

        Args:
            initial_batch_size: åˆå§‹æ‰¹å¤§å°
            min_batch_size: æœ€å°æ‰¹å¤§å°
            max_batch_size: æœ€å¤§æ‰¹å¤§å°
            memory_threshold: å†…å­˜ä½¿ç”¨é˜ˆå€¼ (0-1)
            cpu_threshold: CPUä½¿ç”¨é˜ˆå€¼ (0-1)
            optimization_window: æ€§èƒ½ç»Ÿè®¡çª—å£å¤§å°
        """
        self.current_batch_size = initial_batch_size
        self.min_batch_size = min_batch_size
        self.max_batch_size = max_batch_size
        self.memory_threshold = memory_threshold
        self.cpu_threshold = cpu_threshold
        self.optimization_window = optimization_window

        # æ€§èƒ½å†å²è®°å½•
        self.performance_history = deque(maxlen=optimization_window)
        self.batch_history = deque(maxlen=optimization_window)

        # ç³»ç»Ÿç›‘æ§
        self.memory_history = deque(maxlen=20)
        self.cpu_history = deque(maxlen=20)

        # ä¼˜åŒ–çŠ¶æ€
        self.last_optimization_time = time.time()
        self.optimization_interval = 30  # 30ç§’ä¼˜åŒ–ä¸€æ¬¡
        self.consecutive_bad_performance = 0
        self.consecutive_good_performance = 0

        self.logger = logging.getLogger(__name__)

    def record_batch_performance(self,
                                batch_size: int,
                                records_count: int,
                                duration: float,
                                memory_used_mb: Optional[float] = None) -> None:
        """
        è®°å½•æ‰¹å¤„ç†æ€§èƒ½æ•°æ®

        Args:
            batch_size: æ‰¹å¤§å°
            records_count: å¤„ç†è®°å½•æ•°
            duration: å¤„ç†è€—æ—¶(ç§’)
            memory_used_mb: å†…å­˜ä½¿ç”¨é‡(MB)
        """
        if duration > 0:
            throughput = records_count / duration  # è®°å½•/ç§’

            performance_data = {
                'batch_size': batch_size,
                'records_count': records_count,
                'duration': duration,
                'throughput': throughput,
                'memory_used_mb': memory_used_mb,
                'timestamp': time.time()
            }

            self.performance_history.append(performance_data)
            self.batch_history.append(batch_size)

            # è®°å½•ç³»ç»Ÿèµ„æºä½¿ç”¨
            self._record_system_metrics()

    def _record_system_metrics(self) -> None:
        """è®°å½•ç³»ç»ŸæŒ‡æ ‡"""
        if not PSUTIL_AVAILABLE:
            return

        try:
            # å†…å­˜ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            self.memory_history.append(memory.percent / 100.0)

            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=0.1)
            self.cpu_history.append(cpu_percent / 100.0)

        except Exception as e:
            self.logger.warning(f"æ— æ³•è·å–ç³»ç»ŸæŒ‡æ ‡: {e}")

    def should_optimize(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿›è¡Œä¼˜åŒ–"""
        current_time = time.time()

        # æ—¶é—´é—´éš”æ£€æŸ¥
        if current_time - self.last_optimization_time < self.optimization_interval:
            return False

        # æ€§èƒ½æ•°æ®å……è¶³æ£€æŸ¥
        if len(self.performance_history) < 3:
            return False

        return True

    def optimize_batch_size(self) -> Tuple[int, str]:
        """
        ä¼˜åŒ–æ‰¹å¤§å°

        Returns:
            Tuple[æ–°çš„æ‰¹å¤§å°, ä¼˜åŒ–åŸå› ]
        """
        if not self.should_optimize():
            return self.current_batch_size, "æ— éœ€ä¼˜åŒ–"

        # åˆ†ææ€§èƒ½è¶‹åŠ¿
        optimization_reason = self._analyze_performance_trend()
        new_batch_size = self._calculate_optimal_batch_size()

        # åº”ç”¨çº¦æŸ
        new_batch_size = max(self.min_batch_size, min(self.max_batch_size, new_batch_size))

        if new_batch_size != self.current_batch_size:
            self.logger.info(f"æ‰¹å¤§å°ä¼˜åŒ–: {self.current_batch_size} -> {new_batch_size}, åŸå› : {optimization_reason}")
            self.current_batch_size = new_batch_size

        self.last_optimization_time = time.time()
        return self.current_batch_size, optimization_reason

    def _analyze_performance_trend(self) -> str:
        """åˆ†ææ€§èƒ½è¶‹åŠ¿"""
        if len(self.performance_history) < 3:
            return "æ•°æ®ä¸è¶³"

        recent_data = list(self.performance_history)[-3:]
        throughputs = [data['throughput'] for data in recent_data]

        # æ£€æŸ¥ç³»ç»Ÿèµ„æºå‹åŠ›
        if self._is_system_under_pressure():
            self.consecutive_bad_performance += 1
            self.consecutive_good_performance = 0
            return "ç³»ç»Ÿèµ„æºå‹åŠ›è¿‡å¤§"

        # æ£€æŸ¥æ€§èƒ½è¶‹åŠ¿
        if len(throughputs) >= 2:
            trend = throughputs[-1] - throughputs[0]

            if trend < -100:  # æ€§èƒ½ä¸‹é™æ˜æ˜¾
                self.consecutive_bad_performance += 1
                self.consecutive_good_performance = 0
                return "æ€§èƒ½ä¸‹é™è¶‹åŠ¿"
            elif trend > 100:  # æ€§èƒ½æå‡æ˜æ˜¾
                self.consecutive_good_performance += 1
                self.consecutive_bad_performance = 0
                return "æ€§èƒ½æå‡è¶‹åŠ¿"

        # é‡ç½®è®¡æ•°å™¨
        self.consecutive_bad_performance = max(0, self.consecutive_bad_performance - 1)
        self.consecutive_good_performance = max(0, self.consecutive_good_performance - 1)

        return "æ€§èƒ½ç¨³å®š"

    def _is_system_under_pressure(self) -> bool:
        """æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å¤„äºå‹åŠ›çŠ¶æ€"""
        if not self.memory_history or not self.cpu_history:
            return False

        # æ£€æŸ¥å†…å­˜å‹åŠ›
        recent_memory = list(self.memory_history)[-5:] if len(self.memory_history) >= 5 else list(self.memory_history)
        avg_memory = mean(recent_memory)

        # æ£€æŸ¥CPUå‹åŠ›
        recent_cpu = list(self.cpu_history)[-5:] if len(self.cpu_history) >= 5 else list(self.cpu_history)
        avg_cpu = mean(recent_cpu)

        return avg_memory > self.memory_threshold or avg_cpu > self.cpu_threshold

    def _calculate_optimal_batch_size(self) -> int:
        """è®¡ç®—æœ€ä¼˜æ‰¹å¤§å°"""
        recent_data = list(self.performance_history)[-5:]

        if len(recent_data) < 2:
            return self.current_batch_size

        # ç³»ç»Ÿå‹åŠ›æ£€æŸ¥
        if self._is_system_under_pressure():
            # ç³»ç»Ÿå‹åŠ›å¤§ï¼Œå‡å°‘æ‰¹å¤§å°
            return int(self.current_batch_size * 0.8)

        # æ€§èƒ½è¶‹åŠ¿åˆ†æ
        if self.consecutive_bad_performance >= 2:
            # è¿ç»­æ€§èƒ½ä¸ä½³ï¼Œå‡å°‘æ‰¹å¤§å°
            return int(self.current_batch_size * 0.7)
        elif self.consecutive_good_performance >= 3:
            # è¿ç»­æ€§èƒ½è‰¯å¥½ï¼Œå°è¯•å¢åŠ æ‰¹å¤§å°
            return int(self.current_batch_size * 1.3)

        # åŸºäºååé‡çš„ä¼˜åŒ–
        throughputs = [data['throughput'] for data in recent_data]
        batch_sizes = [data['batch_size'] for data in recent_data]

        # å¯»æ‰¾ååé‡æœ€é«˜çš„æ‰¹å¤§å°
        best_idx = throughputs.index(max(throughputs))
        best_batch_size = batch_sizes[best_idx]

        # æ¸è¿›å¼è°ƒæ•´
        if best_batch_size > self.current_batch_size:
            return int(self.current_batch_size * 1.2)
        elif best_batch_size < self.current_batch_size:
            return int(self.current_batch_size * 0.9)

        return self.current_batch_size

    def get_current_batch_size(self) -> int:
        """è·å–å½“å‰æ‰¹å¤§å°"""
        return self.current_batch_size

    def get_performance_stats(self) -> Dict:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        if not self.performance_history:
            return {}

        recent_data = list(self.performance_history)
        throughputs = [data['throughput'] for data in recent_data]

        stats = {
            'current_batch_size': self.current_batch_size,
            'total_measurements': len(recent_data),
            'avg_throughput': mean(throughputs) if throughputs else 0,
            'median_throughput': median(throughputs) if throughputs else 0,
            'max_throughput': max(throughputs) if throughputs else 0,
            'min_throughput': min(throughputs) if throughputs else 0,
            'consecutive_bad_performance': self.consecutive_bad_performance,
            'consecutive_good_performance': self.consecutive_good_performance
        }

        # ç³»ç»Ÿèµ„æºç»Ÿè®¡
        if self.memory_history:
            stats['avg_memory_usage'] = mean(self.memory_history)
            stats['max_memory_usage'] = max(self.memory_history)

        if self.cpu_history:
            stats['avg_cpu_usage'] = mean(self.cpu_history)
            stats['max_cpu_usage'] = max(self.cpu_history)

        return stats

    def reset_optimizer(self) -> None:
        """é‡ç½®ä¼˜åŒ–å™¨çŠ¶æ€"""
        self.performance_history.clear()
        self.batch_history.clear()
        self.memory_history.clear()
        self.cpu_history.clear()
        self.consecutive_bad_performance = 0
        self.consecutive_good_performance = 0
        self.last_optimization_time = time.time()

        self.logger.info("åŠ¨æ€æ‰¹å¤§å°ä¼˜åŒ–å™¨å·²é‡ç½®")

    def force_batch_size(self, batch_size: int) -> None:
        """å¼ºåˆ¶è®¾ç½®æ‰¹å¤§å°ï¼ˆè·³è¿‡ä¼˜åŒ–ï¼‰"""
        self.current_batch_size = max(self.min_batch_size, min(self.max_batch_size, batch_size))
        self.logger.info(f"å¼ºåˆ¶è®¾ç½®æ‰¹å¤§å°ä¸º: {self.current_batch_size}")


class BatchSizeRecommendation:
    """æ‰¹å¤§å°æ¨èå™¨"""

    @staticmethod
    def recommend_initial_batch_size(available_memory_gb: float,
                                   record_size_kb: float = 1.0,
                                   target_memory_usage: float = 0.3) -> int:
        """
        æ ¹æ®ç³»ç»Ÿé…ç½®æ¨èåˆå§‹æ‰¹å¤§å°

        Args:
            available_memory_gb: å¯ç”¨å†…å­˜(GB)
            record_size_kb: å•æ¡è®°å½•å¤§å°(KB)
            target_memory_usage: ç›®æ ‡å†…å­˜ä½¿ç”¨ç‡

        Returns:
            æ¨èçš„åˆå§‹æ‰¹å¤§å°
        """
        # è®¡ç®—å¯ç”¨äºæ‰¹å¤„ç†çš„å†…å­˜
        batch_memory_mb = available_memory_gb * 1024 * target_memory_usage

        # è®¡ç®—å¯å®¹çº³çš„è®°å½•æ•°
        records_per_mb = 1024 / record_size_kb
        max_records = int(batch_memory_mb * records_per_mb)

        # åº”ç”¨åˆç†èŒƒå›´
        recommended_size = max(1000, min(100000, max_records))

        # è°ƒæ•´åˆ°å¸¸ç”¨çš„æ‰¹å¤§å°
        if recommended_size < 5000:
            return 5000
        elif recommended_size < 15000:
            return 10000
        elif recommended_size < 35000:
            return 25000
        elif recommended_size < 75000:
            return 50000
        else:
            return 100000

    @staticmethod
    def get_system_info() -> Dict:
        """è·å–ç³»ç»Ÿä¿¡æ¯ç”¨äºæ‰¹å¤§å°æ¨è"""
        if not PSUTIL_AVAILABLE:
            return {'error': 'psutilæ¨¡å—æœªå®‰è£…ï¼Œæ— æ³•è·å–ç³»ç»Ÿä¿¡æ¯'}

        try:
            memory = psutil.virtual_memory()
            cpu_count = psutil.cpu_count()

            return {
                'total_memory_gb': memory.total / (1024**3),
                'available_memory_gb': memory.available / (1024**3),
                'memory_usage_percent': memory.percent,
                'cpu_count': cpu_count,
                'cpu_usage_percent': psutil.cpu_percent(interval=1)
            }
        except Exception as e:
            return {'error': str(e)}


def main():
    """æ¼”ç¤ºåŠ¨æ€æ‰¹å¤§å°ä¼˜åŒ–å™¨çš„ä½¿ç”¨"""
    print("ğŸ”§ åŠ¨æ€æ‰¹å¤§å°ä¼˜åŒ–å™¨æ¼”ç¤º")
    print("=" * 60)

    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = DynamicBatchOptimizer(
        initial_batch_size=25000,
        min_batch_size=5000,
        max_batch_size=100000
    )

    # è·å–ç³»ç»Ÿä¿¡æ¯
    system_info = BatchSizeRecommendation.get_system_info()
    print("ğŸ“Š ç³»ç»Ÿä¿¡æ¯:")
    for key, value in system_info.items():
        if isinstance(value, float):
            print(f"   {key}: {value:.2f}")
        else:
            print(f"   {key}: {value}")

    # æ¨èåˆå§‹æ‰¹å¤§å°
    if 'available_memory_gb' in system_info:
        recommended = BatchSizeRecommendation.recommend_initial_batch_size(
            system_info['available_memory_gb']
        )
        print(f"\nğŸ’¡ æ¨èåˆå§‹æ‰¹å¤§å°: {recommended:,}")

    # æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®
    print(f"\nğŸš€ å½“å‰æ‰¹å¤§å°: {optimizer.get_current_batch_size():,}")

    # æ¨¡æ‹Ÿå‡ æ¬¡æ€§èƒ½è®°å½•
    import random
    for i in range(5):
        batch_size = optimizer.get_current_batch_size()
        records = batch_size
        duration = random.uniform(1.0, 3.0)  # æ¨¡æ‹Ÿ1-3ç§’å¤„ç†æ—¶é—´
        memory_used = random.uniform(100, 500)  # æ¨¡æ‹Ÿå†…å­˜ä½¿ç”¨

        optimizer.record_batch_performance(batch_size, records, duration, memory_used)

        # å°è¯•ä¼˜åŒ–
        new_size, reason = optimizer.optimize_batch_size()
        print(f"è½®æ¬¡ {i+1}: æ‰¹å¤§å°={new_size:,}, åŸå› ={reason}")

    # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
    stats = optimizer.get_performance_stats()
    print(f"\nğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
    for key, value in stats.items():
        if isinstance(value, float):
            print(f"   {key}: {value:.2f}")
        else:
            print(f"   {key}: {value}")


if __name__ == "__main__":
    main()