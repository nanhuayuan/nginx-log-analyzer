#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DWDå±‚æ•°æ®å†™å…¥å™¨ - æ”¯æŒæ–°è¡¨ç»“æ„
DWD Writer - Supports new table structure

è´Ÿè´£å°†æ˜ å°„åçš„æ•°æ®å†™å…¥dwd_nginx_enriched_v2è¡¨
"""

import logging
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple
import clickhouse_connect
from clickhouse_connect.driver.exceptions import ClickHouseError

class DWDWriter:
    """DWDå±‚æ•°æ®å†™å…¥å™¨"""
    
    def __init__(self, host: str = 'localhost', port: int = 8123, 
                 database: str = 'nginx_analytics', username: str = 'analytics_user', 
                 password: str = 'analytics_password_change_in_prod'):
        """
        åˆå§‹åŒ–DWDå†™å…¥å™¨
        
        Args:
            host: ClickHouseä¸»æœº
            port: ClickHouseç«¯å£
            database: æ•°æ®åº“å
            username: ç”¨æˆ·å
            password: å¯†ç 
        """
        self.config = {
            'host': host,
            'port': port,
            'database': database,
            'username': username,
            'password': password
        }
        
        self.client = None
        self.logger = logging.getLogger(__name__)
        
        # DWDè¡¨å­—æ®µåˆ—è¡¨ï¼ˆæ’é™¤è‡ªåŠ¨ç”Ÿæˆå’ŒMATERIALIZEDå­—æ®µï¼‰
        # æ’é™¤ï¼šid, ods_id (è‡ªåŠ¨ç”Ÿæˆ), date, hour, minute, second, date_hour, date_hour_minute, 
        #       weekday, is_weekend, time_period (MATERIALIZED), created_at, updated_at (DEFAULT)
        self.dwd_fields = [
            # åŸºç¡€å­—æ®µ
            'log_time', 'date_partition', 'hour_partition', 'minute_partition', 'second_partition',
            'client_ip', 'client_port', 'xff_ip', 'server_name', 'request_method',
            'request_uri', 'request_uri_normalized', 'request_full_uri', 'query_parameters',
            'http_protocol_version', 'response_status_code', 'response_body_size', 'response_body_size_kb',
            'total_bytes_sent', 'total_bytes_sent_kb', 'total_request_duration',
            
            # æ€§èƒ½å­—æ®µ
            'upstream_connect_time', 'upstream_header_time', 'upstream_response_time',
            'backend_connect_phase', 'backend_process_phase', 'backend_transfer_phase',
            'nginx_transfer_phase', 'backend_total_phase', 'network_phase', 'processing_phase', 
            'transfer_phase', 'response_transfer_speed', 'total_transfer_speed', 'nginx_transfer_speed',
            'backend_efficiency', 'network_overhead', 'transfer_ratio', 'connection_cost_ratio',
            'processing_efficiency_index',
            
            # ä¸šåŠ¡å­—æ®µ
            'platform', 'platform_version', 'app_version', 'device_type', 'browser_type',
            'os_type', 'os_version', 'sdk_type', 'sdk_version', 'bot_type',
            'entry_source', 'referer_domain', 'search_engine', 'social_media',
            'api_category', 'api_module', 'api_version', 'business_domain', 'access_type',
            'client_category', 'application_name', 'service_name', 'trace_id', 'business_sign',
            'cluster_node', 'upstream_server', 'connection_requests', 'cache_status',
            'referer_url', 'user_agent_string',
            
            # æ—¥å¿—æºä¿¡æ¯
            'log_source_file',
            
            # çŠ¶æ€å­—æ®µ
            'is_success', 'is_business_success', 'is_slow', 'is_very_slow', 'is_error',
            'is_client_error', 'is_server_error', 'has_anomaly', 'anomaly_type',
            'user_experience_level', 'apdex_classification', 'api_importance', 'business_value_score',
            'data_quality_score', 'parsing_errors',
            
            # åœ°ç†å’Œé£é™©ä¿¡æ¯
            'client_region', 'client_isp', 'ip_risk_level', 'is_internal_ip'
        ]
        
        # å†™å…¥ç»Ÿè®¡
        self.stats = {
            'total_records': 0,
            'success_records': 0,
            'failed_records': 0,
            'batch_count': 0
        }
    
    def connect(self) -> bool:
        """è¿æ¥ClickHouse"""
        try:
            self.client = clickhouse_connect.get_client(**self.config)
            self.client.ping()
            self.logger.info(f"æˆåŠŸè¿æ¥åˆ°ClickHouse: {self.config['host']}:{self.config['port']}")
            return True
        except Exception as e:
            self.logger.error(f"è¿æ¥ClickHouseå¤±è´¥: {e}")
            self.client = None
            return False
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if self.client:
            try:
                self.client.close()
                self.logger.info("ClickHouseè¿æ¥å·²å…³é—­")
            except Exception as e:
                self.logger.error(f"å…³é—­è¿æ¥å¤±è´¥: {e}")
            finally:
                self.client = None
    
    def write_batch(self, records: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ‰¹é‡å†™å…¥æ•°æ®åˆ°DWDè¡¨
        
        Args:
            records: è¦å†™å…¥çš„è®°å½•åˆ—è¡¨
            
        Returns:
            å†™å…¥ç»“æœå­—å…¸
        """
        if not self.client:
            if not self.connect():
                return self._create_error_result("æ•°æ®åº“è¿æ¥å¤±è´¥")
        
        if not records:
            return self._create_success_result(0, "æ²¡æœ‰æ•°æ®éœ€è¦å†™å…¥")
        
        try:
            self.stats['batch_count'] += 1
            self.logger.info(f"å¼€å§‹å†™å…¥æ‰¹æ¬¡ {self.stats['batch_count']}: {len(records)} æ¡è®°å½•")
            
            # å‡†å¤‡æ•°æ®
            prepared_data = self._prepare_batch_data(records)
            
            # æ‰§è¡Œæ’å…¥ï¼ˆæ’é™¤è‡ªåŠ¨ç”Ÿæˆçš„idå’Œods_idå­—æ®µï¼‰
            table_name = f"{self.config['database']}.dwd_nginx_enriched_v2"
            
            # æ„å»ºINSERTè¯­å¥ï¼Œæ˜ç¡®æŒ‡å®šå­—æ®µåˆ—è¡¨
            column_list = ', '.join(self.dwd_fields)
            insert_sql = f"INSERT INTO {table_name} ({column_list}) VALUES"
            
            result = self.client.insert(
                table=table_name,
                data=prepared_data,
                column_names=self.dwd_fields
            )
            
            # æ›´æ–°ç»Ÿè®¡
            success_count = len(records)
            self.stats['total_records'] += success_count
            self.stats['success_records'] += success_count
            
            self.logger.info(f"æ‰¹æ¬¡å†™å…¥æˆåŠŸ: {success_count} æ¡è®°å½•")
            
            return self._create_success_result(success_count, f"æˆåŠŸå†™å…¥ {success_count} æ¡è®°å½•")
            
        except ClickHouseError as e:
            self.logger.error(f"ClickHouseå†™å…¥é”™è¯¯: {e}")
            self.stats['failed_records'] += len(records)
            return self._create_error_result(f"ClickHouseé”™è¯¯: {str(e)}")
            
        except Exception as e:
            self.logger.error(f"å†™å…¥å¼‚å¸¸: {e}")
            self.stats['failed_records'] += len(records)
            return self._create_error_result(f"æœªçŸ¥é”™è¯¯: {str(e)}")
    
    def write_single(self, record: Dict[str, Any]) -> Dict[str, Any]:
        """
        å†™å…¥å•æ¡è®°å½•
        
        Args:
            record: è¦å†™å…¥çš„è®°å½•
            
        Returns:
            å†™å…¥ç»“æœå­—å…¸
        """
        return self.write_batch([record])
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–å†™å…¥ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.stats.copy()
        if stats['total_records'] > 0:
            stats['success_rate'] = (stats['success_records'] / stats['total_records']) * 100
        else:
            stats['success_rate'] = 0.0
        return stats
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            'total_records': 0,
            'success_records': 0,
            'failed_records': 0,
            'batch_count': 0
        }
    
    def test_connection(self) -> bool:
        """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
        try:
            if not self.client:
                if not self.connect():
                    return False
            
            # æ‰§è¡Œç®€å•æŸ¥è¯¢æµ‹è¯•è¿æ¥
            result = self.client.query("SELECT 1")
            return True
            
        except Exception as e:
            self.logger.error(f"è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def validate_table_structure(self) -> Dict[str, Any]:
        """éªŒè¯ç›®æ ‡è¡¨ç»“æ„"""
        try:
            if not self.client:
                if not self.connect():
                    return {'valid': False, 'error': 'æ— æ³•è¿æ¥æ•°æ®åº“'}
            
            # æŸ¥è¯¢è¡¨ç»“æ„
            table_name = f"{self.config['database']}.dwd_nginx_enriched_v2"
            result = self.client.query(f"DESCRIBE TABLE {table_name}")
            
            # è·å–å®é™…å­—æ®µåˆ—è¡¨ï¼ˆæ’é™¤è‡ªåŠ¨ç”Ÿæˆã€MATERIALIZEDå’ŒDEFAULTå­—æ®µï¼‰
            excluded_fields = ['id', 'ods_id', 'date', 'hour', 'minute', 'second', 
                             'date_hour', 'date_hour_minute', 'weekday', 'is_weekend', 
                             'time_period', 'created_at', 'updated_at']
            actual_fields = [row[0] for row in result.result_rows if row[0] not in excluded_fields]
            
            # æ¯”è¾ƒå­—æ®µ
            missing_fields = set(self.dwd_fields) - set(actual_fields)
            extra_fields = set(actual_fields) - set(self.dwd_fields)
            
            validation_result = {
                'valid': len(missing_fields) == 0,
                'total_fields': len(actual_fields),
                'expected_fields': len(self.dwd_fields),
                'missing_fields': list(missing_fields),
                'extra_fields': list(extra_fields)
            }
            
            if validation_result['valid']:
                self.logger.info(f"è¡¨ç»“æ„éªŒè¯é€šè¿‡: {validation_result['total_fields']} ä¸ªå­—æ®µ")
            else:
                self.logger.warning(f"è¡¨ç»“æ„éªŒè¯å¤±è´¥: ç¼ºå¤± {len(missing_fields)} ä¸ªå­—æ®µ")
                
            return validation_result
            
        except Exception as e:
            self.logger.error(f"è¡¨ç»“æ„éªŒè¯å¤±è´¥: {e}")
            return {'valid': False, 'error': str(e)}
    
    # === ç§æœ‰æ–¹æ³• ===
    
    def _prepare_batch_data(self, records: List[Dict[str, Any]]) -> List[List[Any]]:
        """å‡†å¤‡æ‰¹é‡å†™å…¥æ•°æ®"""
        prepared_data = []
        
        for record in records:
            row_data = []
            
            for field_name in self.dwd_fields:
                value = record.get(field_name)
                
                # å¤„ç†ä¸åŒç±»å‹çš„å­—æ®µ
                processed_value = self._process_field_value(field_name, value)
                row_data.append(processed_value)
            
            prepared_data.append(row_data)
        
        return prepared_data
    
    def _process_field_value(self, field_name: str, value: Any) -> Any:
        """å¤„ç†å­—æ®µå€¼ï¼Œç¡®ä¿ç±»å‹åŒ¹é…"""
        # å¤„ç†Noneå€¼
        if value is None:
            return self._get_default_value(field_name)
        
        # æ—¶é—´ç±»å‹å­—æ®µ
        if field_name in ['log_time', 'created_at', 'updated_at']:
            if isinstance(value, datetime):
                return value
            return datetime.now()
        
        # æ—¥æœŸç±»å‹å­—æ®µ  
        if field_name in ['date_partition']:
            if hasattr(value, 'date'):
                return value.date()
            return datetime.now().date()
        
        # æ•´æ•°å­—æ®µ
        if field_name in ['hour_partition', 'minute_partition', 'second_partition', 
                         'client_port', 'response_body_size', 'total_bytes_sent',
                         'connection_requests', 'business_value_score']:
            return int(value) if value is not None else 0
        
        # æµ®ç‚¹æ•°å­—æ®µ
        if field_name in ['response_body_size_kb', 'total_bytes_sent_kb', 'total_request_duration',
                         'upstream_connect_time', 'upstream_header_time', 'upstream_response_time',
                         'backend_connect_phase', 'backend_process_phase', 'backend_transfer_phase',
                         'nginx_transfer_phase', 'backend_total_phase', 'network_phase',
                         'processing_phase', 'transfer_phase', 'response_transfer_speed',
                         'total_transfer_speed', 'nginx_transfer_speed', 'backend_efficiency',
                         'network_overhead', 'transfer_ratio', 'connection_cost_ratio',
                         'processing_efficiency_index', 'data_quality_score']:
            return float(value) if value is not None else 0.0
        
        # å¸ƒå°”å­—æ®µ
        if field_name in ['is_success', 'is_business_success', 'is_slow', 'is_very_slow',
                         'is_error', 'is_client_error', 'is_server_error', 'has_anomaly',
                         'is_internal_ip']:
            return bool(value) if value is not None else False
        
        # æ•°ç»„å­—æ®µ
        if field_name == 'parsing_errors':
            if isinstance(value, list):
                return value
            return []
        
        # å­—ç¬¦ä¸²å­—æ®µï¼ˆé»˜è®¤ï¼‰
        return str(value) if value is not None else ''
    
    def _get_default_value(self, field_name: str) -> Any:
        """è·å–å­—æ®µçš„é»˜è®¤å€¼"""
        # æ—¶é—´ç±»å‹
        if field_name in ['log_time']:
            return datetime.now()
        
        # æ—¥æœŸç±»å‹
        if field_name in ['date_partition']:
            return datetime.now().date()
        
        # æ•´æ•°ç±»å‹
        if field_name in ['hour_partition', 'minute_partition', 'second_partition', 
                         'client_port', 'response_body_size', 'total_bytes_sent',
                         'connection_requests', 'business_value_score']:
            return 0
        
        # æµ®ç‚¹æ•°ç±»å‹
        if field_name in ['response_body_size_kb', 'total_bytes_sent_kb', 'total_request_duration',
                         'upstream_connect_time', 'upstream_header_time', 'upstream_response_time'] + \
                        [f for f in self.dwd_fields if 'phase' in f or 'speed' in f or 
                         'efficiency' in f or 'overhead' in f or 'ratio' in f]:
            return 0.0
        
        # å¸ƒå°”ç±»å‹
        if field_name.startswith('is_') or field_name.startswith('has_'):
            return False
        
        # æ•°ç»„ç±»å‹
        if field_name == 'parsing_errors':
            return []
        
        # å­—ç¬¦ä¸²ç±»å‹ï¼ˆé»˜è®¤ï¼‰
        return ''
    
    def _create_success_result(self, count: int, message: str) -> Dict[str, Any]:
        """åˆ›å»ºæˆåŠŸç»“æœ"""
        return {
            'success': True,
            'count': count,
            'message': message,
            'timestamp': datetime.now()
        }
    
    def _create_error_result(self, error: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return {
            'success': False,
            'count': 0,
            'error': error,
            'timestamp': datetime.now()
        }


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    writer = DWDWriter()
    
    # æµ‹è¯•è¿æ¥
    print("ğŸ”— æµ‹è¯•æ•°æ®åº“è¿æ¥...")
    if writer.test_connection():
        print("âœ… è¿æ¥æˆåŠŸ")
        
        # éªŒè¯è¡¨ç»“æ„
        print("\nğŸ“‹ éªŒè¯è¡¨ç»“æ„...")
        validation = writer.validate_table_structure()
        print(f"éªŒè¯ç»“æœ: {validation}")
        
        if validation.get('valid'):
            print("âœ… è¡¨ç»“æ„éªŒè¯é€šè¿‡")
        else:
            print("âŒ è¡¨ç»“æ„éªŒè¯å¤±è´¥")
            if validation.get('missing_fields'):
                print(f"ç¼ºå¤±å­—æ®µ: {validation['missing_fields'][:10]}...")  # åªæ˜¾ç¤ºå‰10ä¸ª
    else:
        print("âŒ è¿æ¥å¤±è´¥")
    
    # å…³é—­è¿æ¥
    writer.close()