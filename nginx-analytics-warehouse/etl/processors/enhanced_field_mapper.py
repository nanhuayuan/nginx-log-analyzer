#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºå­—æ®µæ˜ å°„å™¨ - é›†æˆå®Œæ•´çš„5%å¾…å®Œå–„åŠŸèƒ½
Enhanced Field Mapper - å®Œæ•´çš„æ•°æ®æ¸…æ´—å¢å¼ºåŠŸèƒ½

æ–°å¢åŠŸèƒ½ï¼š
1. IPåœ°ç†ä½ç½®ç²¾ç¡®å®šä½ (æ”¯æŒGeoIP2åº“å’Œç®€åŒ–ç‰ˆæœ¬)
2. ä¸šåŠ¡åŸŸæ™ºèƒ½åˆ†ç±» (10ä¸ªä¸šåŠ¡åŸŸè‡ªåŠ¨åˆ†ç±»)
3. å®æ—¶å¼‚å¸¸è¡Œä¸ºæ£€æµ‹ (6ç§å¼‚å¸¸ç±»å‹æ£€æµ‹)
4. å¢å¼ºçš„User-Agentè§£æ (8å¤§ç±»ç»†åˆ†è¯†åˆ«)
5. æ™ºèƒ½ç¼“å­˜ä¼˜åŒ– (å¤šçº§ç¼“å­˜æå‡æ€§èƒ½)
"""

import re
import json
import logging
from datetime import datetime, date
from typing import Dict, Any, Optional, Union, List
from urllib.parse import urlparse, parse_qs
from pathlib import Path

# å¯¼å…¥åŸºç¡€å­—æ®µæ˜ å°„å™¨
try:
    from .field_mapper import FieldMapper as BaseFieldMapper
except ImportError:
    import sys
    sys.path.append(str(Path(__file__).parent))
    from field_mapper import FieldMapper as BaseFieldMapper

# å¯é€‰ä¾èµ–å¯¼å…¥
try:
    import geoip2.database
    import geoip2.errors
    GEOIP_AVAILABLE = True
except ImportError:
    GEOIP_AVAILABLE = False

class EnhancedFieldMapper(BaseFieldMapper):
    """å¢å¼ºå­—æ®µæ˜ å°„å™¨ - å®Œæ•´åŠŸèƒ½ç‰ˆæœ¬"""

    def __init__(self, geoip_db_path: str = None):
        """
        åˆå§‹åŒ–å¢å¼ºå­—æ®µæ˜ å°„å™¨

        Args:
            geoip_db_path: GeoIP2æ•°æ®åº“æ–‡ä»¶è·¯å¾„ (å¯é€‰)
        """
        super().__init__()

        # IPåœ°ç†ä½ç½®ç»„ä»¶
        self.geoip_reader = None
        self._init_geoip_database(geoip_db_path)

        # ä¸šåŠ¡åŸŸåˆ†ç±»å™¨
        self.domain_classifier = BusinessDomainClassifier()

        # å¼‚å¸¸æ£€æµ‹å™¨
        self.anomaly_detector = SimpleAnomalyDetector()

        # å¢å¼ºç¼“å­˜
        self.geo_cache = {}
        self.domain_cache = {}
        self.anomaly_cache = {}

        # ç»Ÿè®¡ä¿¡æ¯
        self.enhancement_stats = {
            'geo_lookups': 0,
            'geo_cache_hits': 0,
            'domain_classifications': 0,
            'domain_cache_hits': 0,
            'anomalies_detected': 0,
            'enhancement_errors': 0
        }

        self.logger.info("ğŸš€ å¢å¼ºå­—æ®µæ˜ å°„å™¨åˆå§‹åŒ–å®Œæˆ")
        if self.geoip_reader:
            self.logger.info("âœ… GeoIP2ç²¾ç¡®åœ°ç†ä½ç½®å®šä½å·²å¯ç”¨")
        else:
            self.logger.info("ğŸ“ ä½¿ç”¨ç®€åŒ–åœ°ç†ä½ç½®å®šä½")

    def _init_geoip_database(self, db_path: str = None):
        """åˆå§‹åŒ–GeoIPæ•°æ®åº“"""
        if not GEOIP_AVAILABLE:
            self.logger.info("ğŸ’¡ å®‰è£…geoip2åº“å¯å¯ç”¨ç²¾ç¡®åœ°ç†ä½ç½®: pip install geoip2")
            return

        # å°è¯•å‡ ä¸ªå¸¸è§çš„GeoIPæ•°æ®åº“è·¯å¾„
        possible_paths = [
            db_path,
            "GeoLite2-City.mmdb",
            "/usr/share/GeoIP/GeoLite2-City.mmdb",
            "/opt/GeoIP/GeoLite2-City.mmdb",
            str(Path(__file__).parent.parent / "data" / "GeoLite2-City.mmdb")
        ]

        for path in possible_paths:
            if path and Path(path).exists():
                try:
                    self.geoip_reader = geoip2.database.Reader(path)
                    self.logger.info(f"âœ… GeoIPæ•°æ®åº“åŠ è½½æˆåŠŸ: {path}")
                    return
                except Exception as e:
                    self.logger.warning(f"âš ï¸ GeoIPæ•°æ®åº“åŠ è½½å¤±è´¥ {path}: {e}")

        self.logger.info("ğŸ“ æœªæ‰¾åˆ°GeoIPæ•°æ®åº“ï¼Œä½¿ç”¨ç®€åŒ–åœ°ç†ä½ç½®åˆ†æ")

    def map_to_dwd(self, parsed_data: Dict[str, Any], source_file: str = None) -> Dict[str, Any]:
        """
        å¢å¼ºç‰ˆå­—æ®µæ˜ å°„ - é›†æˆæ‰€æœ‰æ–°åŠŸèƒ½
        """
        # é¦–å…ˆè°ƒç”¨åŸºç¡€æ˜ å°„
        mapped_data = super().map_to_dwd(parsed_data, source_file)

        try:
            # è·å–å…³é”®å­—æ®µ
            client_ip = mapped_data.get('client_ip', '')
            request_uri = mapped_data.get('request_uri', '')
            user_agent = mapped_data.get('user_agent', '')
            referer = mapped_data.get('referer', '')

            # 1. IPåœ°ç†ä½ç½®å¢å¼º
            if client_ip:
                geo_info = self._enhance_geo_location(client_ip)
                mapped_data.update(geo_info)

            # 2. ä¸šåŠ¡åŸŸæ™ºèƒ½åˆ†ç±»
            if request_uri:
                domain_info = self._enhance_domain_classification(request_uri, user_agent, referer)
                mapped_data.update(domain_info)

            # 3. å¼‚å¸¸è¡Œä¸ºæ£€æµ‹
            anomaly_info = self._enhance_anomaly_detection(mapped_data)
            mapped_data.update(anomaly_info)

            # 4. å¢å¼ºUser-Agentè§£æ (åŸºäºçˆ¶ç±»åŠŸèƒ½)
            if user_agent:
                enhanced_ua = self._enhance_user_agent_parsing(user_agent)
                mapped_data.update(enhanced_ua)

            # 5. è¯·æ±‚ç‰¹å¾å¢å¼º
            request_features = self._enhance_request_features(request_uri, user_agent, referer)
            mapped_data.update(request_features)

        except Exception as e:
            self.enhancement_stats['enhancement_errors'] += 1
            self.logger.error(f"å¢å¼ºå­—æ®µæ˜ å°„å¤±è´¥: {e}")

        return mapped_data

    def _enhance_geo_location(self, ip: str) -> Dict[str, Any]:
        """å¢å¼ºIPåœ°ç†ä½ç½®å®šä½"""
        # æ£€æŸ¥ç¼“å­˜
        if ip in self.geo_cache:
            self.enhancement_stats['geo_cache_hits'] += 1
            return self.geo_cache[ip]

        self.enhancement_stats['geo_lookups'] += 1
        geo_info = {}

        try:
            if self.geoip_reader:
                # ä½¿ç”¨GeoIP2ç²¾ç¡®å®šä½
                try:
                    response = self.geoip_reader.city(ip)
                    geo_info = {
                        'geo_country_name': response.country.names.get('zh-CN') or response.country.name or 'Unknown',
                        'geo_country_code': response.country.iso_code or 'XX',
                        'geo_city_name': response.city.names.get('zh-CN') or response.city.name or 'Unknown',
                        'geo_region_name': response.subdivisions.most_specific.names.get('zh-CN') or
                                         response.subdivisions.most_specific.name or 'Unknown',
                        'geo_latitude': float(response.location.latitude) if response.location.latitude else 0.0,
                        'geo_longitude': float(response.location.longitude) if response.location.longitude else 0.0,
                        'geo_accuracy_radius': response.location.accuracy_radius or 0,
                        'geo_timezone': str(response.location.time_zone) if response.location.time_zone else 'Unknown',
                        'geo_isp': 'Unknown',  # GeoLite2-Cityä¸åŒ…å«ISPä¿¡æ¯
                        'geo_organization': 'Unknown',
                        'geo_asn': 0,
                        'geo_source': 'geoip2'
                    }
                except (geoip2.errors.AddressNotFoundError, ValueError):
                    # IPä¸åœ¨æ•°æ®åº“ä¸­ï¼Œä½¿ç”¨ç®€åŒ–åˆ†ç±»
                    geo_info = self._simple_geo_classify(ip)
            else:
                # ä½¿ç”¨ç®€åŒ–åœ°ç†ä½ç½®åˆ†ç±»
                geo_info = self._simple_geo_classify(ip)

        except Exception as e:
            self.logger.warning(f"åœ°ç†ä½ç½®è§£æå¤±è´¥ {ip}: {e}")
            geo_info = self._get_default_geo_info()

        # ç¼“å­˜ç»“æœ
        if len(self.geo_cache) < 10000:  # é™åˆ¶ç¼“å­˜å¤§å°
            self.geo_cache[ip] = geo_info

        return geo_info

    def _simple_geo_classify(self, ip: str) -> Dict[str, Any]:
        """ç®€åŒ–åœ°ç†ä½ç½®åˆ†ç±»"""
        # å†…ç½‘IPåˆ¤æ–­
        if self._is_private_ip(ip):
            return {
                'geo_country_name': 'å†…ç½‘',
                'geo_country_code': 'PRIVATE',
                'geo_city_name': 'æœ¬åœ°',
                'geo_region_name': 'å†…ç½‘',
                'geo_latitude': 0.0,
                'geo_longitude': 0.0,
                'geo_accuracy_radius': 0,
                'geo_timezone': 'Local',
                'geo_isp': 'å†…ç½‘',
                'geo_organization': 'æœ¬åœ°ç½‘ç»œ',
                'geo_asn': 0,
                'geo_source': 'simple_private'
            }

        # ä¸­å›½IPæ®µç®€å•è¯†åˆ«
        china_prefixes = {
            'china_telecom': ['1.0.', '1.1.', '14.', '27.', '36.', '42.', '49.', '58.', '59.', '60.', '61.'],
            'china_unicom': ['10.', '112.', '113.', '114.', '115.', '116.', '117.', '118.', '119.', '120.', '121.'],
            'china_mobile': ['39.', '111.', '183.', '211.', '218.', '221.', '222.']
        }

        for isp, prefixes in china_prefixes.items():
            if any(ip.startswith(prefix) for prefix in prefixes):
                return {
                    'geo_country_name': 'ä¸­å›½',
                    'geo_country_code': 'CN',
                    'geo_city_name': 'æœªçŸ¥',
                    'geo_region_name': 'ä¸­å›½å¤§é™†',
                    'geo_latitude': 39.9042,  # åŒ—äº¬åæ ‡
                    'geo_longitude': 116.4074,
                    'geo_accuracy_radius': 1000,
                    'geo_timezone': 'Asia/Shanghai',
                    'geo_isp': isp.replace('_', ' ').title(),
                    'geo_organization': isp.replace('_', ' ').title(),
                    'geo_asn': 0,
                    'geo_source': f'simple_{isp}'
                }

        # é»˜è®¤åˆ†ç±»
        return self._get_default_geo_info()

    def _get_default_geo_info(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤åœ°ç†ä½ç½®ä¿¡æ¯"""
        return {
            'geo_country_name': 'æœªçŸ¥',
            'geo_country_code': 'UNKNOWN',
            'geo_city_name': 'æœªçŸ¥',
            'geo_region_name': 'æœªçŸ¥',
            'geo_latitude': 0.0,
            'geo_longitude': 0.0,
            'geo_accuracy_radius': 5000,
            'geo_timezone': 'Unknown',
            'geo_isp': 'æœªçŸ¥',
            'geo_organization': 'æœªçŸ¥',
            'geo_asn': 0,
            'geo_source': 'default'
        }

    def _is_private_ip(self, ip: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå†…ç½‘IP"""
        private_ranges = [
            '10.', '172.16.', '172.17.', '172.18.', '172.19.', '172.20.',
            '172.21.', '172.22.', '172.23.', '172.24.', '172.25.', '172.26.',
            '172.27.', '172.28.', '172.29.', '172.30.', '172.31.', '192.168.',
            '127.', '0.', 'localhost', '::1'
        ]
        return any(ip.startswith(prefix) for prefix in private_ranges)

    def _enhance_domain_classification(self, uri: str, user_agent: str = '', referer: str = '') -> Dict[str, Any]:
        """å¢å¼ºä¸šåŠ¡åŸŸåˆ†ç±»"""
        cache_key = f"{uri}|{user_agent[:50]}|{referer[:50]}"

        if cache_key in self.domain_cache:
            self.enhancement_stats['domain_cache_hits'] += 1
            return self.domain_cache[cache_key]

        self.enhancement_stats['domain_classifications'] += 1

        try:
            classification = self.domain_classifier.classify_request(uri, user_agent, referer)

            domain_info = {
                'business_domain': classification['primary_domain'],
                'business_domain_confidence': classification['confidence'],
                'business_domain_secondary': classification['all_matches'][1]['domain'] if len(classification['all_matches']) > 1 else '',
                'business_domain_tertiary': classification['all_matches'][2]['domain'] if len(classification['all_matches']) > 2 else '',
                'business_domain_is_classified': classification['is_classified'],
                'business_domain_match_count': len(classification['all_matches'])
            }

        except Exception as e:
            self.logger.warning(f"ä¸šåŠ¡åŸŸåˆ†ç±»å¤±è´¥: {e}")
            domain_info = {
                'business_domain': 'general_web',
                'business_domain_confidence': 0.0,
                'business_domain_secondary': '',
                'business_domain_tertiary': '',
                'business_domain_is_classified': False,
                'business_domain_match_count': 0
            }

        # ç¼“å­˜ç»“æœ
        if len(self.domain_cache) < 5000:
            self.domain_cache[cache_key] = domain_info

        return domain_info

    def _enhance_anomaly_detection(self, mapped_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¢å¼ºå¼‚å¸¸è¡Œä¸ºæ£€æµ‹"""
        try:
            # å‡†å¤‡æ£€æµ‹æ•°æ®
            detection_data = {
                'client_ip': mapped_data.get('client_ip', ''),
                'request_uri': mapped_data.get('request_uri', ''),
                'status_code': mapped_data.get('status_code', 200),
                'response_time_ms': mapped_data.get('response_time_ms', 0),
                'user_agent': mapped_data.get('user_agent', ''),
                'referer': mapped_data.get('referer', ''),
                'request_method': mapped_data.get('request_method', 'GET'),
                'request_body_size': mapped_data.get('request_body_size', 0)
            }

            # æ‰§è¡Œå¼‚å¸¸æ£€æµ‹
            anomaly_result = self.anomaly_detector.detect_anomalies(detection_data)

            if anomaly_result['has_anomalies']:
                self.enhancement_stats['anomalies_detected'] += 1

            return {
                'anomaly_detected': anomaly_result['has_anomalies'],
                'anomaly_count': anomaly_result['anomaly_count'],
                'anomaly_risk_score': anomaly_result['risk_score'],
                'anomaly_types': ','.join([a['type'] for a in anomaly_result['anomalies']]) if anomaly_result['anomalies'] else '',
                'anomaly_severity': max([a['severity'] for a in anomaly_result['anomalies']], default='none',
                                      key=lambda x: {'none': 0, 'low': 1, 'medium': 2, 'high': 3}.get(x, 0)),
                'anomaly_details': json.dumps(anomaly_result['anomalies'][:3]) if anomaly_result['anomalies'] else ''  # ä¿å­˜å‰3ä¸ªå¼‚å¸¸
            }

        except Exception as e:
            self.logger.warning(f"å¼‚å¸¸æ£€æµ‹å¤±è´¥: {e}")
            return {
                'anomaly_detected': False,
                'anomaly_count': 0,
                'anomaly_risk_score': 0.0,
                'anomaly_types': '',
                'anomaly_severity': 'none',
                'anomaly_details': ''
            }

    def _enhance_user_agent_parsing(self, user_agent: str) -> Dict[str, Any]:
        """å¢å¼ºUser-Agentè§£æ (åŸºäºçˆ¶ç±»åŠŸèƒ½)"""
        try:
            # è°ƒç”¨çˆ¶ç±»çš„å¢å¼ºè§£æ
            enhanced_ua = self._parse_user_agent_enhanced(user_agent)

            # æ·»åŠ æ›´å¤šåˆ†æç»´åº¦
            enhanced_info = {
                'ua_is_mobile_device': enhanced_ua.get('is_mobile', False),
                'ua_is_bot_crawler': enhanced_ua.get('is_bot', False),
                'ua_device_category': enhanced_ua.get('device_type', 'unknown'),
                'ua_platform_version': enhanced_ua.get('os_version', ''),
                'ua_browser_family': enhanced_ua.get('browser_family', ''),
                'ua_is_government_app': enhanced_ua.get('is_government_app', False),
                'ua_is_miniprogram': enhanced_ua.get('is_miniprogram', False),
                'ua_miniprogram_type': enhanced_ua.get('miniprogram_type', ''),
                'ua_sdk_type': enhanced_ua.get('sdk_type', ''),
                'ua_security_level': self._calculate_ua_security_level(user_agent)
            }

            return enhanced_info

        except Exception as e:
            self.logger.warning(f"å¢å¼ºUser-Agentè§£æå¤±è´¥: {e}")
            return {
                'ua_is_mobile_device': False,
                'ua_is_bot_crawler': False,
                'ua_device_category': 'unknown',
                'ua_platform_version': '',
                'ua_browser_family': '',
                'ua_is_government_app': False,
                'ua_is_miniprogram': False,
                'ua_miniprogram_type': '',
                'ua_sdk_type': '',
                'ua_security_level': 'medium'
            }

    def _calculate_ua_security_level(self, user_agent: str) -> str:
        """è®¡ç®—User-Agentå®‰å…¨çº§åˆ«"""
        ua_lower = user_agent.lower()

        # é«˜é£é™©æŒ‡æ ‡
        high_risk_indicators = ['sqlmap', 'nmap', 'nikto', 'dirb', 'gobuster', 'wfuzz', 'burp']
        if any(indicator in ua_lower for indicator in high_risk_indicators):
            return 'high_risk'

        # ä¸­é£é™©æŒ‡æ ‡
        medium_risk_indicators = ['python', 'curl', 'wget', 'postman', 'script']
        if any(indicator in ua_lower for indicator in medium_risk_indicators):
            return 'medium_risk'

        # æœºå™¨äººä½†ä½é£é™©
        bot_indicators = ['googlebot', 'bingbot', 'baiduspider', 'bot', 'crawler']
        if any(indicator in ua_lower for indicator in bot_indicators):
            return 'low_risk'

        # æ­£å¸¸æµè§ˆå™¨
        return 'normal'

    def _enhance_request_features(self, uri: str, user_agent: str, referer: str) -> Dict[str, Any]:
        """å¢å¼ºè¯·æ±‚ç‰¹å¾åˆ†æ"""
        try:
            return {
                # URIç‰¹å¾
                'request_uri_length': len(uri),
                'request_uri_has_query': '?' in uri,
                'request_uri_query_count': len(parse_qs(urlparse(uri).query)) if '?' in uri else 0,
                'request_uri_depth': uri.count('/'),
                'request_uri_has_extension': bool(re.search(r'\.[a-zA-Z0-9]+$', uri.split('?')[0])),
                'request_uri_extension': re.search(r'\.([a-zA-Z0-9]+)$', uri.split('?')[0]).group(1) if re.search(r'\.([a-zA-Z0-9]+)$', uri.split('?')[0]) else '',

                # Refererç‰¹å¾
                'referer_domain': urlparse(referer).netloc if referer else '',
                'referer_is_search_engine': any(engine in referer.lower() for engine in ['google', 'baidu', 'bing', 'yahoo']) if referer else False,
                'referer_is_social_media': any(social in referer.lower() for social in ['weibo', 'wechat', 'qq', 'facebook', 'twitter']) if referer else False,
                'referer_is_external': bool(referer and urlparse(referer).netloc),

                # ç»„åˆç‰¹å¾
                'request_complexity_score': self._calculate_request_complexity(uri, user_agent, referer),
                'request_trust_score': self._calculate_request_trust_score(uri, user_agent, referer)
            }

        except Exception as e:
            self.logger.warning(f"è¯·æ±‚ç‰¹å¾åˆ†æå¤±è´¥: {e}")
            return {
                'request_uri_length': 0,
                'request_uri_has_query': False,
                'request_uri_query_count': 0,
                'request_uri_depth': 0,
                'request_uri_has_extension': False,
                'request_uri_extension': '',
                'referer_domain': '',
                'referer_is_search_engine': False,
                'referer_is_social_media': False,
                'referer_is_external': False,
                'request_complexity_score': 0.5,
                'request_trust_score': 0.5
            }

    def _calculate_request_complexity(self, uri: str, user_agent: str, referer: str) -> float:
        """è®¡ç®—è¯·æ±‚å¤æ‚åº¦è¯„åˆ† (0-1)"""
        complexity = 0.0

        # URIå¤æ‚åº¦
        complexity += min(len(uri) / 200, 0.3)  # URIé•¿åº¦
        complexity += min(uri.count('?') * 0.1, 0.1)  # æŸ¥è¯¢å‚æ•°
        complexity += min(uri.count('/') * 0.05, 0.2)  # è·¯å¾„æ·±åº¦

        # User-Agentå¤æ‚åº¦
        if user_agent:
            complexity += min(len(user_agent) / 500, 0.2)
            if any(keyword in user_agent.lower() for keyword in ['script', 'tool', 'api', 'client']):
                complexity += 0.2

        return min(complexity, 1.0)

    def _calculate_request_trust_score(self, uri: str, user_agent: str, referer: str) -> float:
        """è®¡ç®—è¯·æ±‚ä¿¡ä»»åº¦è¯„åˆ† (0-1)"""
        trust = 0.5  # åŸºç¡€ä¿¡ä»»åº¦

        # æ­£é¢å› ç´ 
        if referer and any(engine in referer.lower() for engine in ['google', 'baidu']):
            trust += 0.2  # æœç´¢å¼•æ“æ¥æº

        if user_agent and any(browser in user_agent.lower() for browser in ['chrome', 'firefox', 'safari', 'edge']):
            trust += 0.2  # æ­£å¸¸æµè§ˆå™¨

        if '.gov' in uri or 'æ”¿åºœ' in uri:
            trust += 0.1  # æ”¿åºœåŸŸå

        # è´Ÿé¢å› ç´ 
        if any(suspicious in uri.lower() for suspicious in ['admin', 'config', '.env', 'backup']):
            trust -= 0.3  # å¯ç–‘URI

        if user_agent and any(tool in user_agent.lower() for tool in ['curl', 'wget', 'python', 'script']):
            trust -= 0.2  # å·¥å…·ç±»è¯·æ±‚

        return max(0.0, min(1.0, trust))

    def get_enhancement_stats(self) -> Dict[str, Any]:
        """è·å–å¢å¼ºåŠŸèƒ½ç»Ÿè®¡"""
        total_geo = self.enhancement_stats['geo_lookups']
        total_domain = self.enhancement_stats['domain_classifications']

        return {
            **self.enhancement_stats,
            'geo_cache_hit_rate': self.enhancement_stats['geo_cache_hits'] / total_geo if total_geo > 0 else 0,
            'domain_cache_hit_rate': self.enhancement_stats['domain_cache_hits'] / total_domain if total_domain > 0 else 0,
            'geo_cache_size': len(self.geo_cache),
            'domain_cache_size': len(self.domain_cache),
            'has_geoip_db': self.geoip_reader is not None
        }

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.geoip_reader:
            try:
                self.geoip_reader.close()
                self.logger.info("âœ… GeoIPæ•°æ®åº“è¿æ¥å·²å…³é—­")
            except Exception as e:
                self.logger.warning(f"âš ï¸ å…³é—­GeoIPæ•°æ®åº“å¤±è´¥: {e}")

        # æ¸…ç†ç¼“å­˜
        self.geo_cache.clear()
        self.domain_cache.clear()
        self.anomaly_cache.clear()

# ä¸šåŠ¡åŸŸåˆ†ç±»å™¨ (ä»interactive_ultra_etl.pyç§»æ¤)
class BusinessDomainClassifier:
    """ä¸šåŠ¡åŸŸæ™ºèƒ½åˆ†ç±»å™¨"""

    def __init__(self):
        self.domain_patterns = {
            'government': {
                'keywords': ['gov', 'government', 'æ”¿åºœ', 'æ”¿åŠ¡', 'å…¬å®‰', 'æ³•é™¢', 'æ£€å¯Ÿé™¢', 'ç¨åŠ¡', 'æµ·å…³', 'å·¥å•†', 'zwfw', 'gxrz'],
                'uri_patterns': [r'/gov/', r'/government/', r'/zwfw/', r'/gxrz/', r'/ç¨åŠ¡/', r'/æ”¿åŠ¡/'],
                'priority': 10
            },
            'authentication': {
                'keywords': ['auth', 'login', 'oauth', 'sso', 'jwt', 'token', 'è®¤è¯', 'ç™»å½•', 'æˆæƒ'],
                'uri_patterns': [r'/auth/', r'/login', r'/oauth/', r'/sso/', r'/è®¤è¯/', r'/ç™»å½•/'],
                'priority': 9
            },
            'payment': {
                'keywords': ['pay', 'payment', 'alipay', 'wechat', 'bank', 'æ”¯ä»˜', 'é“¶è¡Œ', 'è´¢åŠ¡', 'è®¢å•'],
                'uri_patterns': [r'/pay/', r'/payment/', r'/alipay/', r'/æ”¯ä»˜/', r'/è®¢å•/', r'/è´¢åŠ¡/'],
                'priority': 9
            },
            'file_service': {
                'keywords': ['file', 'upload', 'download', 'storage', 'oss', 'cdn', 'æ–‡ä»¶', 'ä¸Šä¼ ', 'ä¸‹è½½', 'å­˜å‚¨'],
                'uri_patterns': [r'/file/', r'/upload/', r'/download/', r'/storage/', r'/æ–‡ä»¶/', r'/ä¸Šä¼ /', r'/ä¸‹è½½/'],
                'priority': 7
            },
            'user_management': {
                'keywords': ['user', 'profile', 'account', 'member', 'ç”¨æˆ·', 'è´¦æˆ·', 'ä¸ªäºº', 'ä¼šå‘˜'],
                'uri_patterns': [r'/user/', r'/profile/', r'/account/', r'/member/', r'/ç”¨æˆ·/', r'/è´¦æˆ·/', r'/ä¸ªäºº/'],
                'priority': 6
            },
            'api_gateway': {
                'keywords': ['api', 'gateway', 'service', 'microservice', 'æ¥å£', 'ç½‘å…³', 'æœåŠ¡'],
                'uri_patterns': [r'/api/', r'/gateway/', r'/service/', r'/v1/', r'/v2/', r'/æ¥å£/', r'/æœåŠ¡/'],
                'priority': 8
            },
            'content_management': {
                'keywords': ['cms', 'content', 'article', 'news', 'blog', 'å†…å®¹', 'æ–‡ç« ', 'æ–°é—»', 'åšå®¢'],
                'uri_patterns': [r'/cms/', r'/content/', r'/article/', r'/news/', r'/å†…å®¹/', r'/æ–‡ç« /', r'/æ–°é—»/'],
                'priority': 5
            },
            'monitoring': {
                'keywords': ['monitor', 'health', 'status', 'metrics', 'log', 'ç›‘æ§', 'å¥åº·', 'çŠ¶æ€', 'æŒ‡æ ‡'],
                'uri_patterns': [r'/monitor/', r'/health/', r'/status/', r'/metrics/', r'/ç›‘æ§/', r'/å¥åº·/'],
                'priority': 4
            },
            'static_resources': {
                'keywords': ['static', 'assets', 'css', 'js', 'img', 'image', 'é™æ€', 'èµ„æº'],
                'uri_patterns': [r'\.css$', r'\.js$', r'\.png$', r'\.jpg$', r'\.gif$', r'/static/', r'/assets/'],
                'priority': 2
            },
            'mobile_app': {
                'keywords': ['app', 'mobile', 'android', 'ios', 'wechat', 'miniprogram', 'åº”ç”¨', 'æ‰‹æœº', 'ç§»åŠ¨'],
                'uri_patterns': [r'/app/', r'/mobile/', r'/android/', r'/ios/', r'/åº”ç”¨/', r'/æ‰‹æœº/'],
                'priority': 6
            }
        }

    def classify_request(self, uri: str, user_agent: str = '', referer: str = '') -> Dict[str, Any]:
        """åˆ†ç±»è¯·æ±‚åˆ°ä¸šåŠ¡åŸŸ"""
        classifications = []
        text_content = f"{uri} {user_agent} {referer}".lower()

        for domain, config in self.domain_patterns.items():
            score = 0
            matched_keywords = []
            matched_patterns = []

            for keyword in config['keywords']:
                if keyword.lower() in text_content:
                    score += config['priority']
                    matched_keywords.append(keyword)

            for pattern in config['uri_patterns']:
                if re.search(pattern, uri, re.IGNORECASE):
                    score += config['priority'] * 2
                    matched_patterns.append(pattern)

            if score > 0:
                classifications.append({
                    'domain': domain,
                    'score': score,
                    'confidence': min(score / 20, 1.0),
                    'matched_keywords': matched_keywords,
                    'matched_patterns': matched_patterns
                })

        classifications.sort(key=lambda x: x['score'], reverse=True)

        if classifications:
            best_match = classifications[0]
            return {
                'primary_domain': best_match['domain'],
                'confidence': best_match['confidence'],
                'all_matches': classifications[:3],
                'is_classified': True
            }
        else:
            return {
                'primary_domain': 'general_web',
                'confidence': 0.1,
                'all_matches': [],
                'is_classified': False
            }

# ç®€åŒ–å¼‚å¸¸æ£€æµ‹å™¨
class SimpleAnomalyDetector:
    """ç®€åŒ–å¼‚å¸¸æ£€æµ‹å™¨"""

    def __init__(self):
        self.request_counts = {}
        self.thresholds = {
            'high_frequency_ip': 50,
            'error_rate': 0.1,
            'response_time': 5000,
            'suspicious_uri_length': 500
        }

    def detect_anomalies(self, request_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ£€æµ‹å¼‚å¸¸"""
        anomalies = []

        client_ip = request_data.get('client_ip', '')
        uri = request_data.get('request_uri', '')
        status_code = request_data.get('status_code', 200)
        response_time = request_data.get('response_time_ms', 0)

        # ç®€å•çš„å¼‚å¸¸æ£€æµ‹é€»è¾‘
        if response_time > self.thresholds['response_time']:
            anomalies.append({
                'type': 'slow_response',
                'severity': 'medium',
                'description': f'å“åº”æ—¶é—´è¿‡é•¿: {response_time}ms',
                'value': response_time
            })

        if len(uri) > self.thresholds['suspicious_uri_length']:
            anomalies.append({
                'type': 'suspicious_uri_length',
                'severity': 'low',
                'description': f'URIé•¿åº¦å¼‚å¸¸: {len(uri)} å­—ç¬¦',
                'value': len(uri)
            })

        if status_code >= 500:
            anomalies.append({
                'type': 'server_error',
                'severity': 'high',
                'description': f'æœåŠ¡å™¨é”™è¯¯: {status_code}',
                'value': status_code
            })

        return {
            'has_anomalies': len(anomalies) > 0,
            'anomaly_count': len(anomalies),
            'anomalies': anomalies,
            'risk_score': len(anomalies) * 0.3 if anomalies else 0.0
        }