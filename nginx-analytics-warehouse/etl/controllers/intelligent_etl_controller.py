#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½åŒ–ETLæ§åˆ¶å™¨ - æ”¯æŒå¤šæ–‡ä»¶ã€çŠ¶æ€è·Ÿè¸ªã€æŒ‰æ—¥æœŸå¤„ç†
Intelligent ETL Controller - Multi-file processing, state tracking, date-based processing

åŸºäºsimple_etl_controllerå‡çº§ï¼Œå‚è€ƒnginx_processor_modularè®¾è®¡æ€è·¯
"""

import sys
import os
import json
import time
import argparse
from datetime import datetime, date
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥å…¶ä»–æ¨¡å—
current_dir = Path(__file__).parent
etl_root = current_dir.parent
sys.path.append(str(etl_root))

from parsers.base_log_parser import BaseLogParser
from processors.field_mapper import FieldMapper
from writers.dwd_writer import DWDWriter

class IntelligentETLController:
    """æ™ºèƒ½åŒ–ETLæ§åˆ¶å™¨"""
    
    def __init__(self, 
                 base_log_dir: str = None, 
                 state_file: str = None,
                 batch_size: int = 50):
        """
        åˆå§‹åŒ–æ™ºèƒ½åŒ–ETLæ§åˆ¶å™¨
        
        Args:
            base_log_dir: æ—¥å¿—æ ¹ç›®å½•
            state_file: çŠ¶æ€æ–‡ä»¶è·¯å¾„
            batch_size: æ‰¹å¤„ç†å¤§å°
        """
        # åŸºç¡€é…ç½®
        self.base_log_dir = Path(base_log_dir) if base_log_dir else \
            Path("D:/project/nginx-log-analyzer/nginx-analytics-warehouse/nginx_logs")
        self.state_file = Path(state_file) if state_file else \
            Path(etl_root / "processed_logs_state.json")
        self.batch_size = batch_size
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.parser = BaseLogParser()
        self.mapper = FieldMapper()
        self.writer = DWDWriter()
        
        # æ—¥å¿—é…ç½®
        import logging
        self.logger = logging.getLogger(__name__)
        
        # å¤„ç†çŠ¶æ€
        self.processed_state = self.load_state()
        
        # å…¨å±€ç»Ÿè®¡ä¿¡æ¯
        self.session_stats = {
            'start_time': None,
            'end_time': None,
            'total_files_processed': 0,
            'total_lines_processed': 0,
            'total_records_written': 0,
            'total_errors': 0,
            'processing_errors': []
        }
        
        self.logger.info("æ™ºèƒ½åŒ–ETLæ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"æ—¥å¿—ç›®å½•: {self.base_log_dir}")
        self.logger.info(f"çŠ¶æ€æ–‡ä»¶: {self.state_file}")
        self.logger.info(f"æ‰¹å¤„ç†å¤§å°: {self.batch_size}")
    
    def load_state(self) -> Dict[str, Any]:
        """åŠ è½½å¤„ç†çŠ¶æ€"""
        if self.state_file.exists():
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    state = json.load(f)
                    processed_count = len(state.get('processed_files', {}))
                    self.logger.info(f"åŠ è½½çŠ¶æ€æ–‡ä»¶æˆåŠŸ: {processed_count} ä¸ªå·²å¤„ç†æ–‡ä»¶")
                    return state
            except Exception as e:
                self.logger.error(f"åŠ è½½çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
        
        return {
            'processed_files': {},
            'last_update': None,
            'total_processed_records': 0,
            'processing_history': []
        }
    
    def save_state(self):
        """ä¿å­˜å¤„ç†çŠ¶æ€"""
        try:
            self.processed_state['last_update'] = datetime.now().isoformat()
            with open(self.state_file, 'w', encoding='utf-8') as f:
                json.dump(self.processed_state, f, indent=2, ensure_ascii=False, default=str)
            self.logger.info("çŠ¶æ€æ–‡ä»¶ä¿å­˜æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"ä¿å­˜çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
    
    def scan_log_directories(self) -> Dict[str, List[Path]]:
        """æ‰«ææ—¥å¿—ç›®å½•ï¼Œè¿”å›æŒ‰æ—¥æœŸåˆ†ç»„çš„æ—¥å¿—æ–‡ä»¶"""
        if not self.base_log_dir.exists():
            self.logger.error(f"æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {self.base_log_dir}")
            return {}
        
        log_files_by_date = {}
        
        # æ‰«æYYYYMMDDæ ¼å¼çš„ç›®å½•
        for date_dir in self.base_log_dir.iterdir():
            if date_dir.is_dir() and date_dir.name.isdigit() and len(date_dir.name) == 8:
                try:
                    # éªŒè¯æ—¥æœŸæ ¼å¼
                    datetime.strptime(date_dir.name, '%Y%m%d')
                    
                    # æŸ¥æ‰¾.logæ–‡ä»¶
                    log_files = list(date_dir.glob("*.log"))
                    if log_files:
                        log_files_by_date[date_dir.name] = sorted(log_files)
                        
                except ValueError:
                    self.logger.warning(f"å¿½ç•¥æ— æ•ˆæ—¥æœŸç›®å½•: {date_dir.name}")
        
        self.logger.info(f"æ‰«æå®Œæˆ: æ‰¾åˆ° {len(log_files_by_date)} ä¸ªæ—¥æœŸç›®å½•")
        total_files = sum(len(files) for files in log_files_by_date.values())
        self.logger.info(f"æ€»è®¡ {total_files} ä¸ªæ—¥å¿—æ–‡ä»¶")
        
        return log_files_by_date
    
    def is_file_processed(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å¤„ç†"""
        file_key = str(file_path)
        if file_key not in self.processed_state['processed_files']:
            return False
        
        # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ˜¯å¦å˜åŒ–
        try:
            current_mtime = file_path.stat().st_mtime
            recorded_mtime = self.processed_state['processed_files'][file_key].get('mtime', 0)
            return abs(current_mtime - recorded_mtime) < 1.0  # 1ç§’è¯¯å·®å®¹å¿
        except:
            return False
    
    def mark_file_processed(self, file_path: Path, record_count: int, processing_time: float):
        """æ ‡è®°æ–‡ä»¶ä¸ºå·²å¤„ç†"""
        file_key = str(file_path)
        try:
            mtime = file_path.stat().st_mtime
            self.processed_state['processed_files'][file_key] = {
                'processed_at': datetime.now().isoformat(),
                'record_count': record_count,
                'processing_time': processing_time,
                'mtime': mtime,
                'file_size': file_path.stat().st_size
            }
        except Exception as e:
            self.logger.error(f"æ ‡è®°æ–‡ä»¶çŠ¶æ€å¤±è´¥ {file_path}: {e}")
    
    def process_single_file(self, file_path: Path, test_mode: bool = False, limit: int = None) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªæ—¥å¿—æ–‡ä»¶ - åŸºäºsimple_etl_controllerçš„process_fileæ–¹æ³•
        
        Args:
            file_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            test_mode: æµ‹è¯•æ¨¡å¼ï¼ˆä¸å®é™…å†™å…¥æ•°æ®åº“ï¼‰
            limit: é™åˆ¶å¤„ç†çš„è¡Œæ•°
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        if not file_path.exists():
            error_msg = f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
            self.logger.error(error_msg)
            return self._create_error_result(error_msg)
        
        start_time = time.time()
        
        # æ–‡ä»¶çº§åˆ«çš„ç»Ÿè®¡ä¿¡æ¯
        file_stats = {
            'total_lines': 0,
            'parsed_lines': 0,
            'mapped_lines': 0,
            'written_lines': 0,
            'failed_lines': 0,
            'batches_processed': 0,
            'processing_errors': []
        }
        
        self.logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path.name}")
        if test_mode:
            self.logger.info("ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šå°†ä¸ä¼šå®é™…å†™å…¥æ•°æ®åº“")
        if limit:
            self.logger.info(f"ğŸ”¢ é™åˆ¶å¤„ç†è¡Œæ•°: {limit}")
        
        try:
            # è¿æ¥æ•°æ®åº“ï¼ˆéæµ‹è¯•æ¨¡å¼ï¼‰
            if not test_mode:
                if not self.writer.connect():
                    return self._create_error_result("æ•°æ®åº“è¿æ¥å¤±è´¥")
            
            # æ‰¹é‡å¤„ç†
            batch = []
            processed_count = 0
            
            for parsed_data in self.parser.parse_file(file_path):
                file_stats['total_lines'] += 1
                
                if parsed_data:
                    file_stats['parsed_lines'] += 1
                    
                    try:
                        # å­—æ®µæ˜ å°„
                        mapped_data = self.mapper.map_to_dwd(parsed_data, file_path.name)
                        file_stats['mapped_lines'] += 1
                        
                        batch.append(mapped_data)
                        
                        # æ‰¹é‡å†™å…¥
                        if len(batch) >= self.batch_size:
                            write_result = self._write_batch(batch, test_mode)
                            if write_result['success']:
                                file_stats['written_lines'] += write_result['count']
                            else:
                                file_stats['failed_lines'] += len(batch)
                                file_stats['processing_errors'].append(write_result['error'])
                            
                            file_stats['batches_processed'] += 1
                            batch = []
                        
                        processed_count += 1
                        
                        # æ£€æŸ¥é™åˆ¶
                        if limit and processed_count >= limit:
                            self.logger.info(f"è¾¾åˆ°å¤„ç†é™åˆ¶ ({limit} è¡Œ)ï¼Œåœæ­¢å¤„ç†")
                            break
                            
                    except Exception as e:
                        self.logger.error(f"å­—æ®µæ˜ å°„å¤±è´¥: {e}")
                        file_stats['failed_lines'] += 1
                        file_stats['processing_errors'].append(str(e))
                else:
                    file_stats['failed_lines'] += 1
            
            # å¤„ç†æœ€åä¸€æ‰¹
            if batch:
                write_result = self._write_batch(batch, test_mode)
                if write_result['success']:
                    file_stats['written_lines'] += write_result['count']
                else:
                    file_stats['failed_lines'] += len(batch)
                    file_stats['processing_errors'].append(write_result['error'])
                
                file_stats['batches_processed'] += 1
            
            duration = time.time() - start_time
            
            # å…³é—­è¿æ¥
            if not test_mode:
                self.writer.close()
            
            # æ›´æ–°å…¨å±€ç»Ÿè®¡
            self.session_stats['total_files_processed'] += 1
            self.session_stats['total_lines_processed'] += file_stats['total_lines']
            self.session_stats['total_records_written'] += file_stats['written_lines']
            self.session_stats['total_errors'] += file_stats['failed_lines']
            
            # ç”Ÿæˆç»“æœæŠ¥å‘Š
            return {
                'success': True,
                'file_path': file_path,
                'duration': duration,
                'stats': file_stats,
                'message': f'æ–‡ä»¶ {file_path.name} å¤„ç†å®Œæˆ',
                'timestamp': datetime.now()
            }
            
        except Exception as e:
            duration = time.time() - start_time
            self.logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")
            if not test_mode:
                self.writer.close()
            return {
                'success': False,
                'file_path': file_path,
                'duration': duration,
                'error': str(e),
                'stats': file_stats,
                'timestamp': datetime.now()
            }
    
    def process_specific_date(self, date_str: str, force_reprocess: bool = False, 
                            test_mode: bool = False, limit: int = None) -> Dict[str, Any]:
        """
        å¤„ç†æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰æ—¥å¿—
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸² (YYYYMMDDæ ¼å¼)
            force_reprocess: å¼ºåˆ¶é‡æ–°å¤„ç†
            test_mode: æµ‹è¯•æ¨¡å¼
            limit: é™åˆ¶å¤„ç†çš„è¡Œæ•°ï¼ˆæ¯ä¸ªæ–‡ä»¶ï¼‰
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        self.logger.info(f"å¼€å§‹å¤„ç† {date_str} çš„æ—¥å¿— (å¼ºåˆ¶é‡æ–°å¤„ç†: {force_reprocess})")
        
        self.session_stats['start_time'] = datetime.now()
        start_time = time.time()
        
        # æ£€æŸ¥æ—¥æœŸç›®å½•
        date_dir = self.base_log_dir / date_str
        if not date_dir.exists():
            return {
                'success': False,
                'error': f'æ—¥æœŸç›®å½•ä¸å­˜åœ¨: {date_dir}',
                'date': date_str,
                'processed_files': 0,
                'total_records': 0
            }
        
        log_files = list(date_dir.glob("*.log"))
        if not log_files:
            return {
                'success': False,
                'error': f'ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°.logæ–‡ä»¶: {date_dir}',
                'date': date_str,
                'processed_files': 0,
                'total_records': 0
            }
        
        self.logger.info(f"æ‰¾åˆ° {len(log_files)} ä¸ªæ—¥å¿—æ–‡ä»¶")
        
        total_records = 0
        processed_files = 0
        errors = []
        file_results = []
        
        for log_file in sorted(log_files):
            self.logger.info(f"å¤„ç†æ–‡ä»¶: {log_file.name}")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†
            if not force_reprocess and self.is_file_processed(log_file):
                self.logger.info(f"è·³è¿‡å·²å¤„ç†æ–‡ä»¶: {log_file.name}")
                continue
            
            # å¤„ç†å•ä¸ªæ–‡ä»¶
            file_result = self.process_single_file(log_file, test_mode, limit)
            file_results.append(file_result)
            
            if file_result['success']:
                record_count = file_result['stats']['written_lines']
                total_records += record_count
                processed_files += 1
                
                # æ ‡è®°ä¸ºå·²å¤„ç†ï¼ˆéæµ‹è¯•æ¨¡å¼ï¼‰
                if not test_mode:
                    self.mark_file_processed(log_file, record_count, file_result['duration'])
            else:
                errors.append(f"{log_file.name}: {file_result['error']}")
                self.logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥ {log_file.name}: {file_result['error']}")
        
        # ä¿å­˜çŠ¶æ€
        if not test_mode:
            self.save_state()
        
        self.session_stats['end_time'] = datetime.now()
        duration = time.time() - start_time
        success = len(errors) == 0
        
        result = {
            'success': success,
            'date': date_str,
            'processed_files': processed_files,
            'total_records': total_records,
            'duration': duration,
            'errors': errors,
            'file_results': file_results
        }
        
        if success:
            self.logger.info(f"æ—¥æœŸ {date_str} å¤„ç†å®Œæˆ: {processed_files} æ–‡ä»¶, {total_records} è®°å½•, è€—æ—¶ {duration:.2f}s")
            
            # è®°å½•å¤„ç†å†å²
            if not test_mode:
                self.processed_state['processing_history'].append({
                    'date': date_str,
                    'processed_at': datetime.now().isoformat(),
                    'files': processed_files,
                    'records': total_records,
                    'duration': duration
                })
        
        return result
    
    def process_all_unprocessed_logs(self, test_mode: bool = False, limit: int = None) -> Dict[str, Any]:
        """
        å¤„ç†æ‰€æœ‰æœªå¤„ç†çš„æ—¥å¿—
        
        Args:
            test_mode: æµ‹è¯•æ¨¡å¼
            limit: é™åˆ¶å¤„ç†çš„è¡Œæ•°ï¼ˆæ¯ä¸ªæ–‡ä»¶ï¼‰
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        self.logger.info("å¼€å§‹å¤„ç†æ‰€æœ‰æœªå¤„ç†çš„æ—¥å¿—")
        self.session_stats['start_time'] = datetime.now()
        start_time = time.time()
        
        log_files_by_date = self.scan_log_directories()
        if not log_files_by_date:
            return {
                'success': False,
                'error': 'æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶',
                'processed_dates': 0,
                'total_records': 0
            }
        
        processed_dates = 0
        total_records = 0
        errors = []
        date_results = []
        
        for date_str in sorted(log_files_by_date.keys()):
            self.logger.info(f"å¤„ç†æ—¥æœŸ: {date_str}")
            
            result = self.process_specific_date(date_str, force_reprocess=False, 
                                              test_mode=test_mode, limit=limit)
            date_results.append(result)
            
            if result['success'] and result['processed_files'] > 0:
                processed_dates += 1
                total_records += result['total_records']
            else:
                if result.get('errors'):
                    errors.extend(result['errors'])
                elif result.get('error'):
                    errors.append(f"{date_str}: {result['error']}")
        
        self.session_stats['end_time'] = datetime.now()
        duration = time.time() - start_time
        success = len(errors) == 0
        
        return {
            'success': success,
            'processed_dates': processed_dates,
            'total_records': total_records,
            'duration': duration,
            'errors': errors,
            'date_results': date_results
        }
    
    def show_status(self):
        """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
        print("=" * 80)
        print("ğŸ“Š æ™ºèƒ½åŒ–ETLæ§åˆ¶å™¨çŠ¶æ€æŠ¥å‘Š")
        print("=" * 80)
        
        # 1. æ—¥å¿—ç›®å½•çŠ¶æ€
        log_files_by_date = self.scan_log_directories()
        print(f"ğŸ“ æ—¥å¿—æ ¹ç›®å½•: {self.base_log_dir}")
        print(f"   æ‰¾åˆ° {len(log_files_by_date)} ä¸ªæ—¥æœŸç›®å½•")
        
        if log_files_by_date:
            total_files = sum(len(files) for files in log_files_by_date.values())
            print(f"   æ€»è®¡ {total_files} ä¸ªæ—¥å¿—æ–‡ä»¶")
            
            # æ˜¾ç¤ºæœ€è¿‘çš„å‡ ä¸ªæ—¥æœŸ
            recent_dates = sorted(log_files_by_date.keys())[-5:]
            print(f"   æœ€è¿‘æ—¥æœŸ: {', '.join(recent_dates)}")
            
            # æ˜¾ç¤ºæ¯ä¸ªæ—¥æœŸçš„æ–‡ä»¶æ•°
            print("   å„æ—¥æœŸæ–‡ä»¶ç»Ÿè®¡:")
            for date_str in sorted(log_files_by_date.keys())[-10:]:  # æ˜¾ç¤ºæœ€è¿‘10å¤©
                file_count = len(log_files_by_date[date_str])
                # æ£€æŸ¥å·²å¤„ç†çš„æ–‡ä»¶æ•°
                processed_count = 0
                for log_file in log_files_by_date[date_str]:
                    if self.is_file_processed(log_file):
                        processed_count += 1
                status = "âœ…" if processed_count == file_count else f"âš ï¸ {processed_count}/{file_count}"
                print(f"     {date_str}: {file_count} ä¸ªæ–‡ä»¶ {status}")
        
        # 2. å¤„ç†çŠ¶æ€ç»Ÿè®¡
        processed_files_count = len(self.processed_state.get('processed_files', {}))
        total_processed_records = sum(
            info.get('record_count', 0) 
            for info in self.processed_state.get('processed_files', {}).values()
        )
        
        print(f"\nğŸ“ˆ å¤„ç†çŠ¶æ€ç»Ÿè®¡:")
        print(f"   å·²å¤„ç†æ–‡ä»¶: {processed_files_count} ä¸ª")
        print(f"   å·²å¤„ç†è®°å½•: {total_processed_records:,} æ¡")
        
        if self.processed_state.get('last_update'):
            print(f"   æœ€åæ›´æ–°: {self.processed_state['last_update']}")
        
        # 3. æœ€è¿‘å¤„ç†å†å²
        history = self.processed_state.get('processing_history', [])
        if history:
            print(f"\nğŸ•’ æœ€è¿‘å¤„ç†è®°å½•:")
            for record in history[-5:]:  # æ˜¾ç¤ºæœ€è¿‘5æ¡
                date_str = record.get('date', 'Unknown')
                files = record.get('files', 0)
                records = record.get('records', 0)
                duration = record.get('duration', 0)
                processed_at = record.get('processed_at', '')[:19].replace('T', ' ')
                print(f"     {date_str} - {processed_at}: {files} æ–‡ä»¶, {records:,} è®°å½•, {duration:.1f}s")
        
        # 4. ä¼šè¯ç»Ÿè®¡
        if self.session_stats['start_time']:
            print(f"\nğŸ“‹ å½“å‰ä¼šè¯ç»Ÿè®¡:")
            print(f"   å¼€å§‹æ—¶é—´: {self.session_stats['start_time'].strftime('%Y-%m-%d %H:%M:%S')}")
            if self.session_stats['end_time']:
                print(f"   ç»“æŸæ—¶é—´: {self.session_stats['end_time'].strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"   å¤„ç†æ–‡ä»¶: {self.session_stats['total_files_processed']} ä¸ª")
            print(f"   å¤„ç†è®°å½•: {self.session_stats['total_records_written']:,} æ¡")
            print(f"   å¤„ç†è¡Œæ•°: {self.session_stats['total_lines_processed']:,} è¡Œ")
            if self.session_stats['total_errors'] > 0:
                print(f"   é”™è¯¯æ•°é‡: {self.session_stats['total_errors']:,} æ¡")
    
    def clear_all_data(self):
        """æ¸…ç©ºæ‰€æœ‰æ•°æ®ï¼ˆå¼€å‘ç¯å¢ƒä½¿ç”¨ï¼‰"""
        self.logger.info("å¼€å§‹æ¸…ç©ºæ‰€æœ‰æ•°æ®")
        
        print("âš ï¸  è­¦å‘Šï¼šè¿™å°†æ¸…ç©ºæ‰€æœ‰ETLæ•°æ®å’Œå¤„ç†çŠ¶æ€")
        print("1. æ¸…ç©ºClickHouseæ•°æ®åº“è¡¨")
        print("2. é‡ç½®å¤„ç†çŠ¶æ€æ–‡ä»¶")
        
        # è¿æ¥æ•°æ®åº“è¿›è¡Œæ¸…ç†
        if not self.writer.connect():
            print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
            return
        
        try:
            # æ‰§è¡Œè¡¨æ¸…ç©º - ä½¿ç”¨DWD Writerçš„ç®€å•æ¸…ç©ºæ–¹æ³•
            tables_to_clear = ['dwd_nginx_enriched_v2']  # ä¸»è¦æ•°æ®è¡¨
            cleared_count = 0
            
            for table_name in tables_to_clear:
                try:
                    result = self.writer.client.command(f"TRUNCATE TABLE {table_name}")
                    print(f"âœ… å·²æ¸…ç©ºè¡¨: {table_name}")
                    cleared_count += 1
                except Exception as e:
                    print(f"âŒ æ¸…ç©ºè¡¨å¤±è´¥ {table_name}: {e}")
            
            print(f"âœ… æˆåŠŸæ¸…ç©º {cleared_count}/{len(tables_to_clear)} ä¸ªè¡¨")
            
            # é‡ç½®çŠ¶æ€æ–‡ä»¶
            self.processed_state = {
                'processed_files': {},
                'last_update': None,
                'total_processed_records': 0,
                'processing_history': []
            }
            self.save_state()
            print("âœ… å¤„ç†çŠ¶æ€å·²é‡ç½®")
            
            # é‡ç½®ä¼šè¯ç»Ÿè®¡
            self.session_stats = {
                'start_time': None,
                'end_time': None,
                'total_files_processed': 0,
                'total_lines_processed': 0,
                'total_records_written': 0,
                'total_errors': 0,
                'processing_errors': []
            }
            
        finally:
            self.writer.close()
    
    def interactive_menu(self):
        """äº¤äº’å¼èœå•"""
        while True:
            print("\n" + "=" * 80)
            print("ğŸš€ æ™ºèƒ½åŒ–ETLæ§åˆ¶å™¨ - åŸºäºPhase 1æˆåŠŸéªŒè¯")
            print("=" * 80)
            print("1. ğŸ”„ å¤„ç†æ‰€æœ‰æœªå¤„ç†çš„æ—¥å¿— (æ¨è)")
            print("2. ğŸ“… å¤„ç†æŒ‡å®šæ—¥æœŸçš„æ—¥å¿—")
            print("3. ğŸ“Š æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€")
            print("4. ğŸ§ª æµ‹è¯•æ¨¡å¼å¤„ç† (ä¸å†™å…¥æ•°æ®åº“)")
            print("5. ğŸ§¹ æ¸…ç©ºæ‰€æœ‰æ•°æ® (å¼€å‘ç¯å¢ƒ)")
            print("6. ğŸ” å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰æ—¥å¿—")
            print("0. ğŸ‘‹ é€€å‡º")
            print("-" * 80)
            
            try:
                choice = input("è¯·é€‰æ‹©æ“ä½œ [0-6]: ").strip()
                
                if choice == '0':
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                
                elif choice == '1':
                    print("\\nğŸ”„ å¼€å§‹å¤„ç†æ‰€æœ‰æœªå¤„ç†çš„æ—¥å¿—...")
                    
                    # è¯¢é—®æ˜¯å¦é™åˆ¶å¤„ç†è¡Œæ•°
                    limit_input = input("æ˜¯å¦é™åˆ¶æ¯ä¸ªæ–‡ä»¶çš„å¤„ç†è¡Œæ•°ï¼Ÿ(ç•™ç©ºè¡¨ç¤ºä¸é™åˆ¶): ").strip()
                    limit = int(limit_input) if limit_input.isdigit() else None
                    
                    result = self.process_all_unprocessed_logs(test_mode=False, limit=limit)
                    self._print_batch_process_result(result)
                    input("\\næŒ‰å›è½¦é”®ç»§ç»­...")
                
                elif choice == '2':
                    date_str = input("\\nè¯·è¾“å…¥æ—¥æœŸ (YYYYMMDDæ ¼å¼ï¼Œå¦‚: 20250829): ").strip()
                    if not self._validate_date_format(date_str):
                        continue
                    
                    force = input("æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†ï¼Ÿ(y/N): ").strip().lower() == 'y'
                    limit_input = input("æ˜¯å¦é™åˆ¶æ¯ä¸ªæ–‡ä»¶çš„å¤„ç†è¡Œæ•°ï¼Ÿ(ç•™ç©ºè¡¨ç¤ºä¸é™åˆ¶): ").strip()
                    limit = int(limit_input) if limit_input.isdigit() else None
                    
                    print(f"\\nğŸ”„ å¼€å§‹å¤„ç† {date_str} çš„æ—¥å¿—...")
                    result = self.process_specific_date(date_str, force, test_mode=False, limit=limit)
                    self._print_single_date_result(result)
                    input("\\næŒ‰å›è½¦é”®ç»§ç»­...")
                
                elif choice == '3':
                    print()
                    self.show_status()
                    input("\\næŒ‰å›è½¦é”®ç»§ç»­...")
                
                elif choice == '4':
                    print("\\nğŸ§ª æµ‹è¯•æ¨¡å¼å¤„ç†")
                    sub_choice = input("é€‰æ‹©: 1)å¤„ç†æ‰€æœ‰æœªå¤„ç†æ—¥å¿— 2)å¤„ç†æŒ‡å®šæ—¥æœŸ [1-2]: ").strip()
                    
                    if sub_choice == '1':
                        limit_input = input("é™åˆ¶æ¯ä¸ªæ–‡ä»¶çš„å¤„ç†è¡Œæ•° (å»ºè®®10-100): ").strip()
                        limit = int(limit_input) if limit_input.isdigit() else 10
                        
                        print("\\nğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šå¤„ç†æ‰€æœ‰æœªå¤„ç†çš„æ—¥å¿—...")
                        result = self.process_all_unprocessed_logs(test_mode=True, limit=limit)
                        self._print_batch_process_result(result)
                        
                    elif sub_choice == '2':
                        date_str = input("è¯·è¾“å…¥æ—¥æœŸ (YYYYMMDDæ ¼å¼): ").strip()
                        if not self._validate_date_format(date_str):
                            continue
                        
                        limit_input = input("é™åˆ¶æ¯ä¸ªæ–‡ä»¶çš„å¤„ç†è¡Œæ•° (å»ºè®®10-100): ").strip()
                        limit = int(limit_input) if limit_input.isdigit() else 10
                        
                        print(f"\\nğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šå¤„ç† {date_str} çš„æ—¥å¿—...")
                        result = self.process_specific_date(date_str, False, test_mode=True, limit=limit)
                        self._print_single_date_result(result)
                    
                    input("\\næŒ‰å›è½¦é”®ç»§ç»­...")
                
                elif choice == '5':
                    print("\\nâš ï¸  æ¸…ç©ºæ‰€æœ‰æ•°æ®")
                    confirm = input("ç¡®è®¤æ¸…ç©ºæ‰€æœ‰ETLæ•°æ®ï¼Ÿ(y/N): ").strip().lower()
                    if confirm == 'y':
                        second_confirm = input("å†æ¬¡ç¡®è®¤ï¼è¾“å…¥ 'CLEAR' ç¡®è®¤åˆ é™¤: ").strip()
                        if second_confirm == 'CLEAR':
                            self.clear_all_data()
                        else:
                            print("âŒ ç¡®è®¤å¤±è´¥ï¼Œæ“ä½œå·²å–æ¶ˆ")
                    else:
                        print("âŒ æ“ä½œå·²å–æ¶ˆ")
                    input("\\næŒ‰å›è½¦é”®ç»§ç»­...")
                
                elif choice == '6':
                    print("\\nâš ï¸  å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰æ—¥å¿—")
                    print("è¿™å°†å¿½ç•¥å¤„ç†çŠ¶æ€ï¼Œé‡æ–°å¤„ç†æ‰€æœ‰æ—¥å¿—æ–‡ä»¶")
                    confirm = input("ç¡®è®¤æ‰§è¡Œï¼Ÿ(y/N): ").strip().lower()
                    if confirm == 'y':
                        limit_input = input("æ˜¯å¦é™åˆ¶æ¯ä¸ªæ–‡ä»¶çš„å¤„ç†è¡Œæ•°ï¼Ÿ(ç•™ç©ºè¡¨ç¤ºä¸é™åˆ¶): ").strip()
                        limit = int(limit_input) if limit_input.isdigit() else None
                        
                        print("\\nğŸ”„ å¼€å§‹å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰æ—¥å¿—...")
                        
                        # ä¸´æ—¶å¤‡ä»½çŠ¶æ€
                        backup_state = self.processed_state.copy()
                        
                        # æ¸…ç©ºçŠ¶æ€ä»¥å¼ºåˆ¶é‡å¤„ç†
                        self.processed_state = {
                            'processed_files': {},
                            'last_update': None,
                            'total_processed_records': 0,
                            'processing_history': []
                        }
                        
                        result = self.process_all_unprocessed_logs(test_mode=False, limit=limit)
                        
                        # å¦‚æœå¤±è´¥ï¼Œæ¢å¤çŠ¶æ€
                        if not result['success']:
                            self.processed_state = backup_state
                            print("âŒ å¤„ç†å¤±è´¥ï¼Œå·²æ¢å¤åŸå§‹çŠ¶æ€")
                        
                        self._print_batch_process_result(result)
                    else:
                        print("âŒ æ“ä½œå·²å–æ¶ˆ")
                    input("\\næŒ‰å›è½¦é”®ç»§ç»­...")
                
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 0-6")
                    input("æŒ‰å›è½¦é”®ç»§ç»­...")
                    
            except KeyboardInterrupt:
                print("\\n\\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
                break
            except Exception as e:
                print(f"\\nâŒ æ“ä½œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                input("æŒ‰å›è½¦é”®ç»§ç»­...")
    
    # === ç§æœ‰è¾…åŠ©æ–¹æ³• ===
    
    def _write_batch(self, batch: List[Dict[str, Any]], test_mode: bool) -> Dict[str, Any]:
        """å†™å…¥æ‰¹é‡æ•°æ® - åŸºäºsimple_etl_controller"""
        if test_mode:
            return {
                'success': True,
                'count': len(batch),
                'message': f'æµ‹è¯•æ¨¡å¼ï¼šæ¨¡æ‹Ÿå†™å…¥ {len(batch)} æ¡è®°å½•'
            }
        else:
            return self.writer.write_batch(batch)
    
    def _create_error_result(self, error: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return {
            'success': False,
            'error': error,
            'stats': {},
            'timestamp': datetime.now()
        }
    
    def _validate_date_format(self, date_str: str) -> bool:
        """éªŒè¯æ—¥æœŸæ ¼å¼"""
        if not date_str or len(date_str) != 8 or not date_str.isdigit():
            print("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨YYYYMMDDæ ¼å¼")
            return False
        
        try:
            datetime.strptime(date_str, '%Y%m%d')
            return True
        except ValueError:
            print("âŒ æ— æ•ˆçš„æ—¥æœŸ")
            return False
    
    def _print_batch_process_result(self, result: Dict[str, Any]):
        """æ‰“å°æ‰¹é‡å¤„ç†ç»“æœ"""
        print("\\n" + "=" * 60)
        if result['success']:
            print("âœ… æ‰¹é‡å¤„ç†æˆåŠŸ!")
            print("=" * 60)
            print(f"ğŸ“„ å¤„ç†æ—¥æœŸæ•°: {result.get('processed_dates', 0)} ä¸ª")
            print(f"ğŸ“Š æ€»è®°å½•æ•°: {result.get('total_records', 0):,} æ¡")
            print(f"â±ï¸  æ€»è€—æ—¶: {result.get('duration', 0):.2f} ç§’")
            
            if result.get('total_records', 0) > 0 and result.get('duration', 0) > 0:
                speed = result['total_records'] / result['duration']
                print(f"ğŸš€ å¤„ç†é€Ÿåº¦: {speed:.1f} è®°å½•/ç§’")
        else:
            print("âŒ æ‰¹é‡å¤„ç†å¤±è´¥!")
            print("=" * 60)
            print(f"âŒ é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            errors = result.get('errors', [])
            if errors:
                print(f"ğŸ“‹ è¯¦ç»†é”™è¯¯ ({len(errors)} ä¸ª):")
                for i, error in enumerate(errors[:5], 1):
                    print(f"   {i}. {error}")
                if len(errors) > 5:
                    print(f"   ... è¿˜æœ‰ {len(errors) - 5} ä¸ªé”™è¯¯")
        print("=" * 60)
    
    def _print_single_date_result(self, result: Dict[str, Any]):
        """æ‰“å°å•ä¸ªæ—¥æœŸçš„å¤„ç†ç»“æœ"""
        print("\\n" + "=" * 60)
        if result['success']:
            print("âœ… æ—¥æœŸå¤„ç†æˆåŠŸ!")
            print("=" * 60)
            print(f"ğŸ“… å¤„ç†æ—¥æœŸ: {result['date']}")
            print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {result['processed_files']} ä¸ª")
            print(f"ğŸ“Š æ€»è®°å½•æ•°: {result['total_records']:,} æ¡")
            print(f"â±ï¸  æ€»è€—æ—¶: {result['duration']:.2f} ç§’")
            
            if result['total_records'] > 0 and result['duration'] > 0:
                speed = result['total_records'] / result['duration']
                print(f"ğŸš€ å¤„ç†é€Ÿåº¦: {speed:.1f} è®°å½•/ç§’")
        else:
            print("âŒ æ—¥æœŸå¤„ç†å¤±è´¥!")
            print("=" * 60)
            print(f"ğŸ“… å¤„ç†æ—¥æœŸ: {result['date']}")
            print(f"âŒ é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            errors = result.get('errors', [])
            if errors:
                print(f"ğŸ“‹ è¯¦ç»†é”™è¯¯:")
                for i, error in enumerate(errors, 1):
                    print(f"   {i}. {error}")
        print("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    import logging
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    parser = argparse.ArgumentParser(
        description='æ™ºèƒ½åŒ–ETLæ§åˆ¶å™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python intelligent_etl_controller.py                          # äº¤äº’å¼èœå• (æ¨è)
  python intelligent_etl_controller.py process --date 20250829  # å¤„ç†æŒ‡å®šæ—¥æœŸ
  python intelligent_etl_controller.py process --date 20250829 --force  # å¼ºåˆ¶é‡æ–°å¤„ç†
  python intelligent_etl_controller.py process-all              # å¤„ç†æ‰€æœ‰æœªå¤„ç†æ—¥å¿—
  python intelligent_etl_controller.py status                   # æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
  python intelligent_etl_controller.py clear-all                # æ¸…ç©ºæ‰€æœ‰æ•°æ® (å¼€å‘ç¯å¢ƒ)
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # processå‘½ä»¤
    process_parser = subparsers.add_parser('process', help='å¤„ç†æŒ‡å®šæ—¥æœŸçš„æ—¥å¿—')
    process_parser.add_argument('--date', required=True, help='æ—¥æœŸ (YYYYMMDDæ ¼å¼)')
    process_parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°å¤„ç†')
    process_parser.add_argument('--limit', type=int, help='é™åˆ¶æ¯ä¸ªæ–‡ä»¶çš„å¤„ç†è¡Œæ•°')
    process_parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼ï¼Œä¸å†™å…¥æ•°æ®åº“')
    
    # å…¶ä»–å‘½ä»¤
    process_all_parser = subparsers.add_parser('process-all', help='å¤„ç†æ‰€æœ‰æœªå¤„ç†çš„æ—¥å¿—')
    process_all_parser.add_argument('--limit', type=int, help='é™åˆ¶æ¯ä¸ªæ–‡ä»¶çš„å¤„ç†è¡Œæ•°')
    process_all_parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼ï¼Œä¸å†™å…¥æ•°æ®åº“')
    
    subparsers.add_parser('status', help='æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€')
    subparsers.add_parser('clear-all', help='æ¸…ç©ºæ‰€æœ‰æ•°æ® (å¼€å‘ç¯å¢ƒä½¿ç”¨)')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æ§åˆ¶å™¨
    controller = IntelligentETLController()
    
    # å¦‚æœæ²¡æœ‰å‚æ•°ï¼Œæ˜¾ç¤ºäº¤äº’å¼èœå•
    if not args.command:
        controller.interactive_menu()
        return
    
    # æ‰§è¡Œå¯¹åº”å‘½ä»¤
    if args.command == 'process':
        if not controller._validate_date_format(args.date):
            return
        
        result = controller.process_specific_date(
            args.date, 
            args.force, 
            test_mode=args.test,
            limit=args.limit
        )
        controller._print_single_date_result(result)
    
    elif args.command == 'process-all':
        result = controller.process_all_unprocessed_logs(
            test_mode=args.test,
            limit=args.limit
        )
        controller._print_batch_process_result(result)
    
    elif args.command == 'status':
        controller.show_status()
    
    elif args.command == 'clear-all':
        confirm = input("âš ï¸  ç¡®è®¤æ¸…ç©ºæ‰€æœ‰æ•°æ®ï¼Ÿè¿™å°†åˆ é™¤æ•°æ®åº“ä¸­çš„æ‰€æœ‰æ—¥å¿—æ•°æ® (y/N): ")
        if confirm.lower() == 'y':
            second_confirm = input("å†æ¬¡ç¡®è®¤ï¼è¾“å…¥ 'CLEAR' ç¡®è®¤åˆ é™¤: ").strip()
            if second_confirm == 'CLEAR':
                controller.clear_all_data()
            else:
                print("âŒ ç¡®è®¤å¤±è´¥ï¼Œæ“ä½œå·²å–æ¶ˆ")
        else:
            print("âŒ æ“ä½œå·²å–æ¶ˆ")


if __name__ == "__main__":
    main()