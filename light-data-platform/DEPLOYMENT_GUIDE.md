# ğŸ“‹ è½»é‡çº§æ•°æ®å¹³å° - éƒ¨ç½²å’Œä½¿ç”¨æŒ‡å—

## ğŸ“Š æ•°æ®å­˜å‚¨ä½ç½®

### å½“å‰å­˜å‚¨
```bash
# æ•°æ®åº“æ–‡ä»¶ä½ç½®
D:\project\nginx-log-analyzer\light-data-platform\database\nginx_analytics.db

# å½“å‰å¤§å°ï¼š421KB (98æ¡æ ·æœ¬æ•°æ®)
# é¢„ä¼°å®¹é‡ï¼š10ä¸‡æ¡è®°å½•çº¦400MB
```

### è¡¨ç»“æ„
- **ods_nginx_log**: åŸå§‹CSVæ•°æ®å­˜å‚¨
- **dwd_nginx_enriched**: å¯ŒåŒ–åçš„ç»´åº¦æ ‡ç­¾æ•°æ®  
- **dws_platform_hourly**: æŒ‰ç»´åº¦èšåˆæ•°æ® [é¢„ç•™]
- **ads_anomaly_log**: å¼‚å¸¸æ£€æµ‹ç»“æœ [é¢„ç•™]

## ğŸ”„ æ—¥å¸¸æ•°æ®å¯¼å…¥

### æ–¹å¼ä¸€ï¼šæ‰‹åŠ¨å¯¼å…¥å•ä¸ªCSV
```bash
cd light-data-platform

# å¯¼å…¥æŒ‡å®šCSVæ–‡ä»¶ï¼ˆè‡ªåŠ¨å¤‡ä»½ï¼‰
python scripts/daily_import.py --csv-path "/path/to/new_data.csv"

# å¯¼å…¥æ—¶ä¸å¤‡ä»½æ•°æ®åº“
python scripts/daily_import.py --csv-path "/path/to/new_data.csv" --no-backup
```

### æ–¹å¼äºŒï¼šç›‘æ§ç›®å½•è‡ªåŠ¨å¯¼å…¥
```bash
# ç›‘æ§æŒ‡å®šç›®å½•ï¼Œè‡ªåŠ¨å¤„ç†æ–°çš„CSVæ–‡ä»¶
python scripts/daily_import.py --watch-dir "/path/to/csv_directory"

# å¤„ç†åçš„æ–‡ä»¶ä¼šè‡ªåŠ¨ç§»åŠ¨åˆ° processed/ å­ç›®å½•
```

### æ–¹å¼ä¸‰ï¼šä½¿ç”¨é»˜è®¤é…ç½®
```bash
# ä½¿ç”¨ config/settings.py ä¸­é…ç½®çš„é»˜è®¤CSVè·¯å¾„
python scripts/daily_import.py

# å½“å‰é»˜è®¤è·¯å¾„ï¼š
# DATA_SOURCE['default_csv_path'] = "data/demo/è‡ªç ”Ng2025.05.09æ—¥å¿—-æ ·ä¾‹_åˆ†æç»“æœ_20250829_224524_temp/processed_logs.csv"
```

### æ•°æ®å¯¼å…¥æµç¨‹
```mermaid
graph LR
    A[CSVæ–‡ä»¶] --> B[ODSå±‚åŠ è½½]
    B --> C[æ•°æ®å¯ŒåŒ–]
    C --> D[DWDå±‚å­˜å‚¨]
    D --> E[Webç•Œé¢æ›´æ–°]
    
    B -.-> F[è‡ªåŠ¨å¤‡ä»½]
    C -.-> G[é‡å¤æ£€æµ‹]
    E -.-> H[ç»Ÿè®¡åˆ·æ–°]
```

## ğŸ“ˆ æ•°æ®ç®¡ç†å‘½ä»¤

### æŸ¥çœ‹æ•°æ®åº“çŠ¶æ€
```bash
# æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
python scripts/daily_import.py --stats

# è¾“å‡ºç¤ºä¾‹ï¼š
# æ•°æ®åº“å¤§å°: 0.41 MB
# ODSè®°å½•æ•°: 98
# DWDè®°å½•æ•°: 98  
# æ•°æ®è´¨é‡è¯„åˆ†: 1.0
# æ•°æ®æ—¶é—´èŒƒå›´: 2025-05-09 11:16:11 ~ 2025-05-09 11:16:37
```

### å¤‡ä»½ç®¡ç†
```bash
# æ‰‹åŠ¨å¤‡ä»½æ•°æ®åº“
python scripts/daily_import.py --backup

# æ¸…ç†7å¤©å‰çš„å¤‡ä»½æ–‡ä»¶
python scripts/daily_import.py --cleanup 7

# å¤‡ä»½æ–‡ä»¶ä½ç½®ï¼šbackups/nginx_analytics_backup_YYYYMMDD_HHMMSS.db
```

### ç›´æ¥ä½¿ç”¨æ•°æ®å¤„ç†å™¨
```bash
# ODSå±‚æ“ä½œ
python data_pipeline/ods_processor.py --csv-path "/path/to/file.csv"
python data_pipeline/ods_processor.py --stats

# DWDå±‚æ“ä½œ  
python data_pipeline/dwd_processor.py --process
python data_pipeline/dwd_processor.py --analyze
```

## ğŸš€ ClickHouseå‡çº§æ–¹æ¡ˆ

### å‡†å¤‡å·¥ä½œ
```bash
# å®‰è£…ClickHouseå®¢æˆ·ç«¯
pip install clickhouse-connect

# ç¡®ä¿ClickHouseæœåŠ¡è¿è¡Œ
# Dockeræ–¹å¼ï¼š
docker run -d --name clickhouse-server --ulimit nofile=262144:262144 -p 8123:8123 clickhouse/clickhouse-server

# æˆ–ä¸‹è½½å®‰è£…åŒ…ï¼šhttps://clickhouse.com/docs/en/install
```

### å‡çº§æ­¥éª¤

#### 1. åˆå§‹åŒ–ClickHouseç¯å¢ƒ
```bash
cd light-data-platform

# åˆå§‹åŒ–æ•°æ®åº“å’Œè¡¨ç»“æ„
python migration/clickhouse_migration.py --init --host localhost --port 8123

# åˆ›å»ºçš„è¡¨ï¼š
# - nginx_analytics.ods_nginx_log (åŸå§‹æ•°æ®)
# - nginx_analytics.dwd_nginx_enriched (å¯ŒåŒ–æ•°æ®)  
# - nginx_analytics.dws_platform_hourly (èšåˆæ•°æ®)
```

#### 2. è¿ç§»SQLiteæ•°æ®
```bash
# æ‰§è¡Œå®Œæ•´æ•°æ®è¿ç§»
python migration/clickhouse_migration.py --migrate --host localhost --port 8123

# åˆ†åˆ«è¿ç§»ODSå’ŒDWDæ•°æ®ï¼Œæ”¯æŒ10ä¸‡æ¡/æ‰¹æ¬¡é«˜é€Ÿè¿ç§»
```

#### 3. éªŒè¯è¿ç§»ç»“æœ
```bash
# æ•°æ®ä¸€è‡´æ€§éªŒè¯
python migration/clickhouse_migration.py --verify --host localhost --port 8123

# è¾“å‡ºç¤ºä¾‹ï¼š
# ClickHouse ODSè®°å½•æ•°: 98
# ClickHouse DWDè®°å½•æ•°: 98  
# SQLite ODSè®°å½•æ•°: 98
# SQLite DWDè®°å½•æ•°: 98
# æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥: ODS: âœ“ DWD: âœ“
```

#### 4. æ€§èƒ½å¯¹æ¯”æµ‹è¯•
```bash
python migration/clickhouse_migration.py --performance --host localhost --port 8123

# é¢„æœŸæ€§èƒ½æå‡ï¼š
# - æŸ¥è¯¢é€Ÿåº¦ï¼š10-100xæå‡
# - å­˜å‚¨å‹ç¼©ï¼š50-80%ç©ºé—´èŠ‚çœ
# - å¹¶å‘èƒ½åŠ›ï¼šæ”¯æŒç™¾ä¸‡çº§è®°å½•
```

### ClickHouseä¼˜åŠ¿
| å¯¹æ¯”é¡¹ | SQLite | ClickHouse |
|--------|--------|------------|
| **æ•°æ®é‡æ”¯æŒ** | <10ä¸‡æ¡ | åƒä¸‡çº§+ |
| **æŸ¥è¯¢æ€§èƒ½** | ç§’çº§ | æ¯«ç§’çº§ |
| **å¹¶å‘æŸ¥è¯¢** | å•çº¿ç¨‹ | é«˜å¹¶å‘ |
| **æ•°æ®å‹ç¼©** | æ—  | 10:1å‹ç¼©æ¯” |
| **å®æ—¶èšåˆ** | éœ€è®¡ç®— | ç‰©åŒ–è§†å›¾ |
| **æ‰©å±•æ€§** | å•æœº | åˆ†å¸ƒå¼é›†ç¾¤ |

### å‡çº§åçš„é…ç½®ä¿®æ”¹
```python
# config/clickhouse_settings.py
CLICKHOUSE = {
    'host': 'localhost',
    'port': 8123,
    'username': 'default', 
    'password': '',
    'database': 'nginx_analytics'
}

# Webåº”ç”¨è‡ªåŠ¨åˆ‡æ¢åˆ°ClickHouseæŸ¥è¯¢
```

## ğŸ“Š ç›‘æ§å’Œç»´æŠ¤

### æ•°æ®è´¨é‡ç›‘æ§
```bash
# æ¯æ—¥æ•°æ®è´¨é‡æŠ¥å‘Š
python scripts/daily_import.py --stats

# å…³é”®æŒ‡æ ‡ï¼š
# - æ•°æ®è´¨é‡è¯„åˆ† (ç›®æ ‡: >0.9)
# - æˆåŠŸç‡ (ç›®æ ‡: >95%)  
# - æ…¢è¯·æ±‚ç‡ (ç›®æ ‡: <5%)
# - å¼‚å¸¸ç‡ (ç›®æ ‡: <1%)
```

### æ€§èƒ½ç›‘æ§
```bash
# SQLiteæ€§èƒ½åŸºçº¿ï¼ˆå½“å‰ï¼‰
# - 98æ¡è®°å½•ï¼šç»Ÿè®¡æŸ¥è¯¢ 0.026ç§’
# - é¢„æœŸ10ä¸‡æ¡ï¼šæŸ¥è¯¢ 3ç§’
# - é¢„æœŸ100ä¸‡æ¡ï¼šæŸ¥è¯¢ 30ç§’+ [éœ€å‡çº§ClickHouse]

# ClickHouseæ€§èƒ½ç›®æ ‡
# - 100ä¸‡æ¡è®°å½•ï¼šæŸ¥è¯¢ <100æ¯«ç§’
# - 1000ä¸‡æ¡è®°å½•ï¼šæŸ¥è¯¢ <500æ¯«ç§’  
```

### ç»´æŠ¤ä»»åŠ¡
```bash
# æ¯æ—¥ä»»åŠ¡
python scripts/daily_import.py --watch-dir "/data/nginx_logs"

# æ¯å‘¨ä»»åŠ¡  
python scripts/daily_import.py --cleanup 7  # æ¸…ç†æ—§å¤‡ä»½

# æ¯æœˆä»»åŠ¡
# è¯„ä¼°æ•°æ®é‡å¢é•¿ï¼Œå†³å®šæ˜¯å¦å‡çº§ClickHouse
# å½“æ•°æ®åº“å¤§å° >100MB æˆ–æŸ¥è¯¢æ—¶é—´ >5ç§’ æ—¶å»ºè®®å‡çº§
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. CSVå­—æ®µä¸åŒ¹é…
```bash
# é”™è¯¯ï¼šKeyError: 'timestamp' 
# è§£å†³ï¼šæ£€æŸ¥CSVå­—æ®µåï¼Œä¿®æ”¹ field_mapping

# å½“å‰æ”¯æŒçš„å­—æ®µæ˜ å°„ï¼š
# timestamp <- raw_time, arrival_time
# client_ip <- client_ip_address  
# user_agent <- user_agent_string
# referer <- referer_url
```

#### 2. å†…å­˜ä¸è¶³
```bash
# é”™è¯¯ï¼šMemoryError
# è§£å†³ï¼šå‡å°‘æ‰¹å¤„ç†å¤§å°

python scripts/daily_import.py --csv-path "/path/to/large.csv"
# ä¿®æ”¹ batch_size å‚æ•° (é»˜è®¤1000 -> 500)
```

#### 3. æ•°æ®åº“é”å®š
```bash
# é”™è¯¯ï¼šdatabase is locked
# è§£å†³ï¼šåœæ­¢WebæœåŠ¡åé‡è¯•

# åœæ­¢WebæœåŠ¡
ps aux | grep "web_app/app.py" | awk '{print $2}' | xargs kill

# é‡æ–°å¯¼å…¥æ•°æ®
python scripts/daily_import.py --csv-path "/path/to/file.csv"

# é‡å¯WebæœåŠ¡
python web_app/app.py
```

#### 4. ClickHouseè¿æ¥å¤±è´¥  
```bash
# é”™è¯¯ï¼šConnection refused
# è§£å†³ï¼šæ£€æŸ¥ClickHouseæœåŠ¡çŠ¶æ€

# Dockeræ–¹å¼é‡å¯
docker restart clickhouse-server

# æ£€æŸ¥ç«¯å£
telnet localhost 8123
```

## ğŸ¯ æœ€ä½³å®è·µ

### æ•°æ®å¯¼å…¥ç­–ç•¥
1. **å¢é‡å¯¼å…¥**: æ¯æ—¥åªå¯¼å…¥æ–°æ•°æ®ï¼Œé¿å…é‡å¤
2. **è‡ªåŠ¨å¤‡ä»½**: å¯¼å…¥å‰è‡ªåŠ¨å¤‡ä»½ï¼Œå¤±è´¥æ—¶å¯å›æ»š  
3. **æ‰¹å¤„ç†**: å¤§æ–‡ä»¶åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å†…å­˜æº¢å‡º
4. **ç›‘æ§ç›®å½•**: ä½¿ç”¨watch-dirå®ç°è‡ªåŠ¨åŒ–

### æ€§èƒ½ä¼˜åŒ–
1. **SQLiteé˜¶æ®µ**: æ•°æ®é‡<10ä¸‡æ¡ï¼ŒæŸ¥è¯¢<5ç§’
2. **å‡çº§æ—¶æœº**: æ•°æ®åº“>100MBæˆ–æŸ¥è¯¢>5ç§’æ—¶å‡çº§ClickHouse  
3. **ç´¢å¼•ä¼˜åŒ–**: ClickHouseæŒ‰æ—¶é—´+å¹³å°+APIåˆ†ç±»å»ºç´¢å¼•
4. **ç‰©åŒ–è§†å›¾**: å®æ—¶èšåˆå¸¸ç”¨æŸ¥è¯¢ï¼Œæå‡å“åº”é€Ÿåº¦

### è¿ç»´å»ºè®®
1. **å®šæ—¶å¤‡ä»½**: æ¯æ—¥è‡ªåŠ¨å¤‡ä»½ï¼Œä¿ç•™7å¤©
2. **æ€§èƒ½ç›‘æ§**: å®šæœŸæ£€æŸ¥æŸ¥è¯¢å“åº”æ—¶é—´
3. **å®¹é‡è§„åˆ’**: é¢„ä¼°æ•°æ®å¢é•¿ï¼Œæå‰å‡çº§
4. **æ—¥å¿—å®¡è®¡**: è®°å½•æ‰€æœ‰å¯¼å…¥æ“ä½œå’Œé”™è¯¯

é€šè¿‡è¿™å¥—å®Œæ•´çš„éƒ¨ç½²å’Œè¿ç»´æ–¹æ¡ˆï¼Œæ‚¨å¯ä»¥ä»è½»é‡çº§SQLiteå¹³å°å¹³æ»‘å‡çº§åˆ°ä¼ä¸šçº§ClickHouseå¹³å°ï¼Œå®ç°nginxæ—¥å¿—åˆ†æçš„å…¨é¢æå‡ï¼ğŸš€